{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./churn_dataset.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"RowNumber\", \"CustomerId\", \"Surname\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Gender\", \"Geography\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Exited\"])\n",
    "y = df[\"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(11, activation=\"relu\", input_dim=11))\n",
    "model.add(Dense(11, activation=\"relu\"))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 276\n",
      "Trainable params: 276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.5470 - accuracy: 0.7497 - val_loss: 0.4749 - val_accuracy: 0.7987\n",
      "Epoch 2/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8047 - val_loss: 0.4416 - val_accuracy: 0.8131\n",
      "Epoch 3/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8186 - val_loss: 0.4298 - val_accuracy: 0.8138\n",
      "Epoch 4/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8247 - val_loss: 0.4229 - val_accuracy: 0.8131\n",
      "Epoch 5/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8273 - val_loss: 0.4217 - val_accuracy: 0.8206\n",
      "Epoch 6/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8309 - val_loss: 0.4120 - val_accuracy: 0.8213\n",
      "Epoch 7/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8342 - val_loss: 0.4053 - val_accuracy: 0.8269\n",
      "Epoch 8/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8380 - val_loss: 0.3958 - val_accuracy: 0.8300\n",
      "Epoch 9/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8417 - val_loss: 0.3870 - val_accuracy: 0.8369\n",
      "Epoch 10/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8467 - val_loss: 0.3794 - val_accuracy: 0.8388\n",
      "Epoch 11/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8498 - val_loss: 0.3703 - val_accuracy: 0.8456\n",
      "Epoch 12/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8548 - val_loss: 0.3654 - val_accuracy: 0.8450\n",
      "Epoch 13/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8541 - val_loss: 0.3621 - val_accuracy: 0.8431\n",
      "Epoch 14/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8541 - val_loss: 0.3595 - val_accuracy: 0.8444\n",
      "Epoch 15/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8556 - val_loss: 0.3588 - val_accuracy: 0.8438\n",
      "Epoch 16/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8575 - val_loss: 0.3536 - val_accuracy: 0.8494\n",
      "Epoch 17/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8591 - val_loss: 0.3536 - val_accuracy: 0.8475\n",
      "Epoch 18/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8598 - val_loss: 0.3544 - val_accuracy: 0.8456\n",
      "Epoch 19/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8598 - val_loss: 0.3511 - val_accuracy: 0.8512\n",
      "Epoch 20/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8591 - val_loss: 0.3532 - val_accuracy: 0.8500\n",
      "Epoch 21/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8619 - val_loss: 0.3512 - val_accuracy: 0.8531\n",
      "Epoch 22/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8611 - val_loss: 0.3526 - val_accuracy: 0.8469\n",
      "Epoch 23/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8625 - val_loss: 0.3499 - val_accuracy: 0.8512\n",
      "Epoch 24/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8614 - val_loss: 0.3508 - val_accuracy: 0.8494\n",
      "Epoch 25/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8606 - val_loss: 0.3490 - val_accuracy: 0.8531\n",
      "Epoch 26/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8634 - val_loss: 0.3496 - val_accuracy: 0.8494\n",
      "Epoch 27/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8636 - val_loss: 0.3497 - val_accuracy: 0.8487\n",
      "Epoch 28/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8619 - val_loss: 0.3497 - val_accuracy: 0.8512\n",
      "Epoch 29/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8622 - val_loss: 0.3483 - val_accuracy: 0.8494\n",
      "Epoch 30/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8628 - val_loss: 0.3482 - val_accuracy: 0.8487\n",
      "Epoch 31/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8614 - val_loss: 0.3503 - val_accuracy: 0.8525\n",
      "Epoch 32/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8639 - val_loss: 0.3474 - val_accuracy: 0.8500\n",
      "Epoch 33/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8630 - val_loss: 0.3487 - val_accuracy: 0.8506\n",
      "Epoch 34/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8645 - val_loss: 0.3476 - val_accuracy: 0.8525\n",
      "Epoch 35/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8625 - val_loss: 0.3490 - val_accuracy: 0.8512\n",
      "Epoch 36/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8623 - val_loss: 0.3467 - val_accuracy: 0.8500\n",
      "Epoch 37/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8644 - val_loss: 0.3463 - val_accuracy: 0.8481\n",
      "Epoch 38/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8653 - val_loss: 0.3456 - val_accuracy: 0.8500\n",
      "Epoch 39/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8644 - val_loss: 0.3485 - val_accuracy: 0.8487\n",
      "Epoch 40/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8644 - val_loss: 0.3485 - val_accuracy: 0.8487\n",
      "Epoch 41/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8622 - val_loss: 0.3461 - val_accuracy: 0.8506\n",
      "Epoch 42/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8622 - val_loss: 0.3461 - val_accuracy: 0.8512\n",
      "Epoch 43/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8655 - val_loss: 0.3455 - val_accuracy: 0.8481\n",
      "Epoch 44/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8652 - val_loss: 0.3455 - val_accuracy: 0.8494\n",
      "Epoch 45/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8669 - val_loss: 0.3465 - val_accuracy: 0.8500\n",
      "Epoch 46/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8641 - val_loss: 0.3443 - val_accuracy: 0.8525\n",
      "Epoch 47/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8661 - val_loss: 0.3473 - val_accuracy: 0.8506\n",
      "Epoch 48/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8662 - val_loss: 0.3440 - val_accuracy: 0.8506\n",
      "Epoch 49/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8639 - val_loss: 0.3452 - val_accuracy: 0.8487\n",
      "Epoch 50/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8652 - val_loss: 0.3454 - val_accuracy: 0.8512\n",
      "Epoch 51/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8653 - val_loss: 0.3464 - val_accuracy: 0.8512\n",
      "Epoch 52/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8652 - val_loss: 0.3466 - val_accuracy: 0.8531\n",
      "Epoch 53/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8652 - val_loss: 0.3454 - val_accuracy: 0.8500\n",
      "Epoch 54/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8662 - val_loss: 0.3444 - val_accuracy: 0.8525\n",
      "Epoch 55/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8661 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
      "Epoch 56/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8669 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
      "Epoch 57/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8658 - val_loss: 0.3456 - val_accuracy: 0.8494\n",
      "Epoch 58/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8652 - val_loss: 0.3443 - val_accuracy: 0.8519\n",
      "Epoch 59/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8659 - val_loss: 0.3437 - val_accuracy: 0.8531\n",
      "Epoch 60/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8681 - val_loss: 0.3474 - val_accuracy: 0.8481\n",
      "Epoch 61/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8650 - val_loss: 0.3448 - val_accuracy: 0.8506\n",
      "Epoch 62/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8664 - val_loss: 0.3431 - val_accuracy: 0.8544\n",
      "Epoch 63/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8678 - val_loss: 0.3482 - val_accuracy: 0.8500\n",
      "Epoch 64/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8655 - val_loss: 0.3481 - val_accuracy: 0.8500\n",
      "Epoch 65/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.8655 - val_loss: 0.3444 - val_accuracy: 0.8512\n",
      "Epoch 66/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8658 - val_loss: 0.3435 - val_accuracy: 0.8500\n",
      "Epoch 67/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8667 - val_loss: 0.3434 - val_accuracy: 0.8494\n",
      "Epoch 68/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8655 - val_loss: 0.3442 - val_accuracy: 0.8487\n",
      "Epoch 69/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8661 - val_loss: 0.3427 - val_accuracy: 0.8525\n",
      "Epoch 70/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8677 - val_loss: 0.3451 - val_accuracy: 0.8500\n",
      "Epoch 71/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8672 - val_loss: 0.3459 - val_accuracy: 0.8481\n",
      "Epoch 72/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8670 - val_loss: 0.3420 - val_accuracy: 0.8494\n",
      "Epoch 73/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8655 - val_loss: 0.3427 - val_accuracy: 0.8506\n",
      "Epoch 74/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8684 - val_loss: 0.3430 - val_accuracy: 0.8512\n",
      "Epoch 75/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8652 - val_loss: 0.3431 - val_accuracy: 0.8519\n",
      "Epoch 76/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8667 - val_loss: 0.3435 - val_accuracy: 0.8500\n",
      "Epoch 77/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8677 - val_loss: 0.3435 - val_accuracy: 0.8500\n",
      "Epoch 78/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8680 - val_loss: 0.3448 - val_accuracy: 0.8481\n",
      "Epoch 79/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8684 - val_loss: 0.3421 - val_accuracy: 0.8519\n",
      "Epoch 80/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8680 - val_loss: 0.3419 - val_accuracy: 0.8512\n",
      "Epoch 81/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8677 - val_loss: 0.3438 - val_accuracy: 0.8475\n",
      "Epoch 82/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8683 - val_loss: 0.3436 - val_accuracy: 0.8475\n",
      "Epoch 83/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8662 - val_loss: 0.3437 - val_accuracy: 0.8494\n",
      "Epoch 84/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8692 - val_loss: 0.3435 - val_accuracy: 0.8462\n",
      "Epoch 85/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8683 - val_loss: 0.3448 - val_accuracy: 0.8519\n",
      "Epoch 86/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3203 - accuracy: 0.8673 - val_loss: 0.3485 - val_accuracy: 0.8512\n",
      "Epoch 87/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8680 - val_loss: 0.3425 - val_accuracy: 0.8481\n",
      "Epoch 88/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8683 - val_loss: 0.3427 - val_accuracy: 0.8469\n",
      "Epoch 89/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8680 - val_loss: 0.3442 - val_accuracy: 0.8462\n",
      "Epoch 90/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8695 - val_loss: 0.3436 - val_accuracy: 0.8512\n",
      "Epoch 91/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8697 - val_loss: 0.3478 - val_accuracy: 0.8481\n",
      "Epoch 92/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8669 - val_loss: 0.3431 - val_accuracy: 0.8506\n",
      "Epoch 93/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8698 - val_loss: 0.3430 - val_accuracy: 0.8512\n",
      "Epoch 94/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3445 - val_accuracy: 0.8487\n",
      "Epoch 95/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8712 - val_loss: 0.3452 - val_accuracy: 0.8500\n",
      "Epoch 96/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8686 - val_loss: 0.3455 - val_accuracy: 0.8469\n",
      "Epoch 97/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8692 - val_loss: 0.3445 - val_accuracy: 0.8506\n",
      "Epoch 98/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8691 - val_loss: 0.3453 - val_accuracy: 0.8469\n",
      "Epoch 99/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8687 - val_loss: 0.3449 - val_accuracy: 0.8494\n",
      "Epoch 100/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8691 - val_loss: 0.3446 - val_accuracy: 0.8500\n",
      "Epoch 101/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8692 - val_loss: 0.3455 - val_accuracy: 0.8481\n",
      "Epoch 102/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8691 - val_loss: 0.3456 - val_accuracy: 0.8519\n",
      "Epoch 103/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8698 - val_loss: 0.3453 - val_accuracy: 0.8519\n",
      "Epoch 104/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8698 - val_loss: 0.3450 - val_accuracy: 0.8487\n",
      "Epoch 105/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8681 - val_loss: 0.3455 - val_accuracy: 0.8531\n",
      "Epoch 106/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8708 - val_loss: 0.3476 - val_accuracy: 0.8512\n",
      "Epoch 107/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8692 - val_loss: 0.3461 - val_accuracy: 0.8469\n",
      "Epoch 108/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8692 - val_loss: 0.3468 - val_accuracy: 0.8500\n",
      "Epoch 109/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8692 - val_loss: 0.3443 - val_accuracy: 0.8500\n",
      "Epoch 110/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3178 - accuracy: 0.8722 - val_loss: 0.3440 - val_accuracy: 0.8500\n",
      "Epoch 111/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8711 - val_loss: 0.3487 - val_accuracy: 0.8519\n",
      "Epoch 112/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3180 - accuracy: 0.8695 - val_loss: 0.3476 - val_accuracy: 0.8469\n",
      "Epoch 113/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3176 - accuracy: 0.8684 - val_loss: 0.3457 - val_accuracy: 0.8519\n",
      "Epoch 114/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8697 - val_loss: 0.3455 - val_accuracy: 0.8506\n",
      "Epoch 115/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8687 - val_loss: 0.3476 - val_accuracy: 0.8519\n",
      "Epoch 116/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8684 - val_loss: 0.3441 - val_accuracy: 0.8481\n",
      "Epoch 117/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8694 - val_loss: 0.3451 - val_accuracy: 0.8487\n",
      "Epoch 118/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8700 - val_loss: 0.3465 - val_accuracy: 0.8525\n",
      "Epoch 119/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8703 - val_loss: 0.3466 - val_accuracy: 0.8494\n",
      "Epoch 120/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8716 - val_loss: 0.3461 - val_accuracy: 0.8481\n",
      "Epoch 121/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8687 - val_loss: 0.3462 - val_accuracy: 0.8519\n",
      "Epoch 122/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8694 - val_loss: 0.3496 - val_accuracy: 0.8525\n",
      "Epoch 123/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8702 - val_loss: 0.3460 - val_accuracy: 0.8500\n",
      "Epoch 124/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8691 - val_loss: 0.3482 - val_accuracy: 0.8469\n",
      "Epoch 125/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8719 - val_loss: 0.3463 - val_accuracy: 0.8512\n",
      "Epoch 126/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8708 - val_loss: 0.3471 - val_accuracy: 0.8525\n",
      "Epoch 127/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8683 - val_loss: 0.3446 - val_accuracy: 0.8500\n",
      "Epoch 128/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8711 - val_loss: 0.3476 - val_accuracy: 0.8506\n",
      "Epoch 129/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8686 - val_loss: 0.3466 - val_accuracy: 0.8512\n",
      "Epoch 130/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8714 - val_loss: 0.3465 - val_accuracy: 0.8500\n",
      "Epoch 131/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8705 - val_loss: 0.3465 - val_accuracy: 0.8512\n",
      "Epoch 132/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8703 - val_loss: 0.3452 - val_accuracy: 0.8512\n",
      "Epoch 133/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8698 - val_loss: 0.3457 - val_accuracy: 0.8487\n",
      "Epoch 134/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8694 - val_loss: 0.3467 - val_accuracy: 0.8525\n",
      "Epoch 135/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8700 - val_loss: 0.3446 - val_accuracy: 0.8494\n",
      "Epoch 136/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8719 - val_loss: 0.3469 - val_accuracy: 0.8519\n",
      "Epoch 137/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8698 - val_loss: 0.3460 - val_accuracy: 0.8525\n",
      "Epoch 138/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8712 - val_loss: 0.3465 - val_accuracy: 0.8519\n",
      "Epoch 139/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8703 - val_loss: 0.3460 - val_accuracy: 0.8487\n",
      "Epoch 140/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8714 - val_loss: 0.3473 - val_accuracy: 0.8475\n",
      "Epoch 141/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8714 - val_loss: 0.3471 - val_accuracy: 0.8519\n",
      "Epoch 142/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8697 - val_loss: 0.3461 - val_accuracy: 0.8500\n",
      "Epoch 143/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8730 - val_loss: 0.3459 - val_accuracy: 0.8506\n",
      "Epoch 144/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8712 - val_loss: 0.3452 - val_accuracy: 0.8512\n",
      "Epoch 145/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8719 - val_loss: 0.3462 - val_accuracy: 0.8500\n",
      "Epoch 146/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8698 - val_loss: 0.3477 - val_accuracy: 0.8494\n",
      "Epoch 147/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8711 - val_loss: 0.3484 - val_accuracy: 0.8506\n",
      "Epoch 148/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8705 - val_loss: 0.3470 - val_accuracy: 0.8481\n",
      "Epoch 149/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8723 - val_loss: 0.3468 - val_accuracy: 0.8519\n",
      "Epoch 150/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8709 - val_loss: 0.3467 - val_accuracy: 0.8519\n",
      "Epoch 151/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3147 - accuracy: 0.8716 - val_loss: 0.3454 - val_accuracy: 0.8519\n",
      "Epoch 152/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8730 - val_loss: 0.3472 - val_accuracy: 0.8506\n",
      "Epoch 153/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8719 - val_loss: 0.3472 - val_accuracy: 0.8500\n",
      "Epoch 154/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8709 - val_loss: 0.3468 - val_accuracy: 0.8512\n",
      "Epoch 155/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8727 - val_loss: 0.3483 - val_accuracy: 0.8512\n",
      "Epoch 156/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8720 - val_loss: 0.3479 - val_accuracy: 0.8462\n",
      "Epoch 157/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8727 - val_loss: 0.3471 - val_accuracy: 0.8500\n",
      "Epoch 158/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8717 - val_loss: 0.3475 - val_accuracy: 0.8494\n",
      "Epoch 159/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8703 - val_loss: 0.3470 - val_accuracy: 0.8519\n",
      "Epoch 160/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8714 - val_loss: 0.3470 - val_accuracy: 0.8500\n",
      "Epoch 161/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8689 - val_loss: 0.3472 - val_accuracy: 0.8462\n",
      "Epoch 162/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8720 - val_loss: 0.3514 - val_accuracy: 0.8462\n",
      "Epoch 163/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8728 - val_loss: 0.3457 - val_accuracy: 0.8525\n",
      "Epoch 164/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3148 - accuracy: 0.8720 - val_loss: 0.3459 - val_accuracy: 0.8506\n",
      "Epoch 165/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8714 - val_loss: 0.3463 - val_accuracy: 0.8519\n",
      "Epoch 166/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8725 - val_loss: 0.3468 - val_accuracy: 0.8512\n",
      "Epoch 167/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8712 - val_loss: 0.3499 - val_accuracy: 0.8456\n",
      "Epoch 168/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8720 - val_loss: 0.3473 - val_accuracy: 0.8506\n",
      "Epoch 169/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8711 - val_loss: 0.3473 - val_accuracy: 0.8487\n",
      "Epoch 170/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8731 - val_loss: 0.3458 - val_accuracy: 0.8500\n",
      "Epoch 171/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8709 - val_loss: 0.3472 - val_accuracy: 0.8500\n",
      "Epoch 172/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8733 - val_loss: 0.3478 - val_accuracy: 0.8519\n",
      "Epoch 173/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8708 - val_loss: 0.3475 - val_accuracy: 0.8487\n",
      "Epoch 174/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8712 - val_loss: 0.3468 - val_accuracy: 0.8494\n",
      "Epoch 175/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8708 - val_loss: 0.3465 - val_accuracy: 0.8525\n",
      "Epoch 176/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8716 - val_loss: 0.3476 - val_accuracy: 0.8537\n",
      "Epoch 177/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8727 - val_loss: 0.3459 - val_accuracy: 0.8500\n",
      "Epoch 178/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8708 - val_loss: 0.3469 - val_accuracy: 0.8500\n",
      "Epoch 179/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8709 - val_loss: 0.3450 - val_accuracy: 0.8519\n",
      "Epoch 180/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8730 - val_loss: 0.3479 - val_accuracy: 0.8487\n",
      "Epoch 181/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8714 - val_loss: 0.3476 - val_accuracy: 0.8550\n",
      "Epoch 182/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8723 - val_loss: 0.3462 - val_accuracy: 0.8494\n",
      "Epoch 183/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8727 - val_loss: 0.3478 - val_accuracy: 0.8512\n",
      "Epoch 184/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8705 - val_loss: 0.3452 - val_accuracy: 0.8512\n",
      "Epoch 185/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8714 - val_loss: 0.3489 - val_accuracy: 0.8444\n",
      "Epoch 186/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8716 - val_loss: 0.3503 - val_accuracy: 0.8456\n",
      "Epoch 187/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8708 - val_loss: 0.3456 - val_accuracy: 0.8512\n",
      "Epoch 188/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8714 - val_loss: 0.3462 - val_accuracy: 0.8519\n",
      "Epoch 189/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8720 - val_loss: 0.3484 - val_accuracy: 0.8500\n",
      "Epoch 190/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8714 - val_loss: 0.3468 - val_accuracy: 0.8519\n",
      "Epoch 191/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8725 - val_loss: 0.3468 - val_accuracy: 0.8512\n",
      "Epoch 192/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8725 - val_loss: 0.3495 - val_accuracy: 0.8450\n",
      "Epoch 193/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8708 - val_loss: 0.3468 - val_accuracy: 0.8475\n",
      "Epoch 194/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8723 - val_loss: 0.3469 - val_accuracy: 0.8487\n",
      "Epoch 195/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8709 - val_loss: 0.3468 - val_accuracy: 0.8487\n",
      "Epoch 196/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8727 - val_loss: 0.3496 - val_accuracy: 0.8506\n",
      "Epoch 197/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8728 - val_loss: 0.3468 - val_accuracy: 0.8512\n",
      "Epoch 198/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8719 - val_loss: 0.3501 - val_accuracy: 0.8487\n",
      "Epoch 199/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8711 - val_loss: 0.3471 - val_accuracy: 0.8544\n",
      "Epoch 200/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8711 - val_loss: 0.3476 - val_accuracy: 0.8506\n",
      "Epoch 201/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8703 - val_loss: 0.3469 - val_accuracy: 0.8500\n",
      "Epoch 202/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8722 - val_loss: 0.3478 - val_accuracy: 0.8512\n",
      "Epoch 203/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8723 - val_loss: 0.3490 - val_accuracy: 0.8537\n",
      "Epoch 204/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8708 - val_loss: 0.3476 - val_accuracy: 0.8500\n",
      "Epoch 205/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8717 - val_loss: 0.3472 - val_accuracy: 0.8519\n",
      "Epoch 206/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8720 - val_loss: 0.3508 - val_accuracy: 0.8569\n",
      "Epoch 207/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8717 - val_loss: 0.3484 - val_accuracy: 0.8506\n",
      "Epoch 208/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8716 - val_loss: 0.3495 - val_accuracy: 0.8456\n",
      "Epoch 209/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8717 - val_loss: 0.3483 - val_accuracy: 0.8500\n",
      "Epoch 210/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8711 - val_loss: 0.3486 - val_accuracy: 0.8525\n",
      "Epoch 211/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8714 - val_loss: 0.3477 - val_accuracy: 0.8512\n",
      "Epoch 212/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3120 - accuracy: 0.8719 - val_loss: 0.3475 - val_accuracy: 0.8494\n",
      "Epoch 213/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8734 - val_loss: 0.3488 - val_accuracy: 0.8544\n",
      "Epoch 214/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8695 - val_loss: 0.3467 - val_accuracy: 0.8494\n",
      "Epoch 215/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8731 - val_loss: 0.3476 - val_accuracy: 0.8487\n",
      "Epoch 216/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8728 - val_loss: 0.3476 - val_accuracy: 0.8512\n",
      "Epoch 217/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8711 - val_loss: 0.3485 - val_accuracy: 0.8531\n",
      "Epoch 218/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8723 - val_loss: 0.3478 - val_accuracy: 0.8525\n",
      "Epoch 219/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8719 - val_loss: 0.3473 - val_accuracy: 0.8500\n",
      "Epoch 220/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8716 - val_loss: 0.3467 - val_accuracy: 0.8481\n",
      "Epoch 221/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8717 - val_loss: 0.3474 - val_accuracy: 0.8519\n",
      "Epoch 222/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8723 - val_loss: 0.3502 - val_accuracy: 0.8531\n",
      "Epoch 223/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8722 - val_loss: 0.3491 - val_accuracy: 0.8481\n",
      "Epoch 224/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8720 - val_loss: 0.3494 - val_accuracy: 0.8500\n",
      "Epoch 225/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8691 - val_loss: 0.3487 - val_accuracy: 0.8500\n",
      "Epoch 226/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8730 - val_loss: 0.3492 - val_accuracy: 0.8481\n",
      "Epoch 227/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8728 - val_loss: 0.3494 - val_accuracy: 0.8469\n",
      "Epoch 228/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8723 - val_loss: 0.3494 - val_accuracy: 0.8481\n",
      "Epoch 229/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8731 - val_loss: 0.3546 - val_accuracy: 0.8444\n",
      "Epoch 230/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8700 - val_loss: 0.3494 - val_accuracy: 0.8500\n",
      "Epoch 231/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8723 - val_loss: 0.3493 - val_accuracy: 0.8481\n",
      "Epoch 232/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8714 - val_loss: 0.3504 - val_accuracy: 0.8500\n",
      "Epoch 233/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8705 - val_loss: 0.3494 - val_accuracy: 0.8494\n",
      "Epoch 234/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8702 - val_loss: 0.3485 - val_accuracy: 0.8500\n",
      "Epoch 235/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8706 - val_loss: 0.3476 - val_accuracy: 0.8494\n",
      "Epoch 236/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8717 - val_loss: 0.3478 - val_accuracy: 0.8506\n",
      "Epoch 237/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8717 - val_loss: 0.3485 - val_accuracy: 0.8487\n",
      "Epoch 238/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8716 - val_loss: 0.3510 - val_accuracy: 0.8481\n",
      "Epoch 239/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8709 - val_loss: 0.3489 - val_accuracy: 0.8525\n",
      "Epoch 240/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8728 - val_loss: 0.3486 - val_accuracy: 0.8481\n",
      "Epoch 241/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8717 - val_loss: 0.3515 - val_accuracy: 0.8475\n",
      "Epoch 242/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8706 - val_loss: 0.3491 - val_accuracy: 0.8494\n",
      "Epoch 243/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8719 - val_loss: 0.3488 - val_accuracy: 0.8481\n",
      "Epoch 244/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8730 - val_loss: 0.3481 - val_accuracy: 0.8500\n",
      "Epoch 245/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8717 - val_loss: 0.3496 - val_accuracy: 0.8487\n",
      "Epoch 246/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8698 - val_loss: 0.3477 - val_accuracy: 0.8525\n",
      "Epoch 247/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8722 - val_loss: 0.3499 - val_accuracy: 0.8494\n",
      "Epoch 248/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8722 - val_loss: 0.3498 - val_accuracy: 0.8494\n",
      "Epoch 249/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8698 - val_loss: 0.3483 - val_accuracy: 0.8487\n",
      "Epoch 250/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8716 - val_loss: 0.3482 - val_accuracy: 0.8512\n",
      "Epoch 251/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8725 - val_loss: 0.3506 - val_accuracy: 0.8481\n",
      "Epoch 252/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8706 - val_loss: 0.3477 - val_accuracy: 0.8512\n",
      "Epoch 253/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8684 - val_loss: 0.3499 - val_accuracy: 0.8519\n",
      "Epoch 254/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8703 - val_loss: 0.3481 - val_accuracy: 0.8531\n",
      "Epoch 255/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8722 - val_loss: 0.3478 - val_accuracy: 0.8525\n",
      "Epoch 256/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8709 - val_loss: 0.3492 - val_accuracy: 0.8487\n",
      "Epoch 257/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8706 - val_loss: 0.3484 - val_accuracy: 0.8519\n",
      "Epoch 258/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8748 - val_loss: 0.3505 - val_accuracy: 0.8512\n",
      "Epoch 259/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8711 - val_loss: 0.3507 - val_accuracy: 0.8500\n",
      "Epoch 260/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8717 - val_loss: 0.3490 - val_accuracy: 0.8512\n",
      "Epoch 261/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8691 - val_loss: 0.3501 - val_accuracy: 0.8531\n",
      "Epoch 262/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8694 - val_loss: 0.3489 - val_accuracy: 0.8506\n",
      "Epoch 263/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8722 - val_loss: 0.3482 - val_accuracy: 0.8506\n",
      "Epoch 264/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8720 - val_loss: 0.3485 - val_accuracy: 0.8512\n",
      "Epoch 265/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8712 - val_loss: 0.3501 - val_accuracy: 0.8487\n",
      "Epoch 266/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3103 - accuracy: 0.8727 - val_loss: 0.3517 - val_accuracy: 0.8475\n",
      "Epoch 267/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8708 - val_loss: 0.3494 - val_accuracy: 0.8537\n",
      "Epoch 268/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8722 - val_loss: 0.3479 - val_accuracy: 0.8512\n",
      "Epoch 269/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8728 - val_loss: 0.3502 - val_accuracy: 0.8494\n",
      "Epoch 270/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8720 - val_loss: 0.3498 - val_accuracy: 0.8487\n",
      "Epoch 271/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8714 - val_loss: 0.3494 - val_accuracy: 0.8500\n",
      "Epoch 272/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8734 - val_loss: 0.3504 - val_accuracy: 0.8512\n",
      "Epoch 273/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3101 - accuracy: 0.8722 - val_loss: 0.3490 - val_accuracy: 0.8512\n",
      "Epoch 274/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8708 - val_loss: 0.3498 - val_accuracy: 0.8525\n",
      "Epoch 275/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8720 - val_loss: 0.3485 - val_accuracy: 0.8525\n",
      "Epoch 276/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8734 - val_loss: 0.3493 - val_accuracy: 0.8512\n",
      "Epoch 277/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8706 - val_loss: 0.3498 - val_accuracy: 0.8494\n",
      "Epoch 278/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8725 - val_loss: 0.3507 - val_accuracy: 0.8487\n",
      "Epoch 279/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3102 - accuracy: 0.8709 - val_loss: 0.3491 - val_accuracy: 0.8494\n",
      "Epoch 280/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8731 - val_loss: 0.3495 - val_accuracy: 0.8506\n",
      "Epoch 281/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3102 - accuracy: 0.8723 - val_loss: 0.3493 - val_accuracy: 0.8500\n",
      "Epoch 282/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3103 - accuracy: 0.8716 - val_loss: 0.3513 - val_accuracy: 0.8494\n",
      "Epoch 283/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3104 - accuracy: 0.8708 - val_loss: 0.3499 - val_accuracy: 0.8500\n",
      "Epoch 284/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8723 - val_loss: 0.3511 - val_accuracy: 0.8519\n",
      "Epoch 285/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8719 - val_loss: 0.3502 - val_accuracy: 0.8500\n",
      "Epoch 286/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8731 - val_loss: 0.3521 - val_accuracy: 0.8512\n",
      "Epoch 287/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8709 - val_loss: 0.3510 - val_accuracy: 0.8487\n",
      "Epoch 288/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8720 - val_loss: 0.3498 - val_accuracy: 0.8512\n",
      "Epoch 289/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8728 - val_loss: 0.3499 - val_accuracy: 0.8462\n",
      "Epoch 290/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8723 - val_loss: 0.3490 - val_accuracy: 0.8525\n",
      "Epoch 291/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8727 - val_loss: 0.3521 - val_accuracy: 0.8481\n",
      "Epoch 292/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8717 - val_loss: 0.3501 - val_accuracy: 0.8506\n",
      "Epoch 293/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8727 - val_loss: 0.3505 - val_accuracy: 0.8519\n",
      "Epoch 294/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8714 - val_loss: 0.3511 - val_accuracy: 0.8506\n",
      "Epoch 295/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8709 - val_loss: 0.3511 - val_accuracy: 0.8525\n",
      "Epoch 296/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8741 - val_loss: 0.3499 - val_accuracy: 0.8506\n",
      "Epoch 297/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8731 - val_loss: 0.3513 - val_accuracy: 0.8481\n",
      "Epoch 298/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8714 - val_loss: 0.3518 - val_accuracy: 0.8487\n",
      "Epoch 299/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8723 - val_loss: 0.3526 - val_accuracy: 0.8500\n",
      "Epoch 300/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8739 - val_loss: 0.3519 - val_accuracy: 0.8456\n",
      "Epoch 301/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8716 - val_loss: 0.3507 - val_accuracy: 0.8481\n",
      "Epoch 302/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8719 - val_loss: 0.3498 - val_accuracy: 0.8519\n",
      "Epoch 303/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8714 - val_loss: 0.3501 - val_accuracy: 0.8506\n",
      "Epoch 304/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8725 - val_loss: 0.3507 - val_accuracy: 0.8487\n",
      "Epoch 305/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8736 - val_loss: 0.3548 - val_accuracy: 0.8481\n",
      "Epoch 306/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8716 - val_loss: 0.3504 - val_accuracy: 0.8525\n",
      "Epoch 307/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8723 - val_loss: 0.3506 - val_accuracy: 0.8487\n",
      "Epoch 308/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8722 - val_loss: 0.3500 - val_accuracy: 0.8512\n",
      "Epoch 309/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8722 - val_loss: 0.3543 - val_accuracy: 0.8444\n",
      "Epoch 310/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8727 - val_loss: 0.3495 - val_accuracy: 0.8500\n",
      "Epoch 311/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8720 - val_loss: 0.3501 - val_accuracy: 0.8506\n",
      "Epoch 312/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8727 - val_loss: 0.3502 - val_accuracy: 0.8512\n",
      "Epoch 313/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8723 - val_loss: 0.3511 - val_accuracy: 0.8512\n",
      "Epoch 314/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8709 - val_loss: 0.3499 - val_accuracy: 0.8500\n",
      "Epoch 315/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8736 - val_loss: 0.3505 - val_accuracy: 0.8512\n",
      "Epoch 316/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8741 - val_loss: 0.3518 - val_accuracy: 0.8500\n",
      "Epoch 317/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8727 - val_loss: 0.3516 - val_accuracy: 0.8500\n",
      "Epoch 318/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8702 - val_loss: 0.3517 - val_accuracy: 0.8487\n",
      "Epoch 319/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8712 - val_loss: 0.3513 - val_accuracy: 0.8481\n",
      "Epoch 320/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8725 - val_loss: 0.3498 - val_accuracy: 0.8512\n",
      "Epoch 321/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8711 - val_loss: 0.3520 - val_accuracy: 0.8487\n",
      "Epoch 322/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8728 - val_loss: 0.3519 - val_accuracy: 0.8487\n",
      "Epoch 323/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8720 - val_loss: 0.3508 - val_accuracy: 0.8494\n",
      "Epoch 324/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8709 - val_loss: 0.3503 - val_accuracy: 0.8525\n",
      "Epoch 325/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8722 - val_loss: 0.3505 - val_accuracy: 0.8481\n",
      "Epoch 326/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8703 - val_loss: 0.3509 - val_accuracy: 0.8512\n",
      "Epoch 327/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8727 - val_loss: 0.3527 - val_accuracy: 0.8462\n",
      "Epoch 328/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8684 - val_loss: 0.3507 - val_accuracy: 0.8519\n",
      "Epoch 329/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8714 - val_loss: 0.3499 - val_accuracy: 0.8512\n",
      "Epoch 330/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8728 - val_loss: 0.3520 - val_accuracy: 0.8494\n",
      "Epoch 331/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8712 - val_loss: 0.3519 - val_accuracy: 0.8506\n",
      "Epoch 332/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8725 - val_loss: 0.3508 - val_accuracy: 0.8531\n",
      "Epoch 333/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3095 - accuracy: 0.8731 - val_loss: 0.3523 - val_accuracy: 0.8512\n",
      "Epoch 334/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3094 - accuracy: 0.8717 - val_loss: 0.3515 - val_accuracy: 0.8481\n",
      "Epoch 335/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8712 - val_loss: 0.3496 - val_accuracy: 0.8537\n",
      "Epoch 336/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8736 - val_loss: 0.3495 - val_accuracy: 0.8537\n",
      "Epoch 337/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3091 - accuracy: 0.8705 - val_loss: 0.3521 - val_accuracy: 0.8500\n",
      "Epoch 338/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8711 - val_loss: 0.3511 - val_accuracy: 0.8506\n",
      "Epoch 339/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8727 - val_loss: 0.3535 - val_accuracy: 0.8475\n",
      "Epoch 340/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8712 - val_loss: 0.3541 - val_accuracy: 0.8469\n",
      "Epoch 341/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8709 - val_loss: 0.3501 - val_accuracy: 0.8519\n",
      "Epoch 342/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8719 - val_loss: 0.3532 - val_accuracy: 0.8494\n",
      "Epoch 343/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8719 - val_loss: 0.3542 - val_accuracy: 0.8462\n",
      "Epoch 344/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8709 - val_loss: 0.3506 - val_accuracy: 0.8531\n",
      "Epoch 345/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8705 - val_loss: 0.3491 - val_accuracy: 0.8537\n",
      "Epoch 346/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8734 - val_loss: 0.3528 - val_accuracy: 0.8469\n",
      "Epoch 347/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8714 - val_loss: 0.3505 - val_accuracy: 0.8537\n",
      "Epoch 348/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8708 - val_loss: 0.3520 - val_accuracy: 0.8500\n",
      "Epoch 349/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8708 - val_loss: 0.3506 - val_accuracy: 0.8519\n",
      "Epoch 350/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8728 - val_loss: 0.3558 - val_accuracy: 0.8469\n",
      "Epoch 351/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8716 - val_loss: 0.3510 - val_accuracy: 0.8544\n",
      "Epoch 352/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8739 - val_loss: 0.3573 - val_accuracy: 0.8494\n",
      "Epoch 353/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8736 - val_loss: 0.3509 - val_accuracy: 0.8506\n",
      "Epoch 354/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8702 - val_loss: 0.3534 - val_accuracy: 0.8531\n",
      "Epoch 355/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3095 - accuracy: 0.8712 - val_loss: 0.3508 - val_accuracy: 0.8519\n",
      "Epoch 356/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8733 - val_loss: 0.3555 - val_accuracy: 0.8462\n",
      "Epoch 357/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8725 - val_loss: 0.3501 - val_accuracy: 0.8519\n",
      "Epoch 358/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8712 - val_loss: 0.3500 - val_accuracy: 0.8544\n",
      "Epoch 359/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8722 - val_loss: 0.3512 - val_accuracy: 0.8481\n",
      "Epoch 360/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8722 - val_loss: 0.3506 - val_accuracy: 0.8512\n",
      "Epoch 361/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8706 - val_loss: 0.3516 - val_accuracy: 0.8519\n",
      "Epoch 362/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3089 - accuracy: 0.8734 - val_loss: 0.3508 - val_accuracy: 0.8525\n",
      "Epoch 363/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8712 - val_loss: 0.3508 - val_accuracy: 0.8531\n",
      "Epoch 364/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8712 - val_loss: 0.3518 - val_accuracy: 0.8519\n",
      "Epoch 365/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8716 - val_loss: 0.3540 - val_accuracy: 0.8481\n",
      "Epoch 366/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8747 - val_loss: 0.3558 - val_accuracy: 0.8450\n",
      "Epoch 367/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8725 - val_loss: 0.3521 - val_accuracy: 0.8537\n",
      "Epoch 368/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8742 - val_loss: 0.3497 - val_accuracy: 0.8537\n",
      "Epoch 369/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8722 - val_loss: 0.3498 - val_accuracy: 0.8537\n",
      "Epoch 370/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8727 - val_loss: 0.3503 - val_accuracy: 0.8556\n",
      "Epoch 371/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8711 - val_loss: 0.3508 - val_accuracy: 0.8506\n",
      "Epoch 372/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8703 - val_loss: 0.3507 - val_accuracy: 0.8537\n",
      "Epoch 373/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8731 - val_loss: 0.3530 - val_accuracy: 0.8550\n",
      "Epoch 374/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8706 - val_loss: 0.3514 - val_accuracy: 0.8525\n",
      "Epoch 375/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8717 - val_loss: 0.3521 - val_accuracy: 0.8481\n",
      "Epoch 376/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8725 - val_loss: 0.3515 - val_accuracy: 0.8519\n",
      "Epoch 377/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8736 - val_loss: 0.3524 - val_accuracy: 0.8500\n",
      "Epoch 378/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8720 - val_loss: 0.3510 - val_accuracy: 0.8531\n",
      "Epoch 379/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8733 - val_loss: 0.3526 - val_accuracy: 0.8512\n",
      "Epoch 380/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8712 - val_loss: 0.3504 - val_accuracy: 0.8512\n",
      "Epoch 381/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8727 - val_loss: 0.3509 - val_accuracy: 0.8525\n",
      "Epoch 382/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8719 - val_loss: 0.3518 - val_accuracy: 0.8512\n",
      "Epoch 383/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8722 - val_loss: 0.3519 - val_accuracy: 0.8512\n",
      "Epoch 384/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8698 - val_loss: 0.3517 - val_accuracy: 0.8512\n",
      "Epoch 385/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8728 - val_loss: 0.3523 - val_accuracy: 0.8544\n",
      "Epoch 386/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8734 - val_loss: 0.3509 - val_accuracy: 0.8525\n",
      "Epoch 387/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8728 - val_loss: 0.3513 - val_accuracy: 0.8500\n",
      "Epoch 388/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8741 - val_loss: 0.3519 - val_accuracy: 0.8500\n",
      "Epoch 389/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8717 - val_loss: 0.3509 - val_accuracy: 0.8550\n",
      "Epoch 390/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3096 - accuracy: 0.8711 - val_loss: 0.3511 - val_accuracy: 0.8531\n",
      "Epoch 391/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8703 - val_loss: 0.3510 - val_accuracy: 0.8562\n",
      "Epoch 392/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8708 - val_loss: 0.3511 - val_accuracy: 0.8506\n",
      "Epoch 393/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8725 - val_loss: 0.3508 - val_accuracy: 0.8519\n",
      "Epoch 394/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8723 - val_loss: 0.3508 - val_accuracy: 0.8531\n",
      "Epoch 395/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8717 - val_loss: 0.3511 - val_accuracy: 0.8512\n",
      "Epoch 396/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8725 - val_loss: 0.3512 - val_accuracy: 0.8531\n",
      "Epoch 397/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8703 - val_loss: 0.3534 - val_accuracy: 0.8500\n",
      "Epoch 398/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8712 - val_loss: 0.3497 - val_accuracy: 0.8512\n",
      "Epoch 399/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3090 - accuracy: 0.8714 - val_loss: 0.3511 - val_accuracy: 0.8531\n",
      "Epoch 400/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3090 - accuracy: 0.8730 - val_loss: 0.3532 - val_accuracy: 0.8487\n",
      "Epoch 401/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8711 - val_loss: 0.3506 - val_accuracy: 0.8506\n",
      "Epoch 402/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8714 - val_loss: 0.3502 - val_accuracy: 0.8537\n",
      "Epoch 403/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8722 - val_loss: 0.3515 - val_accuracy: 0.8525\n",
      "Epoch 404/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8731 - val_loss: 0.3566 - val_accuracy: 0.8469\n",
      "Epoch 405/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8719 - val_loss: 0.3519 - val_accuracy: 0.8500\n",
      "Epoch 406/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8737 - val_loss: 0.3501 - val_accuracy: 0.8512\n",
      "Epoch 407/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8709 - val_loss: 0.3511 - val_accuracy: 0.8512\n",
      "Epoch 408/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8706 - val_loss: 0.3501 - val_accuracy: 0.8519\n",
      "Epoch 409/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8720 - val_loss: 0.3520 - val_accuracy: 0.8512\n",
      "Epoch 410/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8727 - val_loss: 0.3503 - val_accuracy: 0.8519\n",
      "Epoch 411/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8733 - val_loss: 0.3512 - val_accuracy: 0.8506\n",
      "Epoch 412/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8725 - val_loss: 0.3538 - val_accuracy: 0.8462\n",
      "Epoch 413/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8722 - val_loss: 0.3527 - val_accuracy: 0.8519\n",
      "Epoch 414/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8711 - val_loss: 0.3541 - val_accuracy: 0.8525\n",
      "Epoch 415/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8728 - val_loss: 0.3505 - val_accuracy: 0.8537\n",
      "Epoch 416/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8728 - val_loss: 0.3525 - val_accuracy: 0.8481\n",
      "Epoch 417/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8712 - val_loss: 0.3517 - val_accuracy: 0.8525\n",
      "Epoch 418/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8712 - val_loss: 0.3520 - val_accuracy: 0.8550\n",
      "Epoch 419/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8720 - val_loss: 0.3512 - val_accuracy: 0.8525\n",
      "Epoch 420/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8723 - val_loss: 0.3546 - val_accuracy: 0.8512\n",
      "Epoch 421/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8711 - val_loss: 0.3498 - val_accuracy: 0.8525\n",
      "Epoch 422/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8722 - val_loss: 0.3534 - val_accuracy: 0.8506\n",
      "Epoch 423/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8730 - val_loss: 0.3517 - val_accuracy: 0.8462\n",
      "Epoch 424/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8722 - val_loss: 0.3514 - val_accuracy: 0.8537\n",
      "Epoch 425/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8731 - val_loss: 0.3508 - val_accuracy: 0.8500\n",
      "Epoch 426/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8705 - val_loss: 0.3515 - val_accuracy: 0.8537\n",
      "Epoch 427/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8734 - val_loss: 0.3512 - val_accuracy: 0.8519\n",
      "Epoch 428/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8719 - val_loss: 0.3520 - val_accuracy: 0.8531\n",
      "Epoch 429/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8725 - val_loss: 0.3524 - val_accuracy: 0.8506\n",
      "Epoch 430/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8720 - val_loss: 0.3524 - val_accuracy: 0.8525\n",
      "Epoch 431/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8697 - val_loss: 0.3535 - val_accuracy: 0.8525\n",
      "Epoch 432/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8714 - val_loss: 0.3529 - val_accuracy: 0.8512\n",
      "Epoch 433/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8727 - val_loss: 0.3508 - val_accuracy: 0.8525\n",
      "Epoch 434/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8741 - val_loss: 0.3521 - val_accuracy: 0.8506\n",
      "Epoch 435/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8720 - val_loss: 0.3516 - val_accuracy: 0.8512\n",
      "Epoch 436/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8737 - val_loss: 0.3518 - val_accuracy: 0.8531\n",
      "Epoch 437/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8711 - val_loss: 0.3518 - val_accuracy: 0.8550\n",
      "Epoch 438/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8714 - val_loss: 0.3522 - val_accuracy: 0.8506\n",
      "Epoch 439/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8720 - val_loss: 0.3521 - val_accuracy: 0.8537\n",
      "Epoch 440/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8720 - val_loss: 0.3517 - val_accuracy: 0.8519\n",
      "Epoch 441/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8727 - val_loss: 0.3518 - val_accuracy: 0.8537\n",
      "Epoch 442/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8736 - val_loss: 0.3499 - val_accuracy: 0.8506\n",
      "Epoch 443/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8709 - val_loss: 0.3511 - val_accuracy: 0.8500\n",
      "Epoch 444/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8727 - val_loss: 0.3495 - val_accuracy: 0.8544\n",
      "Epoch 445/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8723 - val_loss: 0.3521 - val_accuracy: 0.8519\n",
      "Epoch 446/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8720 - val_loss: 0.3525 - val_accuracy: 0.8500\n",
      "Epoch 447/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8739 - val_loss: 0.3524 - val_accuracy: 0.8519\n",
      "Epoch 448/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8717 - val_loss: 0.3509 - val_accuracy: 0.8525\n",
      "Epoch 449/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.3089 - accuracy: 0.8727 - val_loss: 0.3515 - val_accuracy: 0.8519\n",
      "Epoch 450/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3081 - accuracy: 0.8730 - val_loss: 0.3512 - val_accuracy: 0.8512\n",
      "Epoch 451/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3078 - accuracy: 0.8723 - val_loss: 0.3541 - val_accuracy: 0.8487\n",
      "Epoch 452/1000\n",
      "200/200 [==============================] - 0s 3ms/step - loss: 0.3081 - accuracy: 0.8720 - val_loss: 0.3517 - val_accuracy: 0.8469\n",
      "Epoch 453/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8716 - val_loss: 0.3513 - val_accuracy: 0.8512\n",
      "Epoch 454/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8737 - val_loss: 0.3508 - val_accuracy: 0.8512\n",
      "Epoch 455/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8742 - val_loss: 0.3538 - val_accuracy: 0.8494\n",
      "Epoch 456/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8720 - val_loss: 0.3520 - val_accuracy: 0.8519\n",
      "Epoch 457/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3080 - accuracy: 0.8748 - val_loss: 0.3514 - val_accuracy: 0.8544\n",
      "Epoch 458/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8734 - val_loss: 0.3508 - val_accuracy: 0.8469\n",
      "Epoch 459/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8736 - val_loss: 0.3528 - val_accuracy: 0.8481\n",
      "Epoch 460/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8734 - val_loss: 0.3506 - val_accuracy: 0.8537\n",
      "Epoch 461/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8702 - val_loss: 0.3521 - val_accuracy: 0.8525\n",
      "Epoch 462/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8717 - val_loss: 0.3524 - val_accuracy: 0.8519\n",
      "Epoch 463/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8748 - val_loss: 0.3508 - val_accuracy: 0.8481\n",
      "Epoch 464/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8709 - val_loss: 0.3498 - val_accuracy: 0.8500\n",
      "Epoch 465/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8758 - val_loss: 0.3538 - val_accuracy: 0.8506\n",
      "Epoch 466/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8714 - val_loss: 0.3507 - val_accuracy: 0.8506\n",
      "Epoch 467/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8719 - val_loss: 0.3522 - val_accuracy: 0.8537\n",
      "Epoch 468/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8736 - val_loss: 0.3519 - val_accuracy: 0.8512\n",
      "Epoch 469/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8717 - val_loss: 0.3515 - val_accuracy: 0.8519\n",
      "Epoch 470/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8737 - val_loss: 0.3554 - val_accuracy: 0.8494\n",
      "Epoch 471/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3081 - accuracy: 0.8745 - val_loss: 0.3510 - val_accuracy: 0.8525\n",
      "Epoch 472/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8711 - val_loss: 0.3532 - val_accuracy: 0.8506\n",
      "Epoch 473/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3082 - accuracy: 0.8725 - val_loss: 0.3523 - val_accuracy: 0.8494\n",
      "Epoch 474/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8736 - val_loss: 0.3515 - val_accuracy: 0.8525\n",
      "Epoch 475/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8753 - val_loss: 0.3514 - val_accuracy: 0.8525\n",
      "Epoch 476/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8730 - val_loss: 0.3508 - val_accuracy: 0.8475\n",
      "Epoch 477/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3081 - accuracy: 0.8744 - val_loss: 0.3534 - val_accuracy: 0.8475\n",
      "Epoch 478/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8745 - val_loss: 0.3507 - val_accuracy: 0.8525\n",
      "Epoch 479/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8739 - val_loss: 0.3522 - val_accuracy: 0.8531\n",
      "Epoch 480/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8737 - val_loss: 0.3530 - val_accuracy: 0.8512\n",
      "Epoch 481/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8742 - val_loss: 0.3549 - val_accuracy: 0.8512\n",
      "Epoch 482/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8711 - val_loss: 0.3509 - val_accuracy: 0.8525\n",
      "Epoch 483/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8734 - val_loss: 0.3509 - val_accuracy: 0.8506\n",
      "Epoch 484/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8730 - val_loss: 0.3525 - val_accuracy: 0.8519\n",
      "Epoch 485/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8722 - val_loss: 0.3517 - val_accuracy: 0.8494\n",
      "Epoch 486/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8752 - val_loss: 0.3521 - val_accuracy: 0.8519\n",
      "Epoch 487/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8733 - val_loss: 0.3538 - val_accuracy: 0.8500\n",
      "Epoch 488/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8733 - val_loss: 0.3511 - val_accuracy: 0.8519\n",
      "Epoch 489/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8731 - val_loss: 0.3530 - val_accuracy: 0.8487\n",
      "Epoch 490/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8736 - val_loss: 0.3524 - val_accuracy: 0.8537\n",
      "Epoch 491/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8745 - val_loss: 0.3521 - val_accuracy: 0.8500\n",
      "Epoch 492/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8728 - val_loss: 0.3499 - val_accuracy: 0.8494\n",
      "Epoch 493/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8714 - val_loss: 0.3516 - val_accuracy: 0.8494\n",
      "Epoch 494/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8741 - val_loss: 0.3503 - val_accuracy: 0.8494\n",
      "Epoch 495/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8739 - val_loss: 0.3504 - val_accuracy: 0.8544\n",
      "Epoch 496/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8730 - val_loss: 0.3514 - val_accuracy: 0.8525\n",
      "Epoch 497/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8728 - val_loss: 0.3518 - val_accuracy: 0.8544\n",
      "Epoch 498/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8731 - val_loss: 0.3569 - val_accuracy: 0.8475\n",
      "Epoch 499/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8731 - val_loss: 0.3513 - val_accuracy: 0.8487\n",
      "Epoch 500/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3077 - accuracy: 0.8747 - val_loss: 0.3494 - val_accuracy: 0.8519\n",
      "Epoch 501/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8741 - val_loss: 0.3508 - val_accuracy: 0.8519\n",
      "Epoch 502/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8731 - val_loss: 0.3520 - val_accuracy: 0.8512\n",
      "Epoch 503/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8717 - val_loss: 0.3512 - val_accuracy: 0.8525\n",
      "Epoch 504/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8719 - val_loss: 0.3510 - val_accuracy: 0.8544\n",
      "Epoch 505/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8728 - val_loss: 0.3515 - val_accuracy: 0.8531\n",
      "Epoch 506/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8725 - val_loss: 0.3512 - val_accuracy: 0.8525\n",
      "Epoch 507/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8720 - val_loss: 0.3503 - val_accuracy: 0.8506\n",
      "Epoch 508/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8744 - val_loss: 0.3534 - val_accuracy: 0.8500\n",
      "Epoch 509/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8722 - val_loss: 0.3502 - val_accuracy: 0.8500\n",
      "Epoch 510/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8727 - val_loss: 0.3545 - val_accuracy: 0.8494\n",
      "Epoch 511/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8744 - val_loss: 0.3531 - val_accuracy: 0.8556\n",
      "Epoch 512/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3073 - accuracy: 0.8709 - val_loss: 0.3520 - val_accuracy: 0.8519\n",
      "Epoch 513/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3077 - accuracy: 0.8736 - val_loss: 0.3521 - val_accuracy: 0.8500\n",
      "Epoch 514/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3080 - accuracy: 0.8730 - val_loss: 0.3510 - val_accuracy: 0.8544\n",
      "Epoch 515/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8737 - val_loss: 0.3509 - val_accuracy: 0.8475\n",
      "Epoch 516/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8733 - val_loss: 0.3508 - val_accuracy: 0.8537\n",
      "Epoch 517/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8753 - val_loss: 0.3507 - val_accuracy: 0.8481\n",
      "Epoch 518/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8742 - val_loss: 0.3554 - val_accuracy: 0.8469\n",
      "Epoch 519/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8727 - val_loss: 0.3501 - val_accuracy: 0.8512\n",
      "Epoch 520/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8731 - val_loss: 0.3545 - val_accuracy: 0.8475\n",
      "Epoch 521/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8733 - val_loss: 0.3519 - val_accuracy: 0.8506\n",
      "Epoch 522/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8723 - val_loss: 0.3504 - val_accuracy: 0.8512\n",
      "Epoch 523/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8741 - val_loss: 0.3541 - val_accuracy: 0.8469\n",
      "Epoch 524/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8730 - val_loss: 0.3508 - val_accuracy: 0.8512\n",
      "Epoch 525/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8747 - val_loss: 0.3520 - val_accuracy: 0.8531\n",
      "Epoch 526/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8727 - val_loss: 0.3517 - val_accuracy: 0.8525\n",
      "Epoch 527/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8750 - val_loss: 0.3536 - val_accuracy: 0.8481\n",
      "Epoch 528/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8725 - val_loss: 0.3520 - val_accuracy: 0.8506\n",
      "Epoch 529/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8723 - val_loss: 0.3511 - val_accuracy: 0.8519\n",
      "Epoch 530/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8772 - val_loss: 0.3524 - val_accuracy: 0.8494\n",
      "Epoch 531/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8737 - val_loss: 0.3515 - val_accuracy: 0.8525\n",
      "Epoch 532/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8712 - val_loss: 0.3508 - val_accuracy: 0.8537\n",
      "Epoch 533/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8744 - val_loss: 0.3514 - val_accuracy: 0.8494\n",
      "Epoch 534/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8733 - val_loss: 0.3511 - val_accuracy: 0.8494\n",
      "Epoch 535/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8736 - val_loss: 0.3508 - val_accuracy: 0.8506\n",
      "Epoch 536/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3073 - accuracy: 0.8728 - val_loss: 0.3513 - val_accuracy: 0.8512\n",
      "Epoch 537/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8712 - val_loss: 0.3529 - val_accuracy: 0.8519\n",
      "Epoch 538/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8736 - val_loss: 0.3543 - val_accuracy: 0.8494\n",
      "Epoch 539/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8734 - val_loss: 0.3510 - val_accuracy: 0.8525\n",
      "Epoch 540/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8753 - val_loss: 0.3517 - val_accuracy: 0.8531\n",
      "Epoch 541/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8728 - val_loss: 0.3531 - val_accuracy: 0.8537\n",
      "Epoch 542/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8731 - val_loss: 0.3511 - val_accuracy: 0.8481\n",
      "Epoch 543/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8733 - val_loss: 0.3513 - val_accuracy: 0.8487\n",
      "Epoch 544/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8734 - val_loss: 0.3506 - val_accuracy: 0.8487\n",
      "Epoch 545/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8756 - val_loss: 0.3536 - val_accuracy: 0.8506\n",
      "Epoch 546/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8736 - val_loss: 0.3522 - val_accuracy: 0.8487\n",
      "Epoch 547/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8739 - val_loss: 0.3532 - val_accuracy: 0.8525\n",
      "Epoch 548/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8736 - val_loss: 0.3513 - val_accuracy: 0.8487\n",
      "Epoch 549/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8734 - val_loss: 0.3513 - val_accuracy: 0.8506\n",
      "Epoch 550/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8734 - val_loss: 0.3509 - val_accuracy: 0.8487\n",
      "Epoch 551/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8727 - val_loss: 0.3514 - val_accuracy: 0.8469\n",
      "Epoch 552/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3073 - accuracy: 0.8742 - val_loss: 0.3517 - val_accuracy: 0.8537\n",
      "Epoch 553/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8748 - val_loss: 0.3541 - val_accuracy: 0.8512\n",
      "Epoch 554/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8736 - val_loss: 0.3534 - val_accuracy: 0.8494\n",
      "Epoch 555/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3080 - accuracy: 0.8734 - val_loss: 0.3522 - val_accuracy: 0.8500\n",
      "Epoch 556/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3075 - accuracy: 0.8747 - val_loss: 0.3501 - val_accuracy: 0.8500\n",
      "Epoch 557/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8772 - val_loss: 0.3537 - val_accuracy: 0.8462\n",
      "Epoch 558/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8733 - val_loss: 0.3506 - val_accuracy: 0.8500\n",
      "Epoch 559/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3076 - accuracy: 0.8737 - val_loss: 0.3497 - val_accuracy: 0.8525\n",
      "Epoch 560/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3074 - accuracy: 0.8748 - val_loss: 0.3505 - val_accuracy: 0.8519\n",
      "Epoch 561/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8739 - val_loss: 0.3517 - val_accuracy: 0.8487\n",
      "Epoch 562/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8719 - val_loss: 0.3510 - val_accuracy: 0.8506\n",
      "Epoch 563/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3079 - accuracy: 0.8717 - val_loss: 0.3523 - val_accuracy: 0.8500\n",
      "Epoch 564/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3075 - accuracy: 0.8739 - val_loss: 0.3515 - val_accuracy: 0.8494\n",
      "Epoch 565/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8731 - val_loss: 0.3503 - val_accuracy: 0.8506\n",
      "Epoch 566/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8742 - val_loss: 0.3505 - val_accuracy: 0.8494\n",
      "Epoch 567/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8737 - val_loss: 0.3509 - val_accuracy: 0.8500\n",
      "Epoch 568/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8737 - val_loss: 0.3516 - val_accuracy: 0.8519\n",
      "Epoch 569/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8730 - val_loss: 0.3516 - val_accuracy: 0.8506\n",
      "Epoch 570/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8753 - val_loss: 0.3519 - val_accuracy: 0.8475\n",
      "Epoch 571/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8763 - val_loss: 0.3558 - val_accuracy: 0.8512\n",
      "Epoch 572/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8741 - val_loss: 0.3501 - val_accuracy: 0.8487\n",
      "Epoch 573/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8744 - val_loss: 0.3514 - val_accuracy: 0.8462\n",
      "Epoch 574/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8742 - val_loss: 0.3506 - val_accuracy: 0.8500\n",
      "Epoch 575/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8737 - val_loss: 0.3511 - val_accuracy: 0.8500\n",
      "Epoch 576/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8756 - val_loss: 0.3563 - val_accuracy: 0.8487\n",
      "Epoch 577/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8730 - val_loss: 0.3520 - val_accuracy: 0.8506\n",
      "Epoch 578/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8747 - val_loss: 0.3529 - val_accuracy: 0.8469\n",
      "Epoch 579/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8745 - val_loss: 0.3518 - val_accuracy: 0.8469\n",
      "Epoch 580/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8756 - val_loss: 0.3517 - val_accuracy: 0.8506\n",
      "Epoch 581/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8742 - val_loss: 0.3516 - val_accuracy: 0.8544\n",
      "Epoch 582/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8741 - val_loss: 0.3506 - val_accuracy: 0.8500\n",
      "Epoch 583/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8739 - val_loss: 0.3521 - val_accuracy: 0.8494\n",
      "Epoch 584/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8712 - val_loss: 0.3525 - val_accuracy: 0.8494\n",
      "Epoch 585/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8717 - val_loss: 0.3540 - val_accuracy: 0.8506\n",
      "Epoch 586/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8725 - val_loss: 0.3530 - val_accuracy: 0.8481\n",
      "Epoch 587/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8753 - val_loss: 0.3536 - val_accuracy: 0.8456\n",
      "Epoch 588/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3078 - accuracy: 0.8719 - val_loss: 0.3512 - val_accuracy: 0.8506\n",
      "Epoch 589/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8717 - val_loss: 0.3500 - val_accuracy: 0.8469\n",
      "Epoch 590/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3070 - accuracy: 0.8733 - val_loss: 0.3500 - val_accuracy: 0.8469\n",
      "Epoch 591/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8733 - val_loss: 0.3513 - val_accuracy: 0.8494\n",
      "Epoch 592/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8725 - val_loss: 0.3522 - val_accuracy: 0.8531\n",
      "Epoch 593/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8734 - val_loss: 0.3522 - val_accuracy: 0.8475\n",
      "Epoch 594/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8741 - val_loss: 0.3533 - val_accuracy: 0.8469\n",
      "Epoch 595/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8731 - val_loss: 0.3518 - val_accuracy: 0.8506\n",
      "Epoch 596/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8758 - val_loss: 0.3549 - val_accuracy: 0.8487\n",
      "Epoch 597/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8752 - val_loss: 0.3541 - val_accuracy: 0.8487\n",
      "Epoch 598/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8733 - val_loss: 0.3529 - val_accuracy: 0.8487\n",
      "Epoch 599/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8720 - val_loss: 0.3518 - val_accuracy: 0.8475\n",
      "Epoch 600/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8747 - val_loss: 0.3519 - val_accuracy: 0.8481\n",
      "Epoch 601/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8736 - val_loss: 0.3522 - val_accuracy: 0.8494\n",
      "Epoch 602/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8733 - val_loss: 0.3524 - val_accuracy: 0.8506\n",
      "Epoch 603/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8714 - val_loss: 0.3538 - val_accuracy: 0.8506\n",
      "Epoch 604/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8716 - val_loss: 0.3509 - val_accuracy: 0.8481\n",
      "Epoch 605/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8720 - val_loss: 0.3504 - val_accuracy: 0.8519\n",
      "Epoch 606/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8727 - val_loss: 0.3507 - val_accuracy: 0.8519\n",
      "Epoch 607/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8745 - val_loss: 0.3494 - val_accuracy: 0.8531\n",
      "Epoch 608/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8734 - val_loss: 0.3508 - val_accuracy: 0.8506\n",
      "Epoch 609/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8737 - val_loss: 0.3521 - val_accuracy: 0.8481\n",
      "Epoch 610/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8711 - val_loss: 0.3524 - val_accuracy: 0.8462\n",
      "Epoch 611/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8755 - val_loss: 0.3508 - val_accuracy: 0.8531\n",
      "Epoch 612/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8719 - val_loss: 0.3523 - val_accuracy: 0.8500\n",
      "Epoch 613/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8723 - val_loss: 0.3507 - val_accuracy: 0.8506\n",
      "Epoch 614/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8763 - val_loss: 0.3517 - val_accuracy: 0.8494\n",
      "Epoch 615/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8736 - val_loss: 0.3520 - val_accuracy: 0.8500\n",
      "Epoch 616/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3075 - accuracy: 0.8722 - val_loss: 0.3513 - val_accuracy: 0.8475\n",
      "Epoch 617/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3071 - accuracy: 0.8722 - val_loss: 0.3536 - val_accuracy: 0.8481\n",
      "Epoch 618/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8744 - val_loss: 0.3535 - val_accuracy: 0.8487\n",
      "Epoch 619/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8745 - val_loss: 0.3540 - val_accuracy: 0.8456\n",
      "Epoch 620/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8753 - val_loss: 0.3521 - val_accuracy: 0.8494\n",
      "Epoch 621/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8725 - val_loss: 0.3518 - val_accuracy: 0.8481\n",
      "Epoch 622/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8727 - val_loss: 0.3511 - val_accuracy: 0.8456\n",
      "Epoch 623/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8752 - val_loss: 0.3530 - val_accuracy: 0.8469\n",
      "Epoch 624/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8752 - val_loss: 0.3524 - val_accuracy: 0.8469\n",
      "Epoch 625/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8730 - val_loss: 0.3525 - val_accuracy: 0.8481\n",
      "Epoch 626/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3070 - accuracy: 0.8741 - val_loss: 0.3518 - val_accuracy: 0.8494\n",
      "Epoch 627/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8727 - val_loss: 0.3530 - val_accuracy: 0.8519\n",
      "Epoch 628/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3071 - accuracy: 0.8748 - val_loss: 0.3514 - val_accuracy: 0.8494\n",
      "Epoch 629/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8727 - val_loss: 0.3517 - val_accuracy: 0.8481\n",
      "Epoch 630/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8745 - val_loss: 0.3519 - val_accuracy: 0.8506\n",
      "Epoch 631/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3064 - accuracy: 0.8737 - val_loss: 0.3536 - val_accuracy: 0.8494\n",
      "Epoch 632/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8755 - val_loss: 0.3517 - val_accuracy: 0.8494\n",
      "Epoch 633/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3064 - accuracy: 0.8741 - val_loss: 0.3523 - val_accuracy: 0.8494\n",
      "Epoch 634/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3071 - accuracy: 0.8745 - val_loss: 0.3538 - val_accuracy: 0.8487\n",
      "Epoch 635/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8737 - val_loss: 0.3523 - val_accuracy: 0.8506\n",
      "Epoch 636/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8730 - val_loss: 0.3525 - val_accuracy: 0.8475\n",
      "Epoch 637/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8736 - val_loss: 0.3527 - val_accuracy: 0.8500\n",
      "Epoch 638/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8719 - val_loss: 0.3524 - val_accuracy: 0.8481\n",
      "Epoch 639/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8727 - val_loss: 0.3501 - val_accuracy: 0.8512\n",
      "Epoch 640/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8725 - val_loss: 0.3527 - val_accuracy: 0.8537\n",
      "Epoch 641/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3067 - accuracy: 0.8761 - val_loss: 0.3518 - val_accuracy: 0.8500\n",
      "Epoch 642/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8736 - val_loss: 0.3521 - val_accuracy: 0.8469\n",
      "Epoch 643/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8744 - val_loss: 0.3509 - val_accuracy: 0.8462\n",
      "Epoch 644/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3068 - accuracy: 0.8737 - val_loss: 0.3511 - val_accuracy: 0.8500\n",
      "Epoch 645/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3064 - accuracy: 0.8733 - val_loss: 0.3533 - val_accuracy: 0.8506\n",
      "Epoch 646/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8750 - val_loss: 0.3518 - val_accuracy: 0.8481\n",
      "Epoch 647/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3068 - accuracy: 0.8739 - val_loss: 0.3521 - val_accuracy: 0.8531\n",
      "Epoch 648/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8719 - val_loss: 0.3524 - val_accuracy: 0.8500\n",
      "Epoch 649/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8737 - val_loss: 0.3523 - val_accuracy: 0.8475\n",
      "Epoch 650/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8750 - val_loss: 0.3516 - val_accuracy: 0.8494\n",
      "Epoch 651/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8745 - val_loss: 0.3521 - val_accuracy: 0.8537\n",
      "Epoch 652/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8712 - val_loss: 0.3530 - val_accuracy: 0.8494\n",
      "Epoch 653/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8741 - val_loss: 0.3515 - val_accuracy: 0.8494\n",
      "Epoch 654/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3071 - accuracy: 0.8745 - val_loss: 0.3549 - val_accuracy: 0.8487\n",
      "Epoch 655/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8734 - val_loss: 0.3519 - val_accuracy: 0.8469\n",
      "Epoch 656/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8739 - val_loss: 0.3496 - val_accuracy: 0.8506\n",
      "Epoch 657/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8733 - val_loss: 0.3499 - val_accuracy: 0.8519\n",
      "Epoch 658/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8720 - val_loss: 0.3523 - val_accuracy: 0.8506\n",
      "Epoch 659/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8736 - val_loss: 0.3513 - val_accuracy: 0.8475\n",
      "Epoch 660/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8737 - val_loss: 0.3539 - val_accuracy: 0.8475\n",
      "Epoch 661/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8742 - val_loss: 0.3532 - val_accuracy: 0.8450\n",
      "Epoch 662/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3064 - accuracy: 0.8727 - val_loss: 0.3528 - val_accuracy: 0.8512\n",
      "Epoch 663/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8737 - val_loss: 0.3536 - val_accuracy: 0.8519\n",
      "Epoch 664/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8736 - val_loss: 0.3526 - val_accuracy: 0.8469\n",
      "Epoch 665/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8711 - val_loss: 0.3516 - val_accuracy: 0.8487\n",
      "Epoch 666/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8736 - val_loss: 0.3514 - val_accuracy: 0.8500\n",
      "Epoch 667/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8752 - val_loss: 0.3533 - val_accuracy: 0.8475\n",
      "Epoch 668/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8737 - val_loss: 0.3509 - val_accuracy: 0.8494\n",
      "Epoch 669/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8739 - val_loss: 0.3515 - val_accuracy: 0.8475\n",
      "Epoch 670/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8733 - val_loss: 0.3516 - val_accuracy: 0.8506\n",
      "Epoch 671/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8739 - val_loss: 0.3525 - val_accuracy: 0.8550\n",
      "Epoch 672/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8739 - val_loss: 0.3501 - val_accuracy: 0.8512\n",
      "Epoch 673/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8755 - val_loss: 0.3531 - val_accuracy: 0.8469\n",
      "Epoch 674/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3065 - accuracy: 0.8741 - val_loss: 0.3514 - val_accuracy: 0.8519\n",
      "Epoch 675/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8722 - val_loss: 0.3540 - val_accuracy: 0.8512\n",
      "Epoch 676/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8741 - val_loss: 0.3525 - val_accuracy: 0.8487\n",
      "Epoch 677/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8719 - val_loss: 0.3506 - val_accuracy: 0.8506\n",
      "Epoch 678/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8747 - val_loss: 0.3514 - val_accuracy: 0.8506\n",
      "Epoch 679/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8733 - val_loss: 0.3523 - val_accuracy: 0.8506\n",
      "Epoch 680/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8722 - val_loss: 0.3529 - val_accuracy: 0.8494\n",
      "Epoch 681/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8737 - val_loss: 0.3558 - val_accuracy: 0.8537\n",
      "Epoch 682/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8723 - val_loss: 0.3556 - val_accuracy: 0.8512\n",
      "Epoch 683/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8748 - val_loss: 0.3496 - val_accuracy: 0.8519\n",
      "Epoch 684/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8756 - val_loss: 0.3512 - val_accuracy: 0.8500\n",
      "Epoch 685/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8741 - val_loss: 0.3522 - val_accuracy: 0.8500\n",
      "Epoch 686/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8730 - val_loss: 0.3529 - val_accuracy: 0.8487\n",
      "Epoch 687/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8739 - val_loss: 0.3511 - val_accuracy: 0.8475\n",
      "Epoch 688/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8736 - val_loss: 0.3501 - val_accuracy: 0.8494\n",
      "Epoch 689/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8725 - val_loss: 0.3520 - val_accuracy: 0.8500\n",
      "Epoch 690/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8734 - val_loss: 0.3529 - val_accuracy: 0.8475\n",
      "Epoch 691/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8741 - val_loss: 0.3535 - val_accuracy: 0.8469\n",
      "Epoch 692/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8720 - val_loss: 0.3512 - val_accuracy: 0.8494\n",
      "Epoch 693/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3068 - accuracy: 0.8731 - val_loss: 0.3515 - val_accuracy: 0.8487\n",
      "Epoch 694/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3069 - accuracy: 0.8753 - val_loss: 0.3494 - val_accuracy: 0.8500\n",
      "Epoch 695/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8731 - val_loss: 0.3515 - val_accuracy: 0.8494\n",
      "Epoch 696/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3064 - accuracy: 0.8742 - val_loss: 0.3515 - val_accuracy: 0.8500\n",
      "Epoch 697/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3067 - accuracy: 0.8739 - val_loss: 0.3499 - val_accuracy: 0.8506\n",
      "Epoch 698/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8736 - val_loss: 0.3525 - val_accuracy: 0.8481\n",
      "Epoch 699/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8752 - val_loss: 0.3518 - val_accuracy: 0.8500\n",
      "Epoch 700/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8750 - val_loss: 0.3518 - val_accuracy: 0.8487\n",
      "Epoch 701/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8728 - val_loss: 0.3495 - val_accuracy: 0.8525\n",
      "Epoch 702/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8761 - val_loss: 0.3520 - val_accuracy: 0.8487\n",
      "Epoch 703/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8739 - val_loss: 0.3518 - val_accuracy: 0.8506\n",
      "Epoch 704/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8722 - val_loss: 0.3567 - val_accuracy: 0.8506\n",
      "Epoch 705/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8750 - val_loss: 0.3539 - val_accuracy: 0.8469\n",
      "Epoch 706/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8734 - val_loss: 0.3542 - val_accuracy: 0.8519\n",
      "Epoch 707/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8725 - val_loss: 0.3533 - val_accuracy: 0.8487\n",
      "Epoch 708/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8731 - val_loss: 0.3496 - val_accuracy: 0.8494\n",
      "Epoch 709/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8758 - val_loss: 0.3510 - val_accuracy: 0.8525\n",
      "Epoch 710/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8714 - val_loss: 0.3508 - val_accuracy: 0.8481\n",
      "Epoch 711/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8719 - val_loss: 0.3512 - val_accuracy: 0.8481\n",
      "Epoch 712/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8747 - val_loss: 0.3533 - val_accuracy: 0.8475\n",
      "Epoch 713/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8736 - val_loss: 0.3505 - val_accuracy: 0.8475\n",
      "Epoch 714/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8742 - val_loss: 0.3522 - val_accuracy: 0.8512\n",
      "Epoch 715/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8733 - val_loss: 0.3526 - val_accuracy: 0.8512\n",
      "Epoch 716/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8730 - val_loss: 0.3531 - val_accuracy: 0.8431\n",
      "Epoch 717/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8748 - val_loss: 0.3521 - val_accuracy: 0.8469\n",
      "Epoch 718/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8720 - val_loss: 0.3518 - val_accuracy: 0.8481\n",
      "Epoch 719/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8720 - val_loss: 0.3510 - val_accuracy: 0.8481\n",
      "Epoch 720/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8739 - val_loss: 0.3503 - val_accuracy: 0.8512\n",
      "Epoch 721/1000\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.3069 - accuracy: 0.8736 - val_loss: 0.3519 - val_accuracy: 0.8494\n",
      "Epoch 722/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8734 - val_loss: 0.3504 - val_accuracy: 0.8525\n",
      "Epoch 723/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8737 - val_loss: 0.3522 - val_accuracy: 0.8519\n",
      "Epoch 724/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3065 - accuracy: 0.8712 - val_loss: 0.3536 - val_accuracy: 0.8487\n",
      "Epoch 725/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.3061 - accuracy: 0.8736 - val_loss: 0.3525 - val_accuracy: 0.8544\n",
      "Epoch 726/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8748 - val_loss: 0.3524 - val_accuracy: 0.8444\n",
      "Epoch 727/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8741 - val_loss: 0.3517 - val_accuracy: 0.8494\n",
      "Epoch 728/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8731 - val_loss: 0.3521 - val_accuracy: 0.8500\n",
      "Epoch 729/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8731 - val_loss: 0.3525 - val_accuracy: 0.8512\n",
      "Epoch 730/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8734 - val_loss: 0.3518 - val_accuracy: 0.8512\n",
      "Epoch 731/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8728 - val_loss: 0.3510 - val_accuracy: 0.8494\n",
      "Epoch 732/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8717 - val_loss: 0.3537 - val_accuracy: 0.8456\n",
      "Epoch 733/1000\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.3060 - accuracy: 0.8752 - val_loss: 0.3528 - val_accuracy: 0.8487\n",
      "Epoch 734/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8731 - val_loss: 0.3532 - val_accuracy: 0.8506\n",
      "Epoch 735/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8739 - val_loss: 0.3506 - val_accuracy: 0.8487\n",
      "Epoch 736/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8744 - val_loss: 0.3511 - val_accuracy: 0.8500\n",
      "Epoch 737/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8716 - val_loss: 0.3514 - val_accuracy: 0.8481\n",
      "Epoch 738/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8723 - val_loss: 0.3512 - val_accuracy: 0.8475\n",
      "Epoch 739/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3061 - accuracy: 0.8736 - val_loss: 0.3516 - val_accuracy: 0.8487\n",
      "Epoch 740/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8736 - val_loss: 0.3508 - val_accuracy: 0.8544\n",
      "Epoch 741/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3067 - accuracy: 0.8717 - val_loss: 0.3527 - val_accuracy: 0.8469\n",
      "Epoch 742/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8733 - val_loss: 0.3517 - val_accuracy: 0.8469\n",
      "Epoch 743/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3064 - accuracy: 0.8709 - val_loss: 0.3539 - val_accuracy: 0.8525\n",
      "Epoch 744/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8728 - val_loss: 0.3514 - val_accuracy: 0.8475\n",
      "Epoch 745/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8737 - val_loss: 0.3519 - val_accuracy: 0.8519\n",
      "Epoch 746/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8745 - val_loss: 0.3516 - val_accuracy: 0.8531\n",
      "Epoch 747/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8750 - val_loss: 0.3531 - val_accuracy: 0.8487\n",
      "Epoch 748/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8745 - val_loss: 0.3515 - val_accuracy: 0.8481\n",
      "Epoch 749/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8722 - val_loss: 0.3506 - val_accuracy: 0.8500\n",
      "Epoch 750/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8748 - val_loss: 0.3525 - val_accuracy: 0.8475\n",
      "Epoch 751/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8739 - val_loss: 0.3508 - val_accuracy: 0.8506\n",
      "Epoch 752/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3060 - accuracy: 0.8744 - val_loss: 0.3539 - val_accuracy: 0.8506\n",
      "Epoch 753/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3069 - accuracy: 0.8725 - val_loss: 0.3547 - val_accuracy: 0.8456\n",
      "Epoch 754/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8752 - val_loss: 0.3524 - val_accuracy: 0.8494\n",
      "Epoch 755/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8727 - val_loss: 0.3515 - val_accuracy: 0.8537\n",
      "Epoch 756/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8725 - val_loss: 0.3520 - val_accuracy: 0.8512\n",
      "Epoch 757/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8742 - val_loss: 0.3522 - val_accuracy: 0.8481\n",
      "Epoch 758/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8741 - val_loss: 0.3528 - val_accuracy: 0.8494\n",
      "Epoch 759/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8734 - val_loss: 0.3522 - val_accuracy: 0.8487\n",
      "Epoch 760/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8728 - val_loss: 0.3532 - val_accuracy: 0.8487\n",
      "Epoch 761/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8719 - val_loss: 0.3514 - val_accuracy: 0.8537\n",
      "Epoch 762/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8727 - val_loss: 0.3520 - val_accuracy: 0.8512\n",
      "Epoch 763/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8719 - val_loss: 0.3500 - val_accuracy: 0.8487\n",
      "Epoch 764/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8736 - val_loss: 0.3524 - val_accuracy: 0.8469\n",
      "Epoch 765/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8745 - val_loss: 0.3546 - val_accuracy: 0.8500\n",
      "Epoch 766/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8722 - val_loss: 0.3510 - val_accuracy: 0.8525\n",
      "Epoch 767/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8755 - val_loss: 0.3517 - val_accuracy: 0.8525\n",
      "Epoch 768/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8748 - val_loss: 0.3509 - val_accuracy: 0.8537\n",
      "Epoch 769/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8739 - val_loss: 0.3532 - val_accuracy: 0.8519\n",
      "Epoch 770/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8734 - val_loss: 0.3532 - val_accuracy: 0.8494\n",
      "Epoch 771/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8759 - val_loss: 0.3537 - val_accuracy: 0.8494\n",
      "Epoch 772/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8714 - val_loss: 0.3532 - val_accuracy: 0.8500\n",
      "Epoch 773/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8745 - val_loss: 0.3555 - val_accuracy: 0.8500\n",
      "Epoch 774/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8733 - val_loss: 0.3527 - val_accuracy: 0.8519\n",
      "Epoch 775/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8744 - val_loss: 0.3533 - val_accuracy: 0.8531\n",
      "Epoch 776/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8737 - val_loss: 0.3518 - val_accuracy: 0.8537\n",
      "Epoch 777/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8727 - val_loss: 0.3505 - val_accuracy: 0.8519\n",
      "Epoch 778/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8722 - val_loss: 0.3557 - val_accuracy: 0.8462\n",
      "Epoch 779/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8739 - val_loss: 0.3505 - val_accuracy: 0.8494\n",
      "Epoch 780/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8750 - val_loss: 0.3538 - val_accuracy: 0.8525\n",
      "Epoch 781/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8722 - val_loss: 0.3514 - val_accuracy: 0.8475\n",
      "Epoch 782/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8736 - val_loss: 0.3523 - val_accuracy: 0.8519\n",
      "Epoch 783/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8723 - val_loss: 0.3513 - val_accuracy: 0.8537\n",
      "Epoch 784/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8717 - val_loss: 0.3528 - val_accuracy: 0.8506\n",
      "Epoch 785/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8736 - val_loss: 0.3537 - val_accuracy: 0.8506\n",
      "Epoch 786/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8744 - val_loss: 0.3538 - val_accuracy: 0.8487\n",
      "Epoch 787/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8742 - val_loss: 0.3513 - val_accuracy: 0.8494\n",
      "Epoch 788/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8739 - val_loss: 0.3497 - val_accuracy: 0.8562\n",
      "Epoch 789/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8727 - val_loss: 0.3522 - val_accuracy: 0.8512\n",
      "Epoch 790/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8744 - val_loss: 0.3525 - val_accuracy: 0.8462\n",
      "Epoch 791/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8716 - val_loss: 0.3520 - val_accuracy: 0.8481\n",
      "Epoch 792/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8717 - val_loss: 0.3530 - val_accuracy: 0.8525\n",
      "Epoch 793/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8748 - val_loss: 0.3504 - val_accuracy: 0.8519\n",
      "Epoch 794/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8723 - val_loss: 0.3527 - val_accuracy: 0.8500\n",
      "Epoch 795/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8736 - val_loss: 0.3515 - val_accuracy: 0.8475\n",
      "Epoch 796/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8744 - val_loss: 0.3551 - val_accuracy: 0.8512\n",
      "Epoch 797/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8725 - val_loss: 0.3524 - val_accuracy: 0.8487\n",
      "Epoch 798/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8752 - val_loss: 0.3499 - val_accuracy: 0.8475\n",
      "Epoch 799/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3064 - accuracy: 0.8747 - val_loss: 0.3505 - val_accuracy: 0.8531\n",
      "Epoch 800/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8728 - val_loss: 0.3529 - val_accuracy: 0.8519\n",
      "Epoch 801/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8741 - val_loss: 0.3534 - val_accuracy: 0.8519\n",
      "Epoch 802/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8731 - val_loss: 0.3508 - val_accuracy: 0.8544\n",
      "Epoch 803/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8752 - val_loss: 0.3541 - val_accuracy: 0.8550\n",
      "Epoch 804/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8725 - val_loss: 0.3529 - val_accuracy: 0.8525\n",
      "Epoch 805/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8742 - val_loss: 0.3516 - val_accuracy: 0.8519\n",
      "Epoch 806/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8750 - val_loss: 0.3522 - val_accuracy: 0.8500\n",
      "Epoch 807/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8728 - val_loss: 0.3519 - val_accuracy: 0.8544\n",
      "Epoch 808/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8744 - val_loss: 0.3531 - val_accuracy: 0.8525\n",
      "Epoch 809/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8741 - val_loss: 0.3530 - val_accuracy: 0.8519\n",
      "Epoch 810/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8737 - val_loss: 0.3527 - val_accuracy: 0.8494\n",
      "Epoch 811/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8761 - val_loss: 0.3548 - val_accuracy: 0.8537\n",
      "Epoch 812/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8731 - val_loss: 0.3518 - val_accuracy: 0.8550\n",
      "Epoch 813/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8745 - val_loss: 0.3512 - val_accuracy: 0.8525\n",
      "Epoch 814/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8730 - val_loss: 0.3515 - val_accuracy: 0.8519\n",
      "Epoch 815/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8722 - val_loss: 0.3539 - val_accuracy: 0.8494\n",
      "Epoch 816/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8736 - val_loss: 0.3525 - val_accuracy: 0.8519\n",
      "Epoch 817/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8742 - val_loss: 0.3500 - val_accuracy: 0.8506\n",
      "Epoch 818/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8733 - val_loss: 0.3551 - val_accuracy: 0.8575\n",
      "Epoch 819/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8741 - val_loss: 0.3526 - val_accuracy: 0.8537\n",
      "Epoch 820/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8736 - val_loss: 0.3520 - val_accuracy: 0.8525\n",
      "Epoch 821/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8750 - val_loss: 0.3538 - val_accuracy: 0.8575\n",
      "Epoch 822/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8739 - val_loss: 0.3507 - val_accuracy: 0.8531\n",
      "Epoch 823/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8742 - val_loss: 0.3537 - val_accuracy: 0.8475\n",
      "Epoch 824/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8742 - val_loss: 0.3506 - val_accuracy: 0.8531\n",
      "Epoch 825/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8719 - val_loss: 0.3513 - val_accuracy: 0.8475\n",
      "Epoch 826/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8745 - val_loss: 0.3526 - val_accuracy: 0.8525\n",
      "Epoch 827/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8744 - val_loss: 0.3517 - val_accuracy: 0.8512\n",
      "Epoch 828/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8744 - val_loss: 0.3522 - val_accuracy: 0.8519\n",
      "Epoch 829/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8736 - val_loss: 0.3529 - val_accuracy: 0.8525\n",
      "Epoch 830/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8744 - val_loss: 0.3513 - val_accuracy: 0.8531\n",
      "Epoch 831/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8739 - val_loss: 0.3511 - val_accuracy: 0.8500\n",
      "Epoch 832/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8752 - val_loss: 0.3502 - val_accuracy: 0.8506\n",
      "Epoch 833/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8759 - val_loss: 0.3538 - val_accuracy: 0.8506\n",
      "Epoch 834/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8748 - val_loss: 0.3512 - val_accuracy: 0.8550\n",
      "Epoch 835/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8742 - val_loss: 0.3527 - val_accuracy: 0.8525\n",
      "Epoch 836/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8761 - val_loss: 0.3553 - val_accuracy: 0.8531\n",
      "Epoch 837/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8734 - val_loss: 0.3510 - val_accuracy: 0.8531\n",
      "Epoch 838/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8719 - val_loss: 0.3511 - val_accuracy: 0.8525\n",
      "Epoch 839/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8753 - val_loss: 0.3513 - val_accuracy: 0.8487\n",
      "Epoch 840/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8742 - val_loss: 0.3517 - val_accuracy: 0.8494\n",
      "Epoch 841/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8739 - val_loss: 0.3515 - val_accuracy: 0.8494\n",
      "Epoch 842/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8734 - val_loss: 0.3506 - val_accuracy: 0.8494\n",
      "Epoch 843/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8742 - val_loss: 0.3515 - val_accuracy: 0.8500\n",
      "Epoch 844/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8753 - val_loss: 0.3487 - val_accuracy: 0.8512\n",
      "Epoch 845/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8734 - val_loss: 0.3526 - val_accuracy: 0.8481\n",
      "Epoch 846/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8727 - val_loss: 0.3503 - val_accuracy: 0.8519\n",
      "Epoch 847/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8722 - val_loss: 0.3526 - val_accuracy: 0.8537\n",
      "Epoch 848/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8752 - val_loss: 0.3524 - val_accuracy: 0.8506\n",
      "Epoch 849/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8755 - val_loss: 0.3509 - val_accuracy: 0.8531\n",
      "Epoch 850/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8733 - val_loss: 0.3516 - val_accuracy: 0.8512\n",
      "Epoch 851/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8737 - val_loss: 0.3509 - val_accuracy: 0.8512\n",
      "Epoch 852/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8741 - val_loss: 0.3545 - val_accuracy: 0.8525\n",
      "Epoch 853/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8739 - val_loss: 0.3520 - val_accuracy: 0.8525\n",
      "Epoch 854/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8725 - val_loss: 0.3519 - val_accuracy: 0.8481\n",
      "Epoch 855/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8745 - val_loss: 0.3514 - val_accuracy: 0.8562\n",
      "Epoch 856/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8730 - val_loss: 0.3513 - val_accuracy: 0.8519\n",
      "Epoch 857/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8728 - val_loss: 0.3547 - val_accuracy: 0.8475\n",
      "Epoch 858/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8748 - val_loss: 0.3544 - val_accuracy: 0.8537\n",
      "Epoch 859/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8733 - val_loss: 0.3526 - val_accuracy: 0.8462\n",
      "Epoch 860/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8748 - val_loss: 0.3505 - val_accuracy: 0.8512\n",
      "Epoch 861/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8744 - val_loss: 0.3528 - val_accuracy: 0.8537\n",
      "Epoch 862/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8742 - val_loss: 0.3542 - val_accuracy: 0.8512\n",
      "Epoch 863/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8759 - val_loss: 0.3495 - val_accuracy: 0.8506\n",
      "Epoch 864/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3045 - accuracy: 0.8727 - val_loss: 0.3528 - val_accuracy: 0.8525\n",
      "Epoch 865/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3038 - accuracy: 0.8753 - val_loss: 0.3520 - val_accuracy: 0.8531\n",
      "Epoch 866/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8722 - val_loss: 0.3507 - val_accuracy: 0.8487\n",
      "Epoch 867/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8742 - val_loss: 0.3520 - val_accuracy: 0.8487\n",
      "Epoch 868/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8752 - val_loss: 0.3518 - val_accuracy: 0.8500\n",
      "Epoch 869/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8744 - val_loss: 0.3521 - val_accuracy: 0.8512\n",
      "Epoch 870/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8758 - val_loss: 0.3520 - val_accuracy: 0.8500\n",
      "Epoch 871/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8752 - val_loss: 0.3515 - val_accuracy: 0.8481\n",
      "Epoch 872/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8734 - val_loss: 0.3529 - val_accuracy: 0.8525\n",
      "Epoch 873/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8755 - val_loss: 0.3515 - val_accuracy: 0.8512\n",
      "Epoch 874/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8745 - val_loss: 0.3515 - val_accuracy: 0.8525\n",
      "Epoch 875/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8761 - val_loss: 0.3518 - val_accuracy: 0.8519\n",
      "Epoch 876/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8737 - val_loss: 0.3521 - val_accuracy: 0.8481\n",
      "Epoch 877/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8755 - val_loss: 0.3523 - val_accuracy: 0.8525\n",
      "Epoch 878/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8728 - val_loss: 0.3520 - val_accuracy: 0.8537\n",
      "Epoch 879/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8731 - val_loss: 0.3514 - val_accuracy: 0.8531\n",
      "Epoch 880/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8758 - val_loss: 0.3533 - val_accuracy: 0.8500\n",
      "Epoch 881/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8747 - val_loss: 0.3542 - val_accuracy: 0.8512\n",
      "Epoch 882/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8756 - val_loss: 0.3500 - val_accuracy: 0.8531\n",
      "Epoch 883/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8759 - val_loss: 0.3527 - val_accuracy: 0.8512\n",
      "Epoch 884/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8761 - val_loss: 0.3506 - val_accuracy: 0.8531\n",
      "Epoch 885/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8750 - val_loss: 0.3515 - val_accuracy: 0.8500\n",
      "Epoch 886/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8731 - val_loss: 0.3529 - val_accuracy: 0.8525\n",
      "Epoch 887/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8755 - val_loss: 0.3504 - val_accuracy: 0.8506\n",
      "Epoch 888/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8750 - val_loss: 0.3535 - val_accuracy: 0.8500\n",
      "Epoch 889/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8759 - val_loss: 0.3542 - val_accuracy: 0.8481\n",
      "Epoch 890/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8778 - val_loss: 0.3503 - val_accuracy: 0.8494\n",
      "Epoch 891/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8753 - val_loss: 0.3530 - val_accuracy: 0.8494\n",
      "Epoch 892/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8747 - val_loss: 0.3531 - val_accuracy: 0.8512\n",
      "Epoch 893/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8747 - val_loss: 0.3518 - val_accuracy: 0.8506\n",
      "Epoch 894/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8750 - val_loss: 0.3518 - val_accuracy: 0.8487\n",
      "Epoch 895/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8744 - val_loss: 0.3527 - val_accuracy: 0.8512\n",
      "Epoch 896/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8731 - val_loss: 0.3546 - val_accuracy: 0.8531\n",
      "Epoch 897/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8725 - val_loss: 0.3509 - val_accuracy: 0.8519\n",
      "Epoch 898/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8731 - val_loss: 0.3517 - val_accuracy: 0.8531\n",
      "Epoch 899/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3039 - accuracy: 0.8745 - val_loss: 0.3519 - val_accuracy: 0.8537\n",
      "Epoch 900/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3039 - accuracy: 0.8766 - val_loss: 0.3515 - val_accuracy: 0.8512\n",
      "Epoch 901/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3039 - accuracy: 0.8720 - val_loss: 0.3526 - val_accuracy: 0.8506\n",
      "Epoch 902/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8719 - val_loss: 0.3516 - val_accuracy: 0.8519\n",
      "Epoch 903/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8755 - val_loss: 0.3517 - val_accuracy: 0.8512\n",
      "Epoch 904/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8741 - val_loss: 0.3521 - val_accuracy: 0.8525\n",
      "Epoch 905/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8764 - val_loss: 0.3513 - val_accuracy: 0.8506\n",
      "Epoch 906/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8752 - val_loss: 0.3555 - val_accuracy: 0.8512\n",
      "Epoch 907/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8777 - val_loss: 0.3541 - val_accuracy: 0.8537\n",
      "Epoch 908/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8750 - val_loss: 0.3511 - val_accuracy: 0.8519\n",
      "Epoch 909/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8747 - val_loss: 0.3523 - val_accuracy: 0.8525\n",
      "Epoch 910/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8747 - val_loss: 0.3496 - val_accuracy: 0.8550\n",
      "Epoch 911/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8747 - val_loss: 0.3527 - val_accuracy: 0.8494\n",
      "Epoch 912/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8741 - val_loss: 0.3547 - val_accuracy: 0.8506\n",
      "Epoch 913/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8739 - val_loss: 0.3549 - val_accuracy: 0.8456\n",
      "Epoch 914/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8739 - val_loss: 0.3530 - val_accuracy: 0.8500\n",
      "Epoch 915/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8737 - val_loss: 0.3512 - val_accuracy: 0.8537\n",
      "Epoch 916/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8750 - val_loss: 0.3519 - val_accuracy: 0.8550\n",
      "Epoch 917/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8712 - val_loss: 0.3522 - val_accuracy: 0.8494\n",
      "Epoch 918/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8730 - val_loss: 0.3508 - val_accuracy: 0.8512\n",
      "Epoch 919/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8748 - val_loss: 0.3513 - val_accuracy: 0.8544\n",
      "Epoch 920/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8763 - val_loss: 0.3513 - val_accuracy: 0.8500\n",
      "Epoch 921/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8748 - val_loss: 0.3533 - val_accuracy: 0.8481\n",
      "Epoch 922/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8747 - val_loss: 0.3530 - val_accuracy: 0.8525\n",
      "Epoch 923/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8734 - val_loss: 0.3562 - val_accuracy: 0.8525\n",
      "Epoch 924/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8756 - val_loss: 0.3516 - val_accuracy: 0.8525\n",
      "Epoch 925/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8731 - val_loss: 0.3533 - val_accuracy: 0.8519\n",
      "Epoch 926/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8756 - val_loss: 0.3541 - val_accuracy: 0.8537\n",
      "Epoch 927/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8731 - val_loss: 0.3508 - val_accuracy: 0.8531\n",
      "Epoch 928/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8758 - val_loss: 0.3578 - val_accuracy: 0.8531\n",
      "Epoch 929/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8747 - val_loss: 0.3539 - val_accuracy: 0.8506\n",
      "Epoch 930/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3040 - accuracy: 0.8730 - val_loss: 0.3529 - val_accuracy: 0.8519\n",
      "Epoch 931/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8753 - val_loss: 0.3518 - val_accuracy: 0.8519\n",
      "Epoch 932/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8742 - val_loss: 0.3529 - val_accuracy: 0.8550\n",
      "Epoch 933/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8716 - val_loss: 0.3534 - val_accuracy: 0.8512\n",
      "Epoch 934/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8769 - val_loss: 0.3549 - val_accuracy: 0.8500\n",
      "Epoch 935/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8752 - val_loss: 0.3530 - val_accuracy: 0.8531\n",
      "Epoch 936/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8745 - val_loss: 0.3522 - val_accuracy: 0.8512\n",
      "Epoch 937/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8764 - val_loss: 0.3537 - val_accuracy: 0.8537\n",
      "Epoch 938/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8731 - val_loss: 0.3532 - val_accuracy: 0.8525\n",
      "Epoch 939/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8725 - val_loss: 0.3524 - val_accuracy: 0.8519\n",
      "Epoch 940/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8730 - val_loss: 0.3534 - val_accuracy: 0.8537\n",
      "Epoch 941/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3039 - accuracy: 0.8739 - val_loss: 0.3530 - val_accuracy: 0.8487\n",
      "Epoch 942/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8739 - val_loss: 0.3531 - val_accuracy: 0.8512\n",
      "Epoch 943/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8742 - val_loss: 0.3544 - val_accuracy: 0.8519\n",
      "Epoch 944/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8759 - val_loss: 0.3523 - val_accuracy: 0.8519\n",
      "Epoch 945/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8744 - val_loss: 0.3529 - val_accuracy: 0.8519\n",
      "Epoch 946/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8752 - val_loss: 0.3515 - val_accuracy: 0.8544\n",
      "Epoch 947/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8747 - val_loss: 0.3519 - val_accuracy: 0.8550\n",
      "Epoch 948/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8744 - val_loss: 0.3528 - val_accuracy: 0.8512\n",
      "Epoch 949/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8728 - val_loss: 0.3533 - val_accuracy: 0.8550\n",
      "Epoch 950/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8725 - val_loss: 0.3525 - val_accuracy: 0.8544\n",
      "Epoch 951/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8748 - val_loss: 0.3547 - val_accuracy: 0.8537\n",
      "Epoch 952/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8747 - val_loss: 0.3527 - val_accuracy: 0.8525\n",
      "Epoch 953/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8766 - val_loss: 0.3514 - val_accuracy: 0.8550\n",
      "Epoch 954/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8739 - val_loss: 0.3542 - val_accuracy: 0.8525\n",
      "Epoch 955/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8747 - val_loss: 0.3509 - val_accuracy: 0.8494\n",
      "Epoch 956/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8755 - val_loss: 0.3543 - val_accuracy: 0.8531\n",
      "Epoch 957/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8777 - val_loss: 0.3538 - val_accuracy: 0.8531\n",
      "Epoch 958/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8739 - val_loss: 0.3540 - val_accuracy: 0.8500\n",
      "Epoch 959/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8742 - val_loss: 0.3532 - val_accuracy: 0.8519\n",
      "Epoch 960/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8758 - val_loss: 0.3525 - val_accuracy: 0.8531\n",
      "Epoch 961/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8758 - val_loss: 0.3549 - val_accuracy: 0.8525\n",
      "Epoch 962/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8728 - val_loss: 0.3530 - val_accuracy: 0.8550\n",
      "Epoch 963/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8747 - val_loss: 0.3552 - val_accuracy: 0.8506\n",
      "Epoch 964/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8753 - val_loss: 0.3516 - val_accuracy: 0.8544\n",
      "Epoch 965/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8748 - val_loss: 0.3546 - val_accuracy: 0.8512\n",
      "Epoch 966/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8763 - val_loss: 0.3537 - val_accuracy: 0.8544\n",
      "Epoch 967/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8741 - val_loss: 0.3538 - val_accuracy: 0.8525\n",
      "Epoch 968/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8739 - val_loss: 0.3535 - val_accuracy: 0.8537\n",
      "Epoch 969/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8759 - val_loss: 0.3565 - val_accuracy: 0.8500\n",
      "Epoch 970/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8772 - val_loss: 0.3507 - val_accuracy: 0.8537\n",
      "Epoch 971/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8759 - val_loss: 0.3551 - val_accuracy: 0.8550\n",
      "Epoch 972/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8769 - val_loss: 0.3555 - val_accuracy: 0.8519\n",
      "Epoch 973/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8742 - val_loss: 0.3538 - val_accuracy: 0.8537\n",
      "Epoch 974/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8758 - val_loss: 0.3558 - val_accuracy: 0.8556\n",
      "Epoch 975/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8764 - val_loss: 0.3558 - val_accuracy: 0.8494\n",
      "Epoch 976/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8756 - val_loss: 0.3525 - val_accuracy: 0.8537\n",
      "Epoch 977/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8761 - val_loss: 0.3520 - val_accuracy: 0.8569\n",
      "Epoch 978/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8747 - val_loss: 0.3526 - val_accuracy: 0.8544\n",
      "Epoch 979/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8763 - val_loss: 0.3535 - val_accuracy: 0.8525\n",
      "Epoch 980/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8750 - val_loss: 0.3559 - val_accuracy: 0.8569\n",
      "Epoch 981/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8745 - val_loss: 0.3546 - val_accuracy: 0.8556\n",
      "Epoch 982/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8753 - val_loss: 0.3558 - val_accuracy: 0.8506\n",
      "Epoch 983/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8756 - val_loss: 0.3540 - val_accuracy: 0.8500\n",
      "Epoch 984/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8755 - val_loss: 0.3522 - val_accuracy: 0.8556\n",
      "Epoch 985/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8747 - val_loss: 0.3547 - val_accuracy: 0.8525\n",
      "Epoch 986/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8756 - val_loss: 0.3553 - val_accuracy: 0.8500\n",
      "Epoch 987/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8753 - val_loss: 0.3574 - val_accuracy: 0.8537\n",
      "Epoch 988/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8741 - val_loss: 0.3519 - val_accuracy: 0.8537\n",
      "Epoch 989/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8741 - val_loss: 0.3538 - val_accuracy: 0.8494\n",
      "Epoch 990/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8742 - val_loss: 0.3538 - val_accuracy: 0.8506\n",
      "Epoch 991/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8741 - val_loss: 0.3515 - val_accuracy: 0.8537\n",
      "Epoch 992/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8708 - val_loss: 0.3545 - val_accuracy: 0.8481\n",
      "Epoch 993/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8744 - val_loss: 0.3542 - val_accuracy: 0.8500\n",
      "Epoch 994/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8753 - val_loss: 0.3555 - val_accuracy: 0.8500\n",
      "Epoch 995/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8745 - val_loss: 0.3530 - val_accuracy: 0.8537\n",
      "Epoch 996/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8756 - val_loss: 0.3540 - val_accuracy: 0.8550\n",
      "Epoch 997/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8747 - val_loss: 0.3523 - val_accuracy: 0.8525\n",
      "Epoch 998/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8755 - val_loss: 0.3526 - val_accuracy: 0.8550\n",
      "Epoch 999/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8733 - val_loss: 0.3541 - val_accuracy: 0.8519\n",
      "Epoch 1000/1000\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8744 - val_loss: 0.3528 - val_accuracy: 0.8544\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(y_log > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.853"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x210957f3ed0>]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2109583aa90>]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB5K0lEQVR4nO3dd3wT9f8H8FeSbmjLaGmhFMreu1ALiCgVBKxbUaYoIgoOcPzYqAjFxRcHiAOcIIiCoiAIZctu2XsXCl2M7qZtcr8/Pk1yl53SNgVez8ejjyaXy+VySe7e9/68P59TSZIkgYiIiKgSU7t7BYiIiIgcYcBCRERElR4DFiIiIqr0GLAQERFRpceAhYiIiCo9BixERERU6TFgISIiokqPAQsRERFVeh7uXoGyotfrcfnyZfj7+0OlUrl7dYiIiMgJkiQhOzsbderUgVptO49y2wQsly9fRnh4uLtXg4iIiErh4sWLqFu3rs3Hb5uAxd/fH4B4wwEBAW5eGyIiInJGVlYWwsPDjcdxW26bgMXQDBQQEMCAhYiI6BbjqJyDRbdERERU6TFgISIiokqPAQsRERFVegxYiIiIqNIrVcAyd+5cREREwMfHB1FRUdi9e7fd+efMmYNmzZrB19cX4eHhGDt2LAoKCoyP63Q6TJkyBQ0aNICvry8aNWqE6dOnQ5Kk0qweERER3WZc7iW0dOlSjBs3DvPnz0dUVBTmzJmDPn364MSJE6hVq5bF/IsXL8b48eOxcOFCdO3aFSdPnsSzzz4LlUqF2bNnAwA++OADfPnll/jhhx/QqlUr7N27F8OHD0dgYCBeffXVm3+XREREdEtTSS6mMaKiotC5c2d88cUXAMQIs+Hh4XjllVcwfvx4i/nHjBmDY8eOIT4+3jjtjTfewK5du7Bt2zYAwIMPPoiQkBAsWLDAOM/jjz8OX19f/Pzzz06tV1ZWFgIDA5GZmcluzURERLcIZ4/fLjUJFRYWIiEhATExMaYFqNWIiYnBjh07rD6na9euSEhIMDYbnT17FqtXr0a/fv0U88THx+PkyZMAgAMHDmDbtm3o27evzXXRarXIyspS/BEREdHtyaUmoYyMDOh0OoSEhCimh4SE4Pjx41afM3DgQGRkZKB79+6QJAnFxcUYNWoUJk6caJxn/PjxyMrKQvPmzaHRaKDT6TBjxgwMGjTI5rrExcXh3XffdWX1iYiI6BZV7r2ENm3ahJkzZ2LevHlITEzE8uXLsWrVKkyfPt04z6+//opFixZh8eLFSExMxA8//ICPP/4YP/zwg83lTpgwAZmZmca/ixcvlvdbISIiIjdxKcMSFBQEjUaD1NRUxfTU1FSEhoZafc6UKVMwZMgQjBgxAgDQpk0b5ObmYuTIkZg0aRLUajXeeustjB8/Hk8//bRxngsXLiAuLg7Dhg2zulxvb294e3u7svpERER0i3Ipw+Ll5YVOnTopCmj1ej3i4+MRHR1t9Tl5eXkWl4vWaDQAYOy2bGsevV7vyuoRERHRbcrlbs3jxo3DsGHDEBkZiS5dumDOnDnIzc3F8OHDAQBDhw5FWFgY4uLiAACxsbGYPXs2OnTogKioKJw+fRpTpkxBbGysMXCJjY3FjBkzUK9ePbRq1Qr79u3D7Nmz8dxzz5XhWyUiIqpYF6/l4e+DVzD4rnrw9/G0eLywWI9ivR5+XmV/LeLM/CIE+Hg4vKjgrcLlLTRgwACkp6dj6tSpSElJQfv27bFmzRpjIW5SUpIiWzJ58mSoVCpMnjwZycnJCA4ONgYoBp9//jmmTJmCl19+GWlpaahTpw5efPFFTJ06tQzeIhERkXs8/uV2pGVrcfF6HmY+2sbi8b6fbkFKZgH2TI4p06Dlv9MZGPTtLoy6pxHG921eZst1J5fHYamsOA4LERno9BKe/W43GgRVwXsPt3bqOe+sPIJTadn4YXgXeGh41RIqGxHjVwEAwmv4Yuvb9ykeK9Lp0WTSPwCA30ZFIzKihsPlSZIEbbEePp4au/P1/t9mnEzNAQCcn9XfOH3X2auY/MdhTOzXAvc2txzs1R3KZRwWIqJbQcKF69h6KgM/7rjg1PySJOH77efx3+mr2HvhejmvHd2JPGVB8MVrebiao0VWfpFxmrOZg3f/Oop27/6Ls+k5Nuc5m56DtGyt1cee/2EvTqXlYPj3e7D1VLqTr1o5MGAhotuOXpY4Lix2XLyfX6Sz+djVHC1+S7iE/ELb87hizeEUnErNdnp+SZKg11dcIrwiX6u8uPIeymr7mi9DZ3bfqyRgycjR4u4PN6LT++sx6x/T+GU52mLF/FtPpSMxyTJ4/n77eWiL9bjvk81YfzTV4vEz6Tm475PNuJFXpJiu10v4Y1+y4nWGLNiNb7acxW8Jl3A1x3qAU5kwYCGiciVJEi5cza3QA6FGbSoyzDU7EFhjvnOXe/a7PXhz2QHM3Xjaqde+eC0PBTYCoL3nr2HUzwm4/39bnFqWJEl4/MvteHjufxWy/TafTEebd9Zixb5LAMR7KdJVTG/NvMJixK0+hv0Xb9zUcpJv5KPj++sQ988xu/Npi3X45N8TaPPOv3jw820WAYYt205l4OO1J6DTSyjS6XH5Rj4OXLyBNu+sxcJt55CWVYBley+i/bv/4qO1poDEQyO+kwdk729ZwiXjbXm2JS2rAEMW7MZj87ZDr5cgSRLOZ+RarOOIH/eiWKfHR2uP47/TGQCAjcfTLNb52JUsLN6dhNeX7rd4bMbqY3hz2QGM+jnBqffvTmVflkxEJPPzriRM+eMwhtxVH9MfMdWTSJJUJr0XDGV48mXJD7I52mJUr+JlnDcjpxBvLDuAgV3C8UDr2gCUAYt5JuVQciYA4KedF3Dg0g20DgvEwUs3MLFfC7SqE6h4H4lJ1/HYvO24t1kwvhveRbGcHG0xZq87abHu5tsg4cI1+Hhq0KpOILIKipGYdAMAcDkzH3Wr+zm9XbILirDtVAbubV7LWO+w/XQG5m46jfcebo1GwVUt1mH0okTkFuowdukBhPj7YOC3u3BP02D88FwXm69TFnacuYoF285h/bFUfLXlrKLmwlVfbDiNG3lF+GrzWUzo28LmfB+tOYFvt50DABy9koXLN/IRXsPPuD0SLlxHNT9P43YyGLxgFwCgSUhVnErNwReyQPa9v4/ivb+PGu/P3XjGeFsFsY3zbGTqMmUBy6Ub+cbbnWesx9XcQgDAyB4NLZ73e+IlzN14BnM3nsH5Wf1RaCXA7PvpVhtbwWTP+et44svtOH81F+P7tsATneoCAH7dexFzN57GhL7Njb8Xd2GGhYjK1Qclae+fdprqSUYvSkT/z7Ypmmv+OXQFv+5xfcTq53/Yi0fnbVcEKZeum3b4uYUiw/LHvmR0nrEeT3+9A1tOpmPUz4nGeeQHC8P8gLI5KTO/CFtPZeDLTWfw3+mrGL0oEceuZKHLzHj8XPLe/j5wBQCw8US6RVPUG7/ux/YzV433N51IQ6f312PQtzvx8doTyCssxtUcLR7/cgf6fybO+OXBU65Wh4wcLQqKdMgusJ4RKtbpMXfjaexLuo7/+/0gXlqUqGh2GPjtLvx3+ire+0scVIt0ejz0xX948ae92Hn2qqK54MvN4mC7+aTjOoeMHC3+t+4kkmUHWvl2M2ScVh64jOWJlxSPX76Rj2e+2Yn1xyybN67maO1mPpbuScJ/pzOw+WQ6vvtPZDesNQHq9BIyzJo8NphlIu7+cCOW7klC5xnrMeqnBDz+5XY8+91um6/92pL9imDFkfRsLa7nFtrM+BkyLIXFepxJM9WnGIIVAPh6y1mL551NzzXePpWa7VQTqC17L1xHRk4h3lx2AOnZWvy88wLe/u0gLlzNw6ifE3E6zXbdTEVghoXuKD/vvIBDlzIR91gbqNW35tgEBy/dQHU/L4TXcP5su6LNWHUU/j6eGBRVz6JtXlusw6pD4sB+KDkTnepXh14v4aVFIoCIblRT8d6yC4pw7Eo2OkdUt8hG5BUWGw88h5Mz0a5uNbz52wEsT0w2zpOrFQdLQzo8I6dQsYyNx9Pw0iJTOnzM4n1oUTsAjYKrWhzk5M5fzcP45YeQnq3F5D8OY/Bd9VErwDT69jdbz+L57g2M2Y21R5QH5Ge/2wMA+O/0Vfx3+ip2nL2qOPtOz9YqgqdRPyfgXEYuVCogqKo31r7eAzVKMkcGv+69hI/WnlBM+377efRuFYJmIf7GaYaCzKOXs3AoOROHkjNx7IqyrmbrqQzj7SOXM5GWpcWyhIuY8UgbVK/ihe1nMvD9f+fx7sOtMHH5IWw8kY6/DlzGhjd7Gp+XfCMfD8zZguyCYvRpFWLcBvc1r4VqfmLdr2RaBjmGdev32VY81K4OPnumg3H6lcx8vLvyKO5uGoRJKw4rnvPuX0fNFwNABIt/7L+Mf167Gy1qi14o1jId//f7IQDAmiMpAICL1/JRrNPDQ6PG9L+PYkFJRqY0UrIK0GH6OgyKqmf18V/3XsJD7cIw4sc9xt49zpD/JpxtanTGwUs3MPkP5fY9l5GLxrWq2nhG+WPAQncUww8wpmUI7m8Z4mDuyufitTw89MV/AICzM/tVyqDrwtVcfLNV7NiPpyivov71ljOKM/7Hv9yOn5+PQtvwQOO0D9Ycx5HLWfjxuS4Ir+GHaSuPYHliMqY+2BLPdW+ANYev4OK1fKhUQM9mpm6Zl28U4OiVJEWwAgBfbDiFb4d1trm+w7/fYzHttSX7sHJ0d6RkFdh8nodahTyzYEye+fho7QlcuJqLl3o2xnNWXsNcglnvpFE/J2C6rEv2uQxxJi1JIpjpOH0dnu0agXceagVtsQ4eajUOX860uuyB3+yCj6cpoV7NVwxgppWdjSddy7O5bv0/22a8HVzVG+8+3BoDvxFNI8V6CdtK6ifOZuRiz/lr6FzSPXfp7iRkF4htJA/Ykm/ko5qfF/R6Cc98vcvi9R6e+x8CS9Zx5YHLmNS/BVbsS0arOgEYskBkPQxBhT1LdifhkQ5h+GP/ZQCiaSS8hi/Cqvna/Wzltp+5ime/242yKiFatCvJ6vSka3l4fP52pNvo3WNLjtZ2/dXNOHDJ8rv0wZrj6FCvGoKquueyOGwSojvSjbxCxzPZsPlkOt5cdgBn0nNwOs16b49dZ69i/O8HnSr4tEanl7Av6TqKzdqjT8p6l7yyZJ/N5xfr9Jj8xyH8uT/Z5jyuunwjH2OX7schsx2ZtliHhAvXUKzTQ6eX8MAcU3u5vAkEAGauPm6x4x+8YBdG/rjXeP/vg1dwLiMXd3+4EWuPpBgDkPf+PorMvCKM+jkRM1Yfw/urjmGWrLDy6JVMizNuQDTP/LjjvNX3ZOvzO5ychehZ8Xhs3narjxuckqXIi3R6Rc0CIM6aZ687aQw2XLH/4g1czbV/8Pp++3lcyczHI3O3496PN8HesFoFRabv0o6zV3E2PQcvlaLQcu2RVEVR8e5z1+DtYRoT5Mn5O4y395y33kW8/2fb8N1/53AiNdtqzcWBizewRdYU9Wn8Kcz657gxWHHW+OWH0HzKGsW0i9fysfPsNaeXMXThzQcrPz1vvwZo1D2NAMDlYAUA1lnpKeSKj55oi+p+IjgcGl3fOP2z+FMW855Oy3G6OLk8MMNClVphsR6eGlWZFmcC1sc8KCzWw8tDbfxvy7CFYqf5W0mF/x+ju+Ho5Sw81jEMPp4aSJKEAV/vBADUq+mHl3s2trqcS9fzsPVUBh7rGGbc4Rfp9PBQq/Dn/mSM+/UA7mteCwufFdkBvV6CfDOsOngFcweK238duIz6Nf3Qtm41AMCKfcn4eWcSft6ZhIfbh1m8tl4vYeRPCagV4G119E1r22Xs0v3Yde4aVuxLxu8vRcPX0wPHU7Kw8+xV/Lr3Et64vyk61Kuu6CJsr/eNnK0DyIs/KQ+o180CzfXHTHUI5sGCnK2mgpjZtlPoqVn2Dx7FZjvuRTutj/lSWFz67tC21lsuOm6D8XbSbttZEnP3fbK5VOuUklWgCAJytMWiaUq2ub7YcAoPtq1jM+MDiPc2Z0B7p15zyW7rWYnK6rGOYfj3SKqxOfTuJsFYPCIKA7+1zCZV9fbA+L7NceFqLv457DhrZM7wPfX38TBmsxzp2SwYmflF6BBeHU9GhuPJyHBoi3Xw9tCgS4MaGLPYdDLk7+OB5qH+xuCzlr/7LjrMgIXKVLFOj2UJl3D8Shbe7NPM6rUznHUttxAxszejbnVf/PpitMXIjhk5WhQW61Gnmq9Ty5Onv80jlmV7L2LiikMIDfTB1ZxC/DwiCiEBPgir5ouz6TkICfBBFW/rP5dH5oommhv5hXi5Z2OclZ1NZ2Rbz+SkZ2vR/YONJfNo8UqvJsgqKMJ9H29Gx3rV4FkSMG04noZxS/djyoMtMXpxokXGIiNHi93nruGVX8QO5sfnuqBj/ep467eDdrfF5pPpxiLHXs1r4cDFG3gtpqmiO7BOL+GdlUfwy+4kfDe8M3afNwUVI37Yi+tmwcin8acwrndTu697s066MH5JWWtVJwBHLosmrsF31cPPO5UH0XdsBBelOWs2KE1mxh2u5Sq/5x//exIf/3vSxtwmyxKcK7Iur5P6eYM6YuupDPxSxgFRoK+nsRuzQb2a1mvOVo7pBgB49+FW0BbrLYqBndGtcU28cl8TPF1yogQAD7atjVZ1AvHn/mQcTxG/m/mDO+GvA5fxbLcIY7OdgeGkqW/r2vhuuAeGl9RYqVUqxW/dndclYpMQ2bVo1wUM+nansW1+eeIlPDV/h2InnHwj3ziA0ZQ/j2DC8kP4YccFzFl/Cjq9hFd/2YeZq49ZTVfnF+rwx75kq8WNS/Yk4VpuIQ5eysSj87Ybn5+ercVT83cg8v316DprA/JkhYkJF65hy8l0DF24G19tVp5xy4vsDAOL6fUSTqRk463fDqJIJ+HitXzkFerw2Lzt6DZrAzaeSMN9n2xG5Pvr8d/pDLtjYWw9Kdrxr8qKOq/nFSLhwnXsPCsCDW2xDot3iZ4IBptKUt8bj6chI0eLf4+mKsZSWL4vGW//ftAiWAGAyPfX4+VFpt4uQxfuVqTSDa9p8NPOCxjw1Q5F3cbzP+zFZxtO492/jmDxriTkFRbj0vU8NJq4Gj/tvIBivYQXf0qA/OMzD1YAkXH42Kzgs6xNXHGozJZlXrDqyB+juxlvu9K92NAt2RXy1Pzt7L/Tlt/p8vL2A82Mt+9tFowlI+9Cvza1EVTVte+Bubf6NENYNV/8KOv6HejriSZmxam1A62fWBlOuGr5+2Dhs53RsV4142OPdbTMjlrz3sOtUTvQx3i/X5tQfDGwI17q2QhTH2xpnH53kyDMHdTRIliR06hVuFdWG6aXJGMX5y4NHF86oDwxw0J2GWoCvt5yFsO7NcC4Xw8AgPGA+/kzHfDBmuO4dD0f4TV8cfGaqeL/xx3nFVX1v+xKwurX7kZ4DT98s+UsLl3Pw/pjaUi+kY8nOtXFrMfaIDVbi7CSH7C8q+mxK1nYeioDzWv7498jqYqz/VOpOWgXXg2FxXo8/qWp/XzLyXS8eE8j/LI7CRq1Ct0aBxkf0xaLAZ/6frpV8TrmDGcZ+UU6DLKSzpXbcfaq8bohBiv2JWPFPlGDMSiqntWCu4QL1zFn/Uk0qWXqxWHeg8GVdmp5AAMAi3Ym4WRqNqp4e9jt5WAYxv56XqFF7YutsSPMuXom/Fy3Blj4n3KdNGqVzXZy8x4+pfX3K93ROizQ+Hnd1bAGfnwuCv+dzsCYxWIsEgBoFFwFZ9Jz8U5sS3hq1Khf0w8Xruahf5vaiuLhsjYoqr7isgIxLULwRKe6Tg/u9enT7RFRswoeLsn+OWPr2/fi7g83uryuZcXHU62os7kZ7z/SWtHDZeObPVFYrMeHa0RA/Vz3BrirYU0AQKjsQL9rYi/M+ue48Tf7TmxLReasYXAVBFf1xq5zpv3P6HsbY/S9jRUF13c3CcZjHepi6srDxrFTNDYK5L3Nmp/lBa3THmyFLhE1MH65/UA9omYVRbf+NFlzpqE3FgCbWWK7JPE7bRRc1e0BCzMsd4D4Y6kYtnA30pysirfmTHoOOk5fZzH9lV/2Gce8kAcrAFCkUx50srXF2HQiDasOXsGM1cfww44LxnEbfku4hMe/FFmND9Ycx7XcQsXIj4DIHnSZEW/R1c4wCqi1LE3raWsxYfkhvP3bQQz4yhTMrD+Wiq6zNtgNVsqard4BADBn/SlITl9NxDXv/X0US/ZcdLpL5kdrT7jUrbK0Pn26PSb3txzYa/24e4y3m4f648Mn2uLZrhE2l7PlrXvRPryaU6/ZoV41fDM0Eq3DRK+k9x5uBX9vD7zVpzm8PNS4t3kt+HqZmh7Xvt4DW9++F8NKXn/Naz2wZ1IMwmv42axzWj+uh1PrIjf63kbG23GPtUGzUH/c2yzYOK1ONR/EtLC8UJ2HjYNg+/BqaGdjm/h5afByz0aKaT89L3pkzR/c0epzGteqqjhTlyurQeU81PYPR7beKwDFe/3smQ4YfJcyQ9UgqIqxsBSAoqm6utkBXX5Qjm1Xx3j77iZB+On5KJsX0/T38cQnT7bDJ0+2Q6f61VGvph++H94FXRuZTpTMtztg2cQi78oe4OuBp7vUw/lZ/XEurh/6tg41PvZiSSD0SPs60KhV8PHUoHWY6LIdI+sB2bJOACb3b2Hzs3VEAuDlocb9LUOMPbfchRmWO8DzP4geGBNXHMa3wyIBiOyFn5cG438/hGNXsrD85a7GGpHRixNx6Voefnupq3EZqw+5XgxmzbGUbCzedcTqY4ZudF9uOoMvN9kuoLRmxb5kLNljGRDIxwCRDyYmH2OispAXut0JohvWtOiW/cLdDRAaYDrjfSoyHE9FhuPbrZYDZhmEBHrjj9HdsDzxEpbuuYjPB3bArrOmuh6512Oa4p6mpkBgaHQEBkfVV6yH/ADioVErxoTx9dIYAxprA3T9O7aH0+PjqFTA/55qj7rVfREZUQNv3C+aLAzrIq/ZGnd/U6tXkL6naTDiS5oPpz/SGlNKgnnDgaV/29pYdfCK4jk/Pd8F7cOro2FwVby5TGRM69eoAgB4oHVtDIuujx92XECPpsHG5kVPjRpNQqyPv9EouIrd92mo92kYXAWv9WoClUqFejX8jLVfBm/0bmosMn62awS+335e8XixXsK7D7XCtJVi/6FRq/DJk+3wQMlBfO2RFNzdJNjY1De5fwu8v+oYXo9pIraJLGCRf+0CZMGLn6cG/VrXxsQVh1A7wAeBvp74d2wPXLyWh14tTEGAIfPyTBflmCqPlzSd2DL2/qZoFuqP6X8fsznGj7xwVv5dVKlUilF3x97fFC1qB6BPK1MQs+zFrlh3LBW9zK7CPOJuyxFynWWv51lFY8BymyjW6bH73DV0qFddcYYoZ7hGR1p2AbrMiEd0w5rYUVJb8d7fR3EjrxCT+rc07uBaT1tb5uu52E6W4Wa8UbLjdbeXezbCPBeDrdJ4vGNd/G42Ymhl0rhWVbStG2gxJoqc+VgO7eoG4v8eaK44MBt6HDWS1QM80CoU6Tla47glhmLBxzrWxWMdxQEjtl0dXLiaa1H4ae0M0TxoerBtbXz333m0rG37MvfWjOjeAE1LBmf74PE2+PvgFWNg3LtlCP4tadarW90X3w6LhI+HBhFBpoO9+Xq81LMRNhxPw6h7GhnT+g+1q4OVBy4b55n8YEvUre6L2HZ1FFkxQwbhf0+1R1Z+ERIuXMenT3dAz2bBxqsGP9GpLvKLdNAW6RQFoVNjW2FgVH00DamKBhNWAwBCA7xxV8OaGN4tAiqoFM14dWzUZhjEtAjBc90aoHagr2Lf9FiHMCzflwwvjRq/vRSNNmGBxoClZZ0A/Df+PmhUKoz8aS8OXspE/7a1UU0WdKx9/W40ljWjmveGe65bA3RrHGT8TLw9NOgSUQOp2QVoHmr6bCMjqiO8hi/qBPpCrVYh0M8Tuyb2godaDQ+NGk1D/I3LMBjWNQLRjYIcBmvmPDVqPNw+DHWr+2L4d3sUQZCBvZ4+8vfv46nBIx2U79nXS4OHZFmhslB5whUGLLeNLzaexpz1pxDTIsSYRQGgKEg1RPR/lQwfbghWAFMgIR/mWXsTQzyXl5a1A3D0SpbjGcvB/S1D7NaSjLu/KV7t1aRCApZHO4Q5DFia1KqqGCfEXFg1X6tDqdtjqOEwN39wRwT7+2DziTQcuJSJb4ZG4qedF+wGLOYH6FZhgcZgJdjfG+nZWvRoIrIh9zQJxgePt0HHetXRJMQf/1t30mKgNXPWeo9V9bYezMtN7t8SresEomUd5wKWe5oGo3erEDwgO9Md0Lke7mlaC90+2AC1StQ5GAKWJSPvcqpot23dajj0Th9F09OnT7fH+L7N0XWW6MpcO9AH75Y0UcgDFkO9hJeHGj89H2Wzq/6QuyyLezVqFZqFigN0p/rVkXDhOl7t1QSeGjWmxbYCAPx18DLSs7VoGlIVarUKv42KRkZOIQqKdPhqy1kMvquesf6tmp8XGgZbZmdmD2iPT55qh2K9ZAyiDDpH1DDWsi0bFY0/91/G/S1CUKTXo23dQNzTNFgRrFijVquMo9oaLBl5F/SSpAiKfTw12PhGT6hl2Yxa/j6wR6UybaPS6FS/BvZOvh+eGstmroZBVWz2DhsYVQ9rDqfg3uaWzYPlpRIlWBiw3C5+KEmfyq/HsebwFYsCTAC4nmu7cNHQ/c1VLWoH4K6GNfDdf+edmt9Lo7Y6YJRB3GNtMMGs0OzVXk0wNLo+It9fb+NZpfdMl3oOuzb2aRWKB9vWxmtL9gMQhZvNQ/1xqGRIeMMBuG51X0XzkzW9mtfChWt5pbo2x2u9mqBb45oW0+cN6ohP/j2BMyVBZ68WITYDloFR9XDhaq4xYJk3qCNeXpQIPy8Nwqr54lRaDu5qWMNifJTWdQJRrJPg7+OBu5sE4Zut51DFS2O8KFqn+tWN85qnkucP7oQmIVXxwJwtirPhxzqGYXliMkZ0b2Cc9u/rPZB8I99Ya6JWqzCgsyn93tyJg8VD7eogMek6ohrUxPW8QqRkFjg8yAHigO0otQ8Ai0dEYc2RFPzfA82tFjOGBvpg9at3o3oVTwRV8UZYNV8U6fSKJi9HzIMMlUqFOtV88cb9TeHtqVY0Gz3QOhTv/nXEag8Qe+MK2fPN0Ehczyu0uADgohFRmL/pDF7tJZpbImWv+UiHMOj1kjFgsTduh0qlUhy0906OwdWcQjSQZZ68PTR4KjLceH/lmO6lei+A+B6pYRkkWGtuK2+2PpP3H22NwLUnrNZt+Xl5KJrqK4K/T+UJE1RSZWqguglZWVkIDAxEZmYmAgJcS+XeDu6aGW8catpwpdOGE1ZZ9No4M7MfJq04hCWluMicwW+jonEsJdvYXg6IXhZLRkZDW6zD9/+dR5ysB0WXiBroWL865pd0M+7WuCbmDOiAZ77Zics38vHH6G7oLbsGxusxTfBarybIK9ShVUmzVM9mwfh+eBdoi3VoNlk5cqVB41pVEdMixPg6zri/ZQiSrubh1xejsfZoCt6WjV8yvm9zLN6VhJE9GqJYp8fQ6AioSwZ1q1+zis1Cz8s38o2FxYBowriSVaC4rPyuib2wL+m68QJ8hvZ2+XuRBzNTHmyJ6X8fRddGNbH4hbsAQNEj6Zku4Yh7rC1OpGSjzxyxLZeNijaOOhpR0w/nSzIjuyf2QrC/N7acysCwhbvROiwAf79yN3K0xahacuDNLihCZn6RcawYgwGR4ZjxaGvoJAl6vej2HtMiRNG0YfC/dSfxaclomR8/2c7YNTJHW4wqXhpj+7wkScgt1Blf2xmSJOHnnRfQPrw62tQNdPyESqCwWA+9JFmMJ1SW8gqL4e2hsdkjpSJtOpGGHG0xHmxbtk0UVDHWHU3FjFVH8b8B7dGhXnXHT7gJzh6/K0/oRKV25HKmxXUx/j2SYrWL6c6zV7HWiWtw2LLhjXvQMLgqIiNqQFukMx5kDd1QvT00ePGeRnjxHmU1fI62GBev56Ff69ro31acjct7g7x6X2N8tuE0vhrSyVhEJj9rNRzM5EOAm3sqsi5G9miE/m1qY8KKgzicbNl0NDS6Pvaev25sVpoW29KYnn8qMhxPdqqLnWevoVmoP2pU8TIOmS1nbeRYuTrVfPFCj4bGgOW+5rVwd9MgxYikVb090LNZLTzcvg66NQ7CU5HhiIyoga+3nMG02FYICfDBU/N3YPf5a+gcUR3Pdo1AsxB/xTV3vhjYAWMW70OXiBrGVL28J0RYNV/0aBqMxAvX8fkzHfHMNztRt7ovapWc4d/TNBh/v9IdNUvGoZAHDP4+nvD38cSL9zREFS8PzF4nakG8PUW7vmFOe8V8EUGmZo8nZBkL88BEpVK5FKwYnjMkOsKl57hbabMcrvDzqjy7dPl1nujWc38lvN5a5fl2k0skSYJKpcLPOy9YdPOVJDHsujWOxhKxJ6pBDUVb9PPdG1gELLZU9fbA3IG2u9WNvb9pydVurafLrY2u2LhWVdzIK8Twbg2g10vGrqdt6gZiZI9GeNVKL5EHWoXi4rU8HC3pOBFgVoSpUqkQ3ciyuaU0fhsVjd3nr+GJTnWhVqsUhbJ+JRmGT582XYW2fXg1zBvUyXh/ztPtsWTPRQy5qz40ahW6NwlSLP/BtnXQJaIGgv29jdtH3hMi0NcT3wzthIJCPQL9PLHt/+61KMg2NLnYMqGv6HZsCFjkY1Y48lC7MFzJLEBUg7LZnkR0Z2PAcgtKTLqO577fg7f7NLcIVgAYK/tvxmMdwzChbwtMWH4QPZoGo5a/N6IbKg+Y8iDiZi+IpVKprAYrXRvVxPYzVzHYyiXZuzcOwrTYllaDmdi2teHnqYGXhxp/H7yMX/eKQCHY3xtXMk3ZqKrleEYaGVFD0bYvbwt2ZnjrOtV8Me5++0Pdm28zbw8N/n6lO3R6yZihMmSl5ANIueqDx9vg3yOpdsdDMadRq2xeR4mIyFUMWG5BH/xzHDfyisp0mHKDr4Z0wpn0HIzq0QhqtQrfDuvs1PNqltPlxn94rgtSswqs9qroHFHD5oFfpVIZB0/KKyw2BixBVb3Rv01tHE/JRpuwQIueKuWpyE6RcVlylDUpjQGd6ymKXomIKhoDlkokM78I/t4eFgfRN349gDPpOXi4fR18u/WcU11R5cPk//BcF/yw/bziolqG7qkd61VTXOtEPgiRM+YP7ohvtp7Duw+1cul5zvLUqC2Clc1v9cTBS5no18bZdTVtz0BfTzzbLQLhNfyMA05VFHdelp2I6FbHgKWSOJeRi3s/3oT24dUw89E2xjEgJEky1j3sl/UysaV5qD8+frIdmof6o/GkfwAAAT4eeKtPM2PAElHTD3+O6Y7k6/loGFzFeKn4KTaG3rbngda1jV1aK0r9mlVQv6bzAzZ1bxKEYH9vtKgdALVaBX8fT4sBlyrCqHsaYcW+ZAzoHO54ZiIiUmC35kri3b+OKMYw2fr2vdh6KgM/7jjv0tgoXw/phN4lWZLJfxzChat5+H54F2jUKhQU6eChVkGtUimyOFtOpkOnlyp0MKKKpi3WwVOtrtAmIGsKinTl2q2ViOhWw27Ntxjz+objKdmlqlGRd518/5E2isdsHSh7yK6tcruy1x26IjFYISIqHV6tuQJJkoS3fzuAt2TXvdHrJfzfbwfx807lKKuGi46Z+/Tp9or7i0ZEKe7rb4+EGRERkQIDlgqUnqPFr3svYVnCJWM9ys5zV7F0r+Wosz/tvGB1Gd0am7oW/29AO3RrHITOEaZRCCuoIwoREVGFYsBSgTKyTdfweWTuf9h8Mh0Dv3FtIDf5FW4NzRyGodrFNH6kRER0+2ENSwUy7468+YT1Zh9HJvVrgb0XrhmHTfbUqPFWn2Y4eiVLkYEhIiK6XbCXUDnT6SW8+9cRtA4LVFxYr7QMFzYkIiK6HbCXUCWx5nAKftxhvR7FQK2CxYUKPdQqtA4LxBu9m2LIgt0AAH8XLxBHRER0u+ARsBx9s+UsPv73hN15albxwrfDIrHpRDq+2nIGKqiwblwPxeiuW9++F59vOGX3yrhERES3MzYJlZP8Qh1aTF3jcL6D7/RGgI+4wq4kSdAW6zlWBxER3THYJOQmSVfzEODrgce/3O7U/IZgBRAX7GOwQkREZIkBSxlafzQVI37cixa1A3AmPdfmfCN7NMSyvRfxRKe6Fbh2REREty4GLGXou+3nAADHrmTZnKd+TT9M7NcCE/u1qKjVIiIiuuVxlLEyciIlGwcvZTqcr1h3W5QMERERVShmWMqAJEnoM2eLU/MWcux8IiIilzHDUgbmbTpj87HagT7oElEDYdV8AQDt6gZW1GoRERHdNphhKQMfrbU91srWt++FWqXCybRsbDyejofa16nANSMiIro9lCrDMnfuXERERMDHxwdRUVHYvXu33fnnzJmDZs2awdfXF+Hh4Rg7diwKCgoU8yQnJ2Pw4MGoWbMmfH190aZNG+zdu7c0q+d2LWqLfuQ+nmp4aNRQq1VoHhqAl3o2MmZaiIiIyHkuZ1iWLl2KcePGYf78+YiKisKcOXPQp08fnDhxArVq1bKYf/HixRg/fjwWLlyIrl274uTJk3j22WehUqkwe/ZsAMD169fRrVs33Hvvvfjnn38QHByMU6dOoXr16jf/DstZsZWalO+e7YxVh66gZ7NgN6wRERHR7cflkW6joqLQuXNnfPHFFwAAvV6P8PBwvPLKKxg/frzF/GPGjMGxY8cQHx9vnPbGG29g165d2LZtGwBg/Pjx+O+//7B169ZSvxF3jXR7PbcQHaavU0w7+X5feHmwPIiIiMgRZ4/fLh1VCwsLkZCQgJiYGNMC1GrExMRgx44dVp/TtWtXJCQkGJuNzp49i9WrV6Nfv37GeVauXInIyEg8+eSTqFWrFjp06IBvvvnG7rpotVpkZWUp/tzh98RLAABfTw3+N6AdPn+mA4MVIiKiMubSkTUjIwM6nQ4hISGK6SEhIUhJSbH6nIEDB+K9995D9+7d4enpiUaNGqFnz56YOHGicZ6zZ8/iyy+/RJMmTbB27Vq89NJLePXVV/HDDz/YXJe4uDgEBgYa/8LDw115K2XiwMUbeH/VMQBAfpEOj3aoi9h2LKolIiIqa+WeCti0aRNmzpyJefPmITExEcuXL8eqVaswffp04zx6vR4dO3bEzJkz0aFDB4wcORIvvPAC5s+fb3O5EyZMQGZmpvHv4sWL5f1WLOw6d7XCX5OIiOhO5FLRbVBQEDQaDVJTUxXTU1NTERoaavU5U6ZMwZAhQzBixAgAQJs2bZCbm4uRI0di0qRJUKvVqF27Nlq2bKl4XosWLfD777/bXBdvb294e3u7svplzpmRbYmIiOjmuZRh8fLyQqdOnRQFtHq9HvHx8YiOjrb6nLy8PKjVypfRaMQViQ31vt26dcOJE8qxTE6ePIn69eu7snoV7vKNfABAsL83Fo+IcvPaEBER3b5c7tY8btw4DBs2DJGRkejSpQvmzJmD3NxcDB8+HAAwdOhQhIWFIS4uDgAQGxuL2bNno0OHDoiKisLp06cxZcoUxMbGGgOXsWPHomvXrpg5cyaeeuop7N69G19//TW+/vrrMnyrZS81SwsA+GpIJ3SsV/m7YBMREd2qXA5YBgwYgPT0dEydOhUpKSlo37491qxZYyzETUpKUmRUJk+eDJVKhcmTJyM5ORnBwcGIjY3FjBkzjPN07twZK1aswIQJE/Dee++hQYMGmDNnDgYNGlQGb7F86PUS0rLF4HchAT5uXhsiIrLq2lkAKqAoHwhp6XB2qrxcHoelsqrocViu5mjR6f31AIBTM/rCU8OuzERElUpOGvBxE9P9oSuBhve4b33IqnIZh4VMUrJEdiWoqheDlbKkzQbWTgKSE9y9JkR0q0s9orx/+Df3rEdlZdjf/vUasNv+2GeVAS9+WEppJfUrbA4qYxveB3bNB3Z8AbzDXlhlQpIAlcrda0F081z9Lmu8LJ9fEa97q9g0S+xrDZo+AFSr+DHNnMXUQCkZMiwMWMpYyiF3r8HtZdUbwGftgQL3jARNVGb2LBDNO67sI9Tm5+SlCFguJQAfNQb2/ez6cys78215/bxbVsNZDFhKKdUYsLh3LJjbzu1RUlX+JAk4swHIu2Z/vj3fip3QoWUVsloVJv+6eP96y4uP0m1q1TggNx34c4zzz5HMvh+l2b2seBHIywD+HF2KJ1diedeA82bX7zv8G5B5yT3r4wQGLKWUygxLOWHA4pT9i4GfHgUWPuDc/GpN+a5PRVvYV7z/hIXuXhOqaLrC0s9rHsA4Q9K5/pxbwdc9LbdHwvfA/1q5Y22cwoClFFIyC7DlZAYABixOubgHWD4SyLZ+vSkFZlics3+R+J9xAoifbn2e46tNtzVOZgIvbBefVU667XnWvwvs/NK55ZWXdHENLxxY6t71qKyunwd+f+H2bGLVWwkgEr4HVr1pyrgd+k0Ukhblmc1otn9J+AH4Z7z9/Y7a82bW1jmX94vP68ZFIPEnYPVb1rOHF7YDy1+0/vtM+B54JxCIfw/4exxwYImYLkmisHbPAtO8G2YANy44t27H/gberSEyW27OaLLothTu/99mZBcUAwBCyzpgKdYCHrdZM9OCkqt7598ABv1qfR7j+5Ysp2u8bs+CN3skCdAVAR4lRYPm3wutrCZl68dAx6FAddnI0MVaYMkzpvsaJ3e63/UteX098Pi3lo+nHAK2zRa3o0aJ9dQXm9bTQFcsPrObyezo9eIMWa0R6y9J4r58O1gckCqIrghQaQB1JT3n+3UYcGU/cPQPYIqd4PNm2NsG5bkfM88KFOaJ4AQAWj8OhEcBvz8v7pvXbpkHJn+9Kv43uR9o3Mv661nUwZSDr0u6WmdfMTXTNOsLNLpPOZ/i9ynr1SPfBls/Ef/3LgDaPQ0k7TQV1nYYDNxIArZ8aH995EXGS0vGQ9v3E1C/G9B2gNu+95X011a5GYIVAKhVljUsVw4AM2qLnjK3o4wT1qcfWQG8X0ucEch3KLlXgQ8bAr8OqZj1q0x+ekQUGGqzgdVvA7PqAxmnTY+b74gLc0y39y8GZppdNdzVzFW6jc9KniXTFQE/PwrMaSN2mPLpn3cAvo25uYzZ4ieBGSHAp+3FWfVvzwEfN1WeXaYeBtZNK/1rlEaxFvi0HfCdk81x7pB6WPx3pfnEFUUFwOyWwIL7LR9LOSx+z/9OKZ/XNm+iSdphuv3dA8DXPUz388wuUGurSSgn1fp0ANBU4Hl90k7T7Z8eFftGa66eVt5P2m57mfL39n4t4LfhjtejMFf8N8+o/DEKyKz4Cw0bMGBxkfk4e2WaYfl3svgxbvmo7JbpTimHgBNrTPdtHbyWPSv+r3gRuLTbNP3wb+JAfOyvcltFZJwCjv5Zfsu359Q60fNAVyTu52YAWz4WKeGzm4CCG6KwdPdXQHE+8N//xHxZVyzTufk3TLf/eElkPeSKC0y3Uw4rPxeDCzuU95MTRHPTRdlnIs/s/DtZrGdOCnB+m2l62jFxFnc5ETjwiwg28m+IgFSbbXNzGJ34R4yfcVoMzIisS+LAc2S52Cb7flLO/98cse2sObpSGXydXCtODOSOrxbr7KzL+4CsZODirvJvwizME9tNXlytzRbT5J+5M5ITgDMby2a9LicCuWlA8l7LxwwnXNs/s3ws/zqw/xfxHtKOi+YGAMi6DBz81fRbSNpp+pyuHBC/FQPzoMP8tyBvBjNvPpI/V34wlv8+AOD8f6bfg7xJ6MgfwMFl1pulANH87WgMqfzrwL5FgLbkJEM+v75IOe+yZ8V6Hl6u/I7ri0Rz6OHfgaRdwHUbzTtF+SLAlnOmmXDzB+I1jyy3fMy3muPnlxM2CblIW2z6kj/TJRw1q5ZhhuV2q9+Y391sgovvryK2xxeR4v+g34EmMeX/egbZqcCiJ8RtrypAq0fF2eq1s8r55DtGTz/xf72VjEL+dfuvp5PttOZ3E/9f2ACEdRK3tdmWGYNvStLRWz8GpmSIZhn56+z+ynRbvsM3nJ0BInjKuwqc2wqcWgu0edJ6U5PB5f3AL09bTpfvdOXZJIMfHwZe+k857XS8KTv3TqY4CC5+ynQfAJITTU1nzo77I/9eFhcAnr7OPa801k4QtQn1ugLP/SOm/fW6COYb9QKGWDmgAACsNKEaPs+xR4DAuje3XvKA2HyMEnuFrb+PEIHomaeAQyXNw8+uFnVTWZdEYNa0N7Cwj3hs6nXgqx7KZZgv317gZp45kX9Pi/Nlt2XfL2028H0/cXtSqrJJaNkw8b/gBtDlBeWytdmm5u//u2D7wP7LQJERyTgJ3P+u6XOxZf8iYOUYIFA2PkrKIWDFSNP9eydbf27+DeVv31nWgk0D7/IfSd4WZlhcpC0y/Vjee7i1uLHra+DXoaINcd1U5xe26yvxPF2RyCKYdzG7WZs+AP542T2BUJmM+yFb78UDxI5u+YumNlpXnFondhQ5aeIM+ceHlWfaZb3t7Uk9Cnx1t+l+doo4izIPVgBl+jYzGfj5CVPmQS7xR/FY7lXLxwAxHsv0YOCLzqZp8ozKtXNmTzD7zhi+17aKceVND/KABRBNVKfWitvy7tW6YvGb2THXNC39uPXlZ1023bZ2gDI0geReBRY/DZxarzwrN6yHuYyT1l/PHnmTRFHJQU+vt/3dzE4BfnpMZKt+etRy9FV79pUUVydtF8HioqdMo7Weibf9PPOaL50swCiLsTYUAYt512HZ9jm7Wbznq2fEfcN395Cslu3iLhGsAMDJNSKraJBjpVBfvj87vgqIf9f2euakKe8f/1tkBY/8AXzXzzR9zXgRLAPiZMJg/TvW679WvymaKOUnFIb3CAAf1BcFsObZ2y0fm5pvjv5p+v7YY/ic7TXFZF+xPv2z9sDKVxy/hivcWE/IDIuLCorFF1SjVpmG5P/nLeVMPSeKs0APHwAS4O1vekySxFgCVWsB/7wtpjWOsf6lyrsmnutswaS5TTPF/w5DgPrRsjeRJZapzQF8qwP514AqweKLqCsSZwqSHvCr6dyX05Dyr1LTNO26+QGwFOQHqZNrxJ/B3W9Yf05OOlAlSKx37lXx/tRqUzZD0gMX/hNNG4ueND2vKE98NhmngBoNrG9zw7Lzr1t+LnnXxJmHrfbugixRPOzpI87S5Gd+hTlinAdHTqyy/ZghILA3VoSuUHmAlr/mjSTlvNlmZ6Y75wHRo20f4HPSxM7X0xcoNGv2yUpW3s/NEGe0p9aK7AEAtH1afH9UNop05Tvry/uszwOI5tST/4i/Vo8qH7tg1s6fk67MjuiKSs7AVYB3VduvIT9LL8oDUEMEvAdLemWYfzf/eVscdAwHnh8fAd46ZXv5cvJgYOsnps/ZIbPfrSKbYNb8oZhPKx73CRT3czMA3xqWRZZZsgOkrkhZXC1f5x8fEv/XjAcG2RgLSF447VVF2WRxzsqJRFG++L351QCWDLT9XgBAayVr9uPD1ufdMVcUssp/F7u+BALCrM9/+Heg66tAaBvx/U85aDnPr0OBaTfE/kiSgA2yHn21Wor9jSP2euwZ2ApY7H3WtyBmWFxUUCQCFh8PO5vuTDzwUSMgLgyY3UoZRf/3qSimTPjBNM1asJJ1GfiwAfCtjcp1R+RnVLmyL3xRPjArHJgRKtZjek3x35ACXNhHvO5HjcSgY8747Tngo4bKA4m1szhXEz320pLW7P8F+LgxsHGmWJePrBTsntlgqsOQBw1FeeJsam5n4JdnYOHQb2LZK0aJ7fN9f9Nj18+LabaKMLU5Ypt/2lbcN8+kFOZZtjOX1sl/nJ9X3iZuXsSXa3ZmCojxGay1aQOi6eL7/mKnbJ4BKTA7aHzUCPhfS+DvsbJpDYH0k7YDZGcDFvkOOvWobLoWuCo7OBxcJj5Peb1YbgYwLxr4rIMoKrVFnkEy/La1djKKKYeV961tW1vk2QpHzX5y5ttRvg+y994+jwRm1ROfYdIu8VktH6Gc5+hK4M+XTffN66WsNQnZW3f5Z6DxVGb75M0eBnkZYuRZaxnJm3Fus/hv3oxkHnDL6XVi/z27ue1MhiEDZF6/dWm3MtNqy4VtjuexFbDcZhiwuKigpEnIx7PkjMJav/T490y3tZnKgj5D/YGhO50tJ0oOPFcOiB3kzvliB7L985Kz03W2K8h1xaaup4D4oeycDywZpDzQyiMIQ8pfXgC2+k1gxzzTwfTwclH5b6hkz04R63P0D3H/657if8Yp0c/fgiQOzvHTxZ+hZ0lpug3qii2nrX5T/N/yoXi/gEgBy3fWttpzi/JNTQan15nSzvsXiwK8NePFfcNZ9MVdJctfJdrlAeDSHuvLNpwx5qSK9TLfweekAtv+Z/255akoXxQ6/vWacoyG0kpOEJ99wY3SPX9uZ9O2NLf+HdkdO5Gv/AAv75V20Gy8FsPBRX42f+2MCIxy00w9T06vF2fScvIeUYbsgPwzlTcT6PViuY4UF4qxbWz1zgKsj6Vz5YBokjYUZhqbwWQBy9nNyiDLVpG5JAGZJZm2Q8uAhb3FbfP3/98c5X2LgMXK5+Mfav01zeVmWGmetELSAVtnO57PFTmpYjuaNyPZU5RnGhPJFsNv23y5uU5kTpxlL4i/jbBJyEXGDIshYLFWAGiodDfISgbCOrr2QvKLdv06TBxEDa6fN2U/gpoCIWYjE57bDGyUBQyJPwIXd6JU1k4QTUZ3vWyqpzjyBzD2kEjHmlfEn1gD/DLA+rIkSVS9G9LaqYeBgUtFwGK+03OkuADQmKXt5TtKeYramR4ghXnKs/OcNCD7sigaBYCqVna4edccp6QBZeX/mv+zfNzRDq+8nF5f9levPRPvWibAwk3WW9lKn5uf/VpLlcsPlJf2Ag3uAX5+XNyv01E0FQLK37yxhkUWpBRrAa+SAml5l1t7dn1pOmmwVfxrbVwTQ0Fq9hXTSco7mcoMy48PAS/Iegcd+hV4eK6VsXNkdUiG4N+amk3MerY4kWHxC7K9PLnsFFM9iyPWmmBsCaxnCsbMBdQ1vWZRnu0eZ9Y4U4Ni4Epm7Wa1iHWtd+UzS23vt+UCbrJY+yYxYHGRoZeQt6FJyPxsA7A8o7p2ThRk/TrM+RdaKbtehjxYAZRNNb8OFb0wVGqg9wyg/TOWPzhng5V3Aq1P3/IRFGdsmUnAh42s112cWG05zSDrknJndHKNCCZK085aXGC/zkC+w/7mXsfLM29KuX5OmQq2Vvx31cqZ84pRwLkt4rndXhOfizuyJ84obSbEHkMmyh3ere7C0OtWAiN53VXBDWXg9Vl74KXt4uRA0SRkyLDIAhadFkBJwOLsWfT5/xzPY37lYTl5RlVXBIsaFnkhq2G9As1qM8yLpeWWDhEF0b3fN2UZDb7sClSPAIasEDUo1jIs5t11bZE32zkiL5pvZWfMEsB+EO1XveS3LomM2+ZZzq/D4icdzwOIbugrXnR+uXIePkDk88DOuY7nNXA1a+1Xw/7jHYaImpsWsa4tt4yxSchFhgyLtyHD4kyPlevngKWDgdRyGCb76mnxY8y7Kgb1STtmWfRYFsxHRrRVJOrsGaWB4QzWVeZnNtocoEi2w1Xd5Fc75ZDji4BZKyw+8Isp0Pnv08obrNyq6nSw/VhprhMjJ6/juXLAsufYr8NEbYe8J9OVg6IAVX6SYugFpCuy35PHlqzLos7EvCDTvDDalqJ8yxqW7Z8r75uf7Rfm2W9WOLZSFFwbuoXL5aSKJtJjf4vMpLXPoTDPspanLHV10BPG3j7RswrgVXLyU16DVMqDlQgn6lbk6nYGoqzU8ph7vKRZ9+43bRevyzW4x3TbUVflqiFA9MtAtXD785UzZlhcZGoScuGAeO0skHbU8XxlYd5dgLeNTElFcLWbqL2CNnvMszILeivv32zAYi8lbuBMW3tFG3tEHFQNY6044hNo6hVW2T2zRPTwKq/2+nTZd/f8VsuAJfuKGN1VHhivn2Y5Ls73/YHn1opsY+KP1l/r1Hrb4/7MbgHUbi+G1pezVfBszlrG0jybZl5PsehJ54o77TEUyIZFWj52co3z618aHg4G8PStIZq2DULamE4gvfzEX2F22daV2FI9wvK71aiX7eDW0w/wqWY5vfs4ZWatzRNAw56id+dyGwFOrVZAWklALe/l6GgsIUMTp5sxw+KigpImIR8PF66RcnZT+ayMLda68t1u1k4StTy/DhUD1Bl+hAaG7rKuqm8+2J0dhm7jFcmziul22wGWzQSBdYHQ1sqgtXGM6H5pTYN7bHfblGt8v6iDaNJbDFLVuAwH2XtkvnPzBdQBQtuV3euaS3dQ61RolsWzJ/FH4LCdJopFj9vvrWMerLhi7STrtXVyu74SlzS4vE80Md9ssCJnbfTb8r7mk6OLe5oPVigfaqL146Ipy5rBv1uffjN8qwND/wSa9gXumwy0HwR0HWN7fk9fMQhd9BjgLtmwBdbq/gxDOpifsEU+J37DT8vq5eTNmI72AV52mt8rEAMWF5Uqw0Jl79RacT2Xo3+W7oq09bpanx7e5ebWq7wFyK4RFD0GePoX6/M1LCnGrNFQ7HQ72qifql7f8Vg7TR8ABv8mCscHLQPueUsss9vrrq17Gxvt/YFhgH8d64/JefuLM8hbQWGO4+Jj+SB6ZZnhkg/KZsuZeFF/93VPMajgrc7DG2jSx/bjtc0CXXlHhQ6DrQcsj30jMl3W2Po9OcO3mvgeD1wC9HgLeGSe/SYZQ7F1nxnAA7KTpLqdrc8PWAYs0WPEb7h6hGla1RDTbY2H/YJaZ3t5lTMedV2UpxVRbVUvmLrx2tL8wdK9SGjb0j3vZjz5vXPzqTS2z9atsVcoaO7uN0U77M025zjiHQAM+Mn6YzUaOn5+lWD7jzd94OZ2aHZfW9bbQuOpTOU+sdB0u98nQN8PRfU/AAQ1BgZaGbjLp5rj7f3Y19an3zcFePQr4MkfgOFWrk1kzta29fB17qrO3gFA1eBbI2jJu+a4luzoH8AnzUXthzPXWLrdyesuou1kHKzx8BGDvj1q47tq3sOqcYz43r6SKO6b9+wERBBjq6nE004TSdRLwItbgZd2WK9XkV+byMDe52+enXrtAPDEd/aPL/Lf9ODfgZqNSqarxCU5hq5U7ksAYORGsf0e/QoWmvWznOYGDFhclFMSsLTQnXbclt7SxoiKcta+dMNWWk7rUM5XLG71KNDiIeuPGYq5ADH+QctHnF/u/dMtp9kKYto8Kdphq9V3fvml0e5pyx+rQc3GyvvWzrCqN7C//IA6QP8yHiPCQJ6aVZsFLPLaAf8QIOpFILipaVpTszofQAQB1gIW+cHDx0ZNlMZDbMtWj4iRlB0Fp1GjRC2BOU8f4JEvHT/fkMZ/8nvRzbyhE72/DKrVdy14vlnOXOrh9HpRF7N0kOhCX940XkCfmYB/7fJ/LVepNECnZ8Xtrq8or5vjDA9v8T1tN0D0zvP0Ez2a1J7AQ19Y1rh4+orvreFAbu2SEJ5+Ipi2XFn7NR8tYoHabYGQltb329auoG0vW2Lee6t6BND6MeXow+ZNYj3eFM3Hd71s2Xwb1gloeA9w10viPRpOrqrWEtuv3dPKglyg9KOtlzEGLC7KLglYPH2cuOCZrTPXWi1Nt60Vi/lWt5wW2saJtbtJQU1Mt1vLeu80MbuEvKcLV6huYOUMw8PHepuz4UchH/zLsBNzpIsLXQYNO0NPszRwzcZAXdlB//EFwIubLZ8vT6tao/G2f0l6+bZ1lbwrt8ZDeeZYmnZmHxsBS2kG85N/l621ifvVAN44IYYql28DDx/xPZkgK8Cu3x14+5zp4oyA6b36VhfFxc7UF0y9DvzfeeD1g2L5Nn+TrSynTbsBDLZTKPrEd45f3xr5ezJw1COtLExIFpdXcBRwu4OkAx6cLT7z3u9bjhHjiPy7d/974uKDXV8BJl4GOg6x/D6bZ1wMWdMqtUzT1B6WlyQARDbQ2SEVqtayfFzeFGPgXRXoIiuUfUHWDV1rrx6p5LXMx/mq0UB87x+Is/3UwLpiOz1kZUTxIX/YeU33YcDiopyCkiYhWwHnXS+Liu8OQ2yn7KLHAJ2GixS+rYP/c2bXDHHUDFEWuo8D2g8WVy6Wnwmbpz8dVeTXbAx0HCpSriGtRFOPvNuhh7dyh+FfW8xjONuRj+PQe4YoSuv9vv3XbGqj/Voe8Dw8V6yXYcdQVbZN2w8GBvwsgqbHF4jPyJBJ6isbOhxQBlTWGN6b1bMzWE8JO8s8wyLfVrYKB+UGLAIayK5+6+1fdgGL/HtiKzDw8BI7dHmbveH75OEldtRtnxbpfb8altc0MtB4ONeMpFabTgA8vGzXisiX5eUPPPg/sZ62skuA6I1RGtYOWOXdS+uJhaYgwNpB1NUi6l4uXOTVFYbxQMz3Ma0eFb9RW8wzAIb3avhvXqdl3u13wCKR4X1xi2mard+5SgO0eUpk0K39luW/Sfl3pPcMsT9qZ+Vq5ICyEFjeK8hec9HIjSW/FyuXUXEm6LM1j7VArRKonGtViRmahKpqbHyZH4gTl3x/+AsRjDQquXS4vGmkflcgdo44yzQ/qBl+qPXuAgaVjEIaUNf1kXIB4N5Jrs3vXRV4ZK7obukvL8jyFEEDIKrNHXWBu28y8NDnIuUKAL2mANGygEXjrUyLjt4l5jGQ77y9q4qitE6yqxZbY62uod/HYidh0HaAWC9DkCjPAjwyF6jVQtxu84QocDNkSdo8oVxua7P75gyfYe+Sz7zpA2a9jyRTm7C9tnBzfjWVOzWNp7II19pIqOZaPCiKCQ28/S133lEvlS5gkZ91mre7B7dQ3pcfkBTNWp2Ax74yvS9nRz21pll/y2lN+4r/D3ygHFFW3uOi/yfie26+buacCRAN5FlVR4N0NX9QnPiUFY23MqNlvt5Vgk0ZyqohwFOyrtjWmvAA8Z2+WfZOQsy/y0HNxG/UFlevIGw+f70ocdAPkDWX1WwCq9QaMR7JUz8CzxtOLGXLk9dqBcoKWe96CYj91HbzivxY4FXFtM/oMMj2+6jTQfxe5K9TVgwXD3U0xk0F4jgsLsouybD4ezg5lPyTP4hrzDS4Rxws8q+bhvgGlGeizyxVDozVOAYY9pfY2VcNFmef39xn/XWG/qm8CumjX4l2UfkQ/YA4sN8/XYzV8MvTYsA5a8wrxvt/ItpN63d33EXRWmZB/iPVeCjHijA/i7V2tuldVRSxabPF4HTysS96vCV2Iq/uFyOSGkQ+J6a/tF0clM13FNXqi3E9HJEfXO/5P6BZX7E9DL0rOr8gAkrDMP6GnW3nEWLnFdZRvP6skqYoSRI7x6SdoinA0XWlDEbvBnZ8Ybqv9hAHvxe3isDH2Z22/GDg6WdWoLdcFAqaX3vHGfLsj/x7NfRPy0Jy+bo6ytiVxpAVQHiU5fRHvxTDyjcyu6iovOhSfkC3lw1zJmB59CvRwyLzkulK2taugwWIYKrLC6Kn2uYPTNPrd7+5bsfmvyfzzJAkiWZfw75GPjL2Y9+ILthy/rUtLwdipIJTl1cYvFzsi/6dbP1x8yZje02spWHvt/LqPnHBTsNIwK8fBua0lj1XFuCHdQKe+1cEDMUF4iKY8qDHr4bI2nj6Oc4IylfJ0w945hfRRTyih82nlKuH54qWAlcHuitHzLC4yNgk5OFkCtcnAGjcS/zgajS0bL9u2kfUUjSOEbflmQ2VSqTvDU0XYZ3EAdMa+RkcIAq/rB0IgpqJgrDwLvZrMVo+DAQ3F+lGQJxpNo4R2QlHBxhrzVyKMyYHB1Zb6fGQluJMKNIs2xJSsjOp0UAMLlY1FHh2tWkHEdIKqNXccnm9porutD3etr8+8vdbq4X4XORdKGs0UJ5xGgIjlUp89r7VxffA9AbFwa5xLyC4mf3XNghuLgqF5etieJ3abUUvIGfJDwYaT2XA0riXSBOXpshOnv2Ra9jTMqvQ9AER4DTsaf/AP+BncYAdYmNME1u9sRrdZ325vtXF99j8gCXP+Mm/qzUbWQ98ALF8W81+LR8WXedbPSreo/xaVLbOmIMai+3v7S+aJAPCRDAuPwAOXi7qLB6cY30Z1pj/nqLHKE9I8jKU+xp5dq1xL8vmovZ2rp91/7viuyo3cJnlWXrjXvYP4PLmGL8gMTS9OUMNWjsrV1e3xrCMoKb2x/Op0VB54lgtXDSTG5g3l9SLEsFNzUbWR2Ku3U5ZH2iLefOuT4D4Hpd1sOYswz7K1XqicsSAxUWGols/tYsX67OlcS9gwiVRQOjMGfK9E62Pemjej9/Tz3o6W94Lpo6dZiYvP+DlnSLdaM5RwGK1oFb2pXfUjdZRe755Rka+Ps36Am+eACKcGOk1oDYw7ihwn4OmM/kOyrBu8qYc7wDlAd7h+5PtmKwVYNp7jvxgWtpeL/Lt5VvD+veuNHU28jFsDOOq2OrJ0/AeYPxFUdxn73vfIhZ464ypadXcQ5851xXdEUUvDdn6qDWW9WQG3gG2a9Ce+hF47h/T5yWvG6nZGBhjZXA1+W/TP1QUFt83WRlA1IsG3jypDNrNC5xbxIqCYUOQVC9a+bh/CDD2MFC/5DcSYlbQLx9zQ6US+6bYT03T7J3o1GgomngNGt8veqf1ft/6CNyG7R7UVDm9WBZAvnXaMuBt1AuYmCze56NODjz44Gwx/+jdrgcB8lGJnRn2vjTk+z1n6rPuQGwSclFeoQhUfFRm/fajx9g/87DH1QInawGDp4/ovrdttqhdUanEj7z/bHEwrd5AXABNvqPrNVU8z1avFVsHEkfr66iIU75cazUcehv1QXJ3vQzsnCduO1O7YYurbd+GwEEeDJr3enI4jowsYNF4Ak8vVl71+dGvxZWsWz9mOdaP/LMvbfGuWi26EWtzxNmjtZ1jaXaYPd4STSstYsXBPPFH4O5x9tfDGY4+o6F/AjvnA52fB/b95FoB6Us7xNWy737D9pWr5a9fu70IMmu1EAOAyT+PB/8HZCZbBgiAsmhepbE+UFirx6y/rvxg7ulrmv7CRjHcfZ2OpiupR9wNxH4m5hm+Gti70PqYJiqVaK7e+ollT7w6HURPm2r1TNPkwbG1XowGhu3x9C/A8VVmI7haaSp66kdg+xdAlxHK6fKMl7XP39vf9d+urWW5qryCCWf2e3c4Biwu0hbpEYBceMOsL32fGdafUB56vCmudVOrpbhGkaFLZsch4k+usyyVat7F2CfAce8bR5r1E9dMCYu0PiS3gWJH4SBgcabHRJsnyiZgcVpJ27whiyA/UHl4mzWh2NgphrYFUg5aprCb9xeD8W3/TKTO2w0AUHKp96Z9xZWko182vZbBzVTyy4PrqFHi4mzyLEa3V0WNjiuDH3r6mgqNAeWonOWpWj3Ta8W849pzQ1pa/natDSFQv5uod+rxpvKKtfLvgaFQ1xp5wOITaP077mMliAFE75X4d0V3fPnvKKyj+Lsk+931+8iUjajZyP5+qWow0NfGlYm7vaa8Lw9YzH+z3gGidgMwBevN+4k/OWvvOaCO9e9J/ZKgz/zkrE5H4HKi88MdlKVWj4kAsfvY8ln+rXA9LzdjwOKiZkVHscB7Kjy2uvHL1XmEaFcPbi6u4Oqo10F5eOtsSYFZHVE8Wqc9MKvkjMxRulW+07V2US3fapYXazMnL/CsiIDl7bOiYNpw1ikPFryqKN+TrbO459aK6x+FtLR8LOYdcWAyL2Z86kcg44SpTsfRNVNKo+0AsXx5O3vk8+I7FuRkjc3twPCdlteRGQz+XVzE1LxWzD/U+lW7zWk8gHHHRW2Gp4+yWRCw3tXZoFq4KCi3VesjbyIur9+CPENqPt6Ph48pYLH3+r7VHV/jyKBGQzEKrfm+7dm/gesXrP+GyttjX4tgpbzGxHLU+5JYw+KqB3Xx8FCZBSs9J1TsSqhUotDSw0sU6rkjYKlSUxSbeniLegSfQNH1uHEMUNtK4ZmcPB1uLcPy1I+it4JhWHlr5Dvv8uhlYs6vhmmcGIMuL4reX+ajQtrKsHj52d7RqjXiMzVPN3t4iR2kIQgqjwOSSiUumChftkolXrcSFdyVO8N32hpPXxFMmgejD30hghj5aNC2BNQ2dT9VqUxFoDWbiB4h9tRoYH38FEDZRFNe9RXyDIt54KT2ECdRDe+13hxmMOAn8bse6MS1jgDxezNvfvKq4p5gBRBZ1Npty6ZZyZouL4gmx17THM56p2KGxQWSJOGULlQZ5nUcCvQc77Z1qlRi5zg3X2BdIPUIUJxv2b0UEFX1o3daTpdTDFLmpgK1fh9an15eOzTAMmgi9wpqDLy8o3TPfXC2+LtZ8iJ0V8b1cYW8ydM8YNF4iG7+jtTp4Ph3fSfzCbQ+sjYZMWBxgbbYSjNQeaTob3eBdYFR24DjfyuHo3aFPC3taOTZilaeAUudDuKsvpqL11qh25fGQ3TnL8xVjt5clhQjAZtnWCrHdWbo9scmIRdoi/TwhNnB8eop96zMrcgwAFHHYeLMtPvr1mtYnOHhZUpTO7q2T0UxdEu1d5n7stBxyK1xxWKqOM36Wo7IXJbkPVgMAYthDJz7bAz+RlTGmGFxgbZYBy9VGY2/cicavFwU09pqi3fV/50X3R9dGSK9PL20XYzEa+tK0ES3KsXAeiXFobGfiuZw+eUhiMoRAxYXFBTp4QWz8VdutlvwncTDq+yCFaAkUKkkwQpgeVFHottFsdZ029BDTqVisEIVik1CLigo1sETsgxL+F3l18WNiKiykI/CS+QmzLC4oKBIBy9DwFI1FHh6kXtXiIioItRuK67rFMhib3IfBiwuKCjSmzIsnUewVoGI7hzyEX6J3IBNQi4oKJIV3d5JA2oRERG5WakClrlz5yIiIgI+Pj6IiorC7t277c4/Z84cNGvWDL6+vggPD8fYsWNRUFBgdd5Zs2ZBpVLh9ddfL82qlav8Ip2p6La0V8olIiIil7kcsCxduhTjxo3DtGnTkJiYiHbt2qFPnz5IS0uzOv/ixYsxfvx4TJs2DceOHcOCBQuwdOlSTJw40WLePXv24KuvvkLbtm1dfycVIK+w2DQOCwMWIiKiCuNywDJ79my88MILGD58OFq2bIn58+fDz88PCxcutDr/9u3b0a1bNwwcOBARERHo3bs3nnnmGYusTE5ODgYNGoRvvvkG1avbuXy5G+VqZb2EGLAQERFVGJcClsLCQiQkJCAmJsa0ALUaMTEx2LHD+vU0unbtioSEBGOAcvbsWaxevRr9+ikvPT569Gj0799fsezKJq+w2NQkxPE2iIiIKoxLvYQyMjKg0+kQEqK8FHpISAiOHz9u9TkDBw5ERkYGunfvDkmSUFxcjFGjRimahJYsWYLExETs2bPH6XXRarXQak2DGWVlZbnyVkolRysrutXw+hlEREQVpdx7CW3atAkzZ87EvHnzkJiYiOXLl2PVqlWYPn06AODixYt47bXXsGjRIvj4+Di93Li4OAQGBhr/wsPLf3yAPG2xaRwWNgkRERFVGJcyLEFBQdBoNEhNTVVMT01NRWhoqNXnTJkyBUOGDMGIESMAAG3atEFubi5GjhyJSZMmISEhAWlpaejYsaPxOTqdDlu2bMEXX3wBrVYLjUZjsdwJEyZg3LhxxvtZWVnlHrTkFsprWNgkREREVFFcyrB4eXmhU6dOiI+PN07T6/WIj49HdHS01efk5eVBrVa+jCEAkSQJvXr1wqFDh7B//37jX2RkJAYNGoT9+/dbDVYAwNvbGwEBAYq/8qaoYWGTEBERUYVxeaTbcePGYdiwYYiMjESXLl0wZ84c5ObmYvjw4QCAoUOHIiwsDHFxcQCA2NhYzJ49Gx06dEBUVBROnz6NKVOmIDY2FhqNBv7+/mjdurXiNapUqYKaNWtaTHe3XG0xAlW54o5PoHtXhoiI6A7icsAyYMAApKenY+rUqUhJSUH79u2xZs0aYyFuUlKSIqMyefJkqFQqTJ48GcnJyQgODkZsbCxmzJhRdu+iguQVFKEmSop7y/Kqw0RERGSXSpIkyd0rURaysrIQGBiIzMzMcmseGvLZKvx0baC4MyWDzUJEREQ3ydnjN68l5AKvggwAQJF3dQYrREREFYgBiwv8iq4BAHS+vEozERFRRWLA4gJVUZ644e3v3hUhIiK6wzBgcZIkSZCKxMi6ak/nB7gjIiKim8eAxUnaYj3UkhiDRe3BUW6JiIgqEgMWJ+UVmq4jpPZkwEJERFSRGLA4KVd2HSE1r9RMRERUoRiwOCmvUCcblp8ZFiIioorEgMVJOdpi2YUPGbAQERFVJAYsTsorLIYndOIOAxYiIqIKxYDFSblaHbxUbBIiIiJyBwYsTsorNBXdgkW3REREFYoBi5PkvYR4HSEiIqKKxYDFSbmFOhbdEhERuQkDFiflaYvZrZmIiMhNGLA4KbdQB08VMyxERETuwIDFSYoaFhbdEhERVSgGLE7KLdSx6JaIiMhNGLA4KY8j3RIREbkNAxYn5Ray6JaIiMhdGLA4KVerg59KK+54VXHvyhAREd1hGLA4KbewGFWRL+54+7t3ZYiIiO4wDFiclKfVwV/FgIWIiMgdGLA4KVcrz7AEuHdliIiI7jAMWJwgSRLyCguZYSEiInITBixO0Bbr4SsVmCYww0JERFShGLA4Qd4cJKk9OdItERFRBWPA4oSsgmJULWkOUnn7AyqVm9eIiIjozsKAxQlZ+UXwA8dgISIichcGLE7IzC+Ct2GUWzYHERERVTgGLE7IKiiCt8oQsPi4d2WIiIjuQAxYnCAyLIXiDjMsREREFY4BixOy8otlTULMsBAREVU0BixOyCoogheKxR1mWIiIiCocAxYn5BfqTDUsGgYsREREFY0BixO0xXrWsBAREbkRAxYnFBbrWcNCRETkRgxYnFCo07OGhYiIyI0YsDihsFgHb5WhSYgZFiIioorGgMUJWkWTkJd7V4aIiOgOxIDFCaxhISIici8GLE5QBiysYSEiIqpopQpY5s6di4iICPj4+CAqKgq7d++2O/+cOXPQrFkz+Pr6Ijw8HGPHjkVBQYHx8bi4OHTu3Bn+/v6oVasWHnnkEZw4caI0q1YuCnV6+KlKrtbMDAsREVGFczlgWbp0KcaNG4dp06YhMTER7dq1Q58+fZCWlmZ1/sWLF2P8+PGYNm0ajh07hgULFmDp0qWYOHGicZ7Nmzdj9OjR2LlzJ9atW4eioiL07t0bubm5pX9nZUhbqEMn9UlxJ6iZe1eGiIjoDqSSJEly5QlRUVHo3LkzvvjiCwCAXq9HeHg4XnnlFYwfP95i/jFjxuDYsWOIj483TnvjjTewa9cubNu2zeprpKeno1atWti8eTN69Ojh1HplZWUhMDAQmZmZCAgIcOUtOfToh39gRd4wcWfiZcCrSpkun4iI6E7l7PHbpQxLYWEhEhISEBMTY1qAWo2YmBjs2LHD6nO6du2KhIQEY7PR2bNnsXr1avTr18/m62RmZgIAatSoYXMerVaLrKwsxV95UelE85Ve481ghYiIyA08XJk5IyMDOp0OISEhiukhISE4fvy41ecMHDgQGRkZ6N69OyRJQnFxMUaNGqVoEpLT6/V4/fXX0a1bN7Ru3drmusTFxeHdd991ZfVLTSoWY7BIGnZpJiIicody7yW0adMmzJw5E/PmzUNiYiKWL1+OVatWYfr06VbnHz16NA4fPowlS5bYXe6ECROQmZlp/Lt48WJ5rD4AQNKVDBqn9iy31yAiIiLbXMqwBAUFQaPRIDU1VTE9NTUVoaGhVp8zZcoUDBkyBCNGjAAAtGnTBrm5uRg5ciQmTZoEtdoUM40ZMwZ///03tmzZgrp169pdF29vb3h7V0wXY6m4SGwpDQMWIiIid3Apw+Ll5YVOnTopCmj1ej3i4+MRHR1t9Tl5eXmKoAQANBoNAMBQ7ytJEsaMGYMVK1Zgw4YNaNCggUtvoryp9CUZFjYJERERuYVLGRYAGDduHIYNG4bIyEh06dIFc+bMQW5uLoYPHw4AGDp0KMLCwhAXFwcAiI2NxezZs9GhQwdERUXh9OnTmDJlCmJjY42By+jRo7F48WL8+eef8Pf3R0pKCgAgMDAQvr6+ZfVeS0Wvl+AhlVz4kBkWIiIit3A5YBkwYADS09MxdepUpKSkoH379lizZo2xEDcpKUmRUZk8eTJUKhUmT56M5ORkBAcHIzY2FjNmzDDO8+WXXwIAevbsqXit7777Ds8++2wp3lbZ0UkSPFU6cYcZFiIiIrdweRyWyqq8xmEpKNLhxWkf4AevD6ALaQvNS1vLbNlERER3unIZh+VOpNNL8IRoElKxSYiIiMgtGLA4oJMkeIBNQkRERO7EgMUBvV6CV0mGBR4MWIiIiNyBAYsDbBIiIiJyPwYsDuj0EjxVhoCFGRYiIiJ3YMDigE4yZVg4DgsREZF7MGBxQCevYWGGhYiIyC0YsDig10OWYWHAQkRE5A4MWBzQSRJ6aRLFHTYJERERuQUDFgek/Ex0Vp8UdzKT3bsyREREdygGLA54X9pmupN6xH0rQkREdAdjwOKAx43zpju9prhtPYiIiO5kDFgckPSi4HazqgvQfqCb14aIiOjOxIDFAUkvriOUqS67K0ATERGRaxiwOGAIWPQqbioiIiJ34VHYAUPAIkHj5jUhIiK6czFgccAYsDDDQkRE5DY8CjtiDFiYYSEiInIXBiyOlPQSYoaFiIjIfXgUdsDQJARmWIiIiNyGAYsjEpuEiIiI3I0BiwOSjkW3RERE7sajsCPMsBAREbkdAxZHjDUs3FRERETuwqOwAxIzLERERG7HgMUBlV4PAJDUHm5eEyIiojsXAxYHONItERGR+/Eo7IjEcViIiIjcjQGLIxKLbomIiNyNR2FHeC0hIiIit2PA4oDKkGFRM2AhIiJyFwYsjpT0EmLAQkRE5D4MWBwpybCo2CRERETkNgxYHFBJ7NZMRETkbjwKO6CSSgaOY4aFiIjIbRiwOGDIsOiZYSEiInIbHoUdYIaFiIjI/RiwOGAKWLipiIiI3IVHYQdUKCm65aYiIiJyGx6FHWCTEBERkfsxYHFALRUDYJMQERGRO5XqKDx37lxERETAx8cHUVFR2L17t93558yZg2bNmsHX1xfh4eEYO3YsCgoKbmqZFcWYYQEzLERERO7icsCydOlSjBs3DtOmTUNiYiLatWuHPn36IC0tzer8ixcvxvjx4zFt2jQcO3YMCxYswNKlSzFx4sRSL7MiGQeO49D8REREbuNywDJ79my88MILGD58OFq2bIn58+fDz88PCxcutDr/9u3b0a1bNwwcOBARERHo3bs3nnnmGUUGxdVlViRDhkXP1jMiIiK3cekoXFhYiISEBMTExJgWoFYjJiYGO3bssPqcrl27IiEhwRignD17FqtXr0a/fv1KvcyKpEJJkxAzLERERG7j4crMGRkZ0Ol0CAkJUUwPCQnB8ePHrT5n4MCByMjIQPfu3SFJEoqLizFq1Chjk1BplgkAWq0WWq3WeD8rK8uVt+I0Y5MQa1iIiIjcptzbOTZt2oSZM2di3rx5SExMxPLly7Fq1SpMnz79ppYbFxeHwMBA4194eHgZrbGS2lB0q2aTEBERkbu4lGEJCgqCRqNBamqqYnpqaipCQ0OtPmfKlCkYMmQIRowYAQBo06YNcnNzMXLkSEyaNKlUywSACRMmYNy4ccb7WVlZ5RK0mDIsDFiIiIjcxaWjsJeXFzp16oT4+HjjNL1ej/j4eERHR1t9Tl5eHtRm2QmNRjSvSJJUqmUCgLe3NwICAhR/5YEDxxEREbmfSxkWABg3bhyGDRuGyMhIdOnSBXPmzEFubi6GDx8OABg6dCjCwsIQFxcHAIiNjcXs2bPRoUMHREVF4fTp05gyZQpiY2ONgYujZbpTpk8dZGg1KFZ7u3tViIiI7lguBywDBgxAeno6pk6dipSUFLRv3x5r1qwxFs0mJSUpMiqTJ0+GSqXC5MmTkZycjODgYMTGxmLGjBlOL9Odlrb5Fp9tOI0hPvXdvSpERER3LJUkSZK7V6IsZGVlITAwEJmZmWXaPDT73xP4bMNpDI2uj/cebl1myyUiIiLnj9+sJHXAEM2p3LoWREREdzYGLA7cHvknIiKiWxsDFgekkhyLSsUcCxERkbswYHGAGRYiIiL3Y8DiJCZYiIiI3IcBiwOmoltGLERERO7CgMUBNgkRERG5HwMWB0xFt25eESIiojsYAxZHSjIsjFeIiIjchwGLk5hhISIich8GLA4Yi24ZsRAREbkNAxYHbpNLLREREd3SGLA4ILGGhYiIyO0YsDhgzK8wYiEiInIbBixO4sBxRERE7sOAxQFjkxDjFSIiIrdhwOKABBbdEhERuRsDFgdYdEtEROR+DFicxCYhIiIi92HA4iQW3RIREbkPAxYHDAPHMcNCRETkPgxYHDAOze/WtSAiIrqzMWBxgCPzExERuR8DFgeM3ZrZJkREROQ2DFicxHCFiIjIfRiwOMCRbomIiNyPAYsDpqJbRixERETuwoDFARbdEhERuR8DFoc4DgsREZG7MWBxEuMVIiIi92HA4gCLbomIiNyPAYsDpoCFEQsREZG7MGBxwDhwHBEREbkNAxYH2EuIiIjI/RiwOIktQkRERO7DgMUBDhxHRETkfgxYHGAvISIiIvdjwOIAi26JiIjcjwGLI4YMi3vXgoiI6I7GgMVJbBIiIiJyHwYsDrDoloiIyP0YsDggSbz4IRERkbuVKmCZO3cuIiIi4OPjg6ioKOzevdvmvD179oRKpbL469+/v3GenJwcjBkzBnXr1oWvry9atmyJ+fPnl2bVyhxLbomIiNzP5YBl6dKlGDduHKZNm4bExES0a9cOffr0QVpamtX5ly9fjitXrhj/Dh8+DI1GgyeffNI4z7hx47BmzRr8/PPPOHbsGF5//XWMGTMGK1euLP07KyMc6ZaIiMj9XA5YZs+ejRdeeAHDhw83ZkL8/PywcOFCq/PXqFEDoaGhxr9169bBz89PEbBs374dw4YNQ8+ePREREYGRI0eiXbt2djM3FY0XPyQiInIflwKWwsJCJCQkICYmxrQAtRoxMTHYsWOHU8tYsGABnn76aVSpUsU4rWvXrli5ciWSk5MhSRI2btyIkydPonfv3jaXo9VqkZWVpfgrD6aiWyIiInIXlwKWjIwM6HQ6hISEKKaHhIQgJSXF4fN3796Nw4cPY8SIEYrpn3/+OVq2bIm6devCy8sLDzzwAObOnYsePXrYXFZcXBwCAwONf+Hh4a68Faex6JaIiMj9KrSX0IIFC9CmTRt06dJFMf3zzz/Hzp07sXLlSiQkJOCTTz7B6NGjsX79epvLmjBhAjIzM41/Fy9eLJd1ZgkLERGR+3m4MnNQUBA0Gg1SU1MV01NTUxEaGmr3ubm5uViyZAnee+89xfT8/HxMnDgRK1asMPYcatu2Lfbv34+PP/5Y0fwk5+3tDW9vb1dWv3Q40i0REZHbuZRh8fLyQqdOnRAfH2+cptfrER8fj+joaLvPXbZsGbRaLQYPHqyYXlRUhKKiIqjVylXRaDTQ6/WurF65YtEtERGR+7iUYQFEF+Rhw4YhMjISXbp0wZw5c5Cbm4vhw4cDAIYOHYqwsDDExcUpnrdgwQI88sgjqFmzpmJ6QEAA7rnnHrz11lvw9fVF/fr1sXnzZvz444+YPXv2Tby1smG4+CHjFSIiIvdxOWAZMGAA0tPTMXXqVKSkpKB9+/ZYs2aNsRA3KSnJIlty4sQJbNu2Df/++6/VZS5ZsgQTJkzAoEGDcO3aNdSvXx8zZszAqFGjSvGWypbEJiEiIiK3U0nS7TE0WlZWFgIDA5GZmYmAgIAyW+6onxKw5kgKpj/cCkOiI8psuUREROT88ZvXEnJAMlbdMsdCRETkLgxYnMRwhYiIyH0YsDggMcFCRETkdgxYHDANzc+IhYiIyF0YsDjADAsREZH7MWBx6LboREVERHRLY8DiJCZYiIiI3IcBiwNsEiIiInI/BiwOsOiWiIjI/RiwOCBxbH4iIiK3Y8DiAEtuiYiI3I8Bi5OYYCEiInIfBiwOmIpuGbIQERG5CwMWB0xFt0REROQuDFgcMBTdMsFCRETkPgxYiIiIqNJjwOIkZliIiIjchwGLA6ZhWBixEBERuQsDFgcksIaFiIjI3RiwOCBx5DgiIiK3Y8DiAAMWIiIi92PA4iQOHEdEROQ+DFgcMNawuHk9iIiI7mQMWBwwDc3v3vUgIiK6kzFgccA0ND8jFiIiIndhwOIIi26JiIjcjgGLk9gkRERE5D4MWBxg0S0REZH7MWBxgEW3RERE7seAxQFTCQsjFiIiIndhwOKAxKFuiYiI3I4Bi5PYJEREROQ+DFgcMI3DQkRERO7CgMUBU9EtQxYiIiJ3YcDiADMsRERE7seAxREW3RIREbkdAxYnsUWIiIjIfRiwOGBsEmLAQkRE5DYMWBwwFt2yioWIiMhtGLA4YLiWEOMVIiIi92HA4oDEeIWIiMjtShWwzJ07FxEREfDx8UFUVBR2795tc96ePXtCpVJZ/PXv318x37Fjx/DQQw8hMDAQVapUQefOnZGUlFSa1SMiIqLbjMsBy9KlSzFu3DhMmzYNiYmJaNeuHfr06YO0tDSr8y9fvhxXrlwx/h0+fBgajQZPPvmkcZ4zZ86ge/fuaN68OTZt2oSDBw9iypQp8PHxKf07KyMcOI6IiMj9PFx9wuzZs/HCCy9g+PDhAID58+dj1apVWLhwIcaPH28xf40aNRT3lyxZAj8/P0XAMmnSJPTr1w8ffvihcVqjRo1cXbVywYHjiIiI3M+lDEthYSESEhIQExNjWoBajZiYGOzYscOpZSxYsABPP/00qlSpAgDQ6/VYtWoVmjZtij59+qBWrVqIiorCH3/8YXc5Wq0WWVlZir/yYLhaMxMsRERE7uNSwJKRkQGdToeQkBDF9JCQEKSkpDh8/u7du3H48GGMGDHCOC0tLQ05OTmYNWsWHnjgAfz777949NFH8dhjj2Hz5s02lxUXF4fAwEDjX3h4uCtvxWXs1kxEROQ+FdpLaMGCBWjTpg26dOlinKbX6wEADz/8MMaOHYv27dtj/PjxePDBBzF//nyby5owYQIyMzONfxcvXiz39SciIiL3cClgCQoKgkajQWpqqmJ6amoqQkND7T43NzcXS5YswfPPP2+xTA8PD7Rs2VIxvUWLFnZ7CXl7eyMgIEDxVx5MRbflsngiIiJygksBi5eXFzp16oT4+HjjNL1ej/j4eERHR9t97rJly6DVajF48GCLZXbu3BknTpxQTD958iTq16/vyuqVC8PAcYxXiIiI3MflXkLjxo3DsGHDEBkZiS5dumDOnDnIzc019hoaOnQowsLCEBcXp3jeggUL8Mgjj6BmzZoWy3zrrbcwYMAA9OjRA/feey/WrFmDv/76C5s2bSrduypDErsJERERuZ3LAcuAAQOQnp6OqVOnIiUlBe3bt8eaNWuMhbhJSUlQq5WJmxMnTmDbtm34999/rS7z0Ucfxfz58xEXF4dXX30VzZo1w++//47u3buX4i2VLVO8woiFiIjIXVSSZMwh3NKysrIQGBiIzMzMMq1niZm9GafTcvDLC3chupFldoiIiIhKz9njN68l5ADHYSEiInI/BiwOsISFiIjI/RiwOMJrCREREbkdAxYHjBkWxitERERuw4CFiIiIKj0GLA4Yi27dvB5ERER3MgYsDrBJiIiIyP0YsDhgGqWGEQsREZG7MGBxwHgtIcYrREREbsOAhYiIiCo9BiwOGJqEmGAhIiJyHwYsDkgcOI6IiMjtGLA4ieEKERGR+zBgcRITLERERO7DgMUBydSvmYiIiNyEAYsDpqs1M8VCRETkLgxYHDAV3bp3PYiIiO5kDFgckMAmISIiIndjwOIkZliIiIjchwGLA6y5JSIicj8GLA6w6JaIiMj9PNy9ApXd8G4RyNUWI8jfy92rQkREdMdiwOLAyz0bu3sViIiI7nhsEiIiIqJKjwELERERVXoMWIiIiKjSY8BCRERElR4DFiIiIqr0GLAQERFRpceAhYiIiCo9BixERERU6TFgISIiokqPAQsRERFVegxYiIiIqNJjwEJERESVHgMWIiIiqvRum6s1S5IEAMjKynLzmhAREZGzDMdtw3HcltsmYMnOzgYAhIeHu3lNiIiIyFXZ2dkIDAy0+bhKchTS3CL0ej0uX74Mf39/qFSqMltuVlYWwsPDcfHiRQQEBJTZckmJ27nicFtXDG7nisHtXHHKa1tLkoTs7GzUqVMHarXtSpXbJsOiVqtRt27dclt+QEAAfwwVgNu54nBbVwxu54rB7VxxymNb28usGLDoloiIiCo9BixERERU6TFgccDb2xvTpk2Dt7e3u1fltsbtXHG4rSsGt3PF4HauOO7e1rdN0S0RERHdvphhISIiokqPAQsRERFVegxYiIiIqNJjwEJERESVHgMWB+bOnYuIiAj4+PggKioKu3fvdvcq3TLi4uLQuXNn+Pv7o1atWnjkkUdw4sQJxTwFBQUYPXo0atasiapVq+Lxxx9HamqqYp6kpCT0798ffn5+qFWrFt566y0UFxdX5Fu5pcyaNQsqlQqvv/66cRq3c9lJTk7G4MGDUbNmTfj6+qJNmzbYu3ev8XFJkjB16lTUrl0bvr6+iImJwalTpxTLuHbtGgYNGoSAgABUq1YNzz//PHJycir6rVRaOp0OU6ZMQYMGDeDr64tGjRph+vTpimvNcDuXzpYtWxAbG4s6depApVLhjz/+UDxeVtv14MGDuPvuu+Hj44Pw8HB8+OGHN7/yEtm0ZMkSycvLS1q4cKF05MgR6YUXXpCqVasmpaamunvVbgl9+vSRvvvuO+nw4cPS/v37pX79+kn16tWTcnJyjPOMGjVKCg8Pl+Lj46W9e/dKd911l9S1a1fj48XFxVLr1q2lmJgYad++fdLq1auloKAgacKECe54S5Xe7t27pYiICKlt27bSa6+9ZpzO7Vw2rl27JtWvX1969tlnpV27dklnz56V1q5dK50+fdo4z6xZs6TAwEDpjz/+kA4cOCA99NBDUoMGDaT8/HzjPA888IDUrl07aefOndLWrVulxo0bS88884w73lKlNGPGDKlmzZrS33//LZ07d05atmyZVLVqVenTTz81zsPtXDqrV6+WJk2aJC1fvlwCIK1YsULxeFls18zMTCkkJEQaNGiQdPjwYemXX36RfH19pa+++uqm1p0Bix1dunSRRo8ebbyv0+mkOnXqSHFxcW5cq1tXWlqaBEDavHmzJEmSdOPGDcnT01NatmyZcZ5jx45JAKQdO3ZIkiR+XGq1WkpJSTHO8+WXX0oBAQGSVqut2DdQyWVnZ0tNmjSR1q1bJ91zzz3GgIXbuez83//9n9S9e3ebj+v1eik0NFT66KOPjNNu3LgheXt7S7/88oskSZJ09OhRCYC0Z88e4zz//POPpFKppOTk5PJb+VtI//79peeee04x7bHHHpMGDRokSRK3c1kxD1jKarvOmzdPql69umLf8X//939Ss2bNbmp92SRkQ2FhIRISEhATE2OcplarERMTgx07drhxzW5dmZmZAIAaNWoAABISElBUVKTYxs2bN0e9evWM23jHjh1o06YNQkJCjPP06dMHWVlZOHLkSAWufeU3evRo9O/fX7E9AW7nsrRy5UpERkbiySefRK1atdChQwd88803xsfPnTuHlJQUxbYODAxEVFSUYltXq1YNkZGRxnliYmKgVquxa9euinszlVjXrl0RHx+PkydPAgAOHDiAbdu2oW/fvgC4nctLWW3XHTt2oEePHvDy8jLO06dPH5w4cQLXr18v9frdNhc/LGsZGRnQ6XSKHTgAhISE4Pjx425aq1uXXq/H66+/jm7duqF169YAgJSUFHh5eaFatWqKeUNCQpCSkmKcx9pnYHiMhCVLliAxMRF79uyxeIzbueycPXsWX375JcaNG4eJEydiz549ePXVV+Hl5YVhw4YZt5W1bSnf1rVq1VI87uHhgRo1anBblxg/fjyysrLQvHlzaDQa6HQ6zJgxA4MGDQIAbudyUlbbNSUlBQ0aNLBYhuGx6tWrl2r9GLBQhRg9ejQOHz6Mbdu2uXtVbjsXL17Ea6+9hnXr1sHHx8fdq3Nb0+v1iIyMxMyZMwEAHTp0wOHDhzF//nwMGzbMzWt3+/j111+xaNEiLF68GK1atcL+/fvx+uuvo06dOtzOdzA2CdkQFBQEjUZj0ZMiNTUVoaGhblqrW9OYMWPw999/Y+PGjahbt65xemhoKAoLC3Hjxg3F/PJtHBoaavUzMDxGosknLS0NHTt2hIeHBzw8PLB582Z89tln8PDwQEhICLdzGalduzZatmypmNaiRQskJSUBMG0re/uN0NBQpKWlKR4vLi7GtWvXuK1LvPXWWxg/fjyefvpptGnTBkOGDMHYsWMRFxcHgNu5vJTVdi2v/QkDFhu8vLzQqVMnxMfHG6fp9XrEx8cjOjrajWt265AkCWPGjMGKFSuwYcMGixRhp06d4OnpqdjGJ06cQFJSknEbR0dH49ChQ4ofyLp16xAQEGBx4LhT9erVC4cOHcL+/fuNf5GRkRg0aJDxNrdz2ejWrZtF1/yTJ0+ifv36AIAGDRogNDRUsa2zsrKwa9cuxba+ceMGEhISjPNs2LABer0eUVFRFfAuKr+8vDyo1crDk0ajgV6vB8DtXF7KartGR0djy5YtKCoqMs6zbt06NGvWrNTNQQDYrdmeJUuWSN7e3tL3338vHT16VBo5cqRUrVo1RU8Ksu2ll16SAgMDpU2bNklXrlwx/uXl5RnnGTVqlFSvXj1pw4YN0t69e6Xo6GgpOjra+Lihu23v3r2l/fv3S2vWrJGCg4PZ3dYBeS8hSeJ2Liu7d++WPDw8pBkzZkinTp2SFi1aJPn5+Uk///yzcZ5Zs2ZJ1apVk/7880/p4MGD0sMPP2y1W2iHDh2kXbt2Sdu2bZOaNGlyx3e3lRs2bJgUFhZm7Na8fPlyKSgoSHr77beN83A7l052dra0b98+ad++fRIAafbs2dK+ffukCxcuSJJUNtv1xo0bUkhIiDRkyBDp8OHD0pIlSyQ/Pz92ay5vn3/+uVSvXj3Jy8tL6tKli7Rz5053r9ItA4DVv++++844T35+vvTyyy9L1atXl/z8/KRHH31UunLlimI558+fl/r27Sv5+vpKQUFB0htvvCEVFRVV8Lu5tZgHLNzOZeevv/6SWrduLXl7e0vNmzeXvv76a8Xjer1emjJlihQSEiJ5e3tLvXr1kk6cOKGY5+rVq9IzzzwjVa1aVQoICJCGDx8uZWdnV+TbqNSysrKk1157TapXr57k4+MjNWzYUJo0aZKimyy3c+ls3LjR6n552LBhkiSV3XY9cOCA1L17d8nb21sKCwuTZs2addPrrpIk2dCBRERERJUQa1iIiIio0mPAQkRERJUeAxYiIiKq9BiwEBERUaXHgIWIiIgqPQYsREREVOkxYCEiIqJKjwELERERVXoMWIiIiKjSY8BCRERElR4DFiIiIqr0GLAQERFRpff/NGFrVrGk6YAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
