{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Admission_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Serial No.\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7, activation=\"relu\", input_dim=7))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                80        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147\n",
      "Trainable params: 147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 1s 185ms/step - loss: 0.3806 - val_loss: 0.4894\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3567 - val_loss: 0.4565\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3351 - val_loss: 0.4260\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3150 - val_loss: 0.3982\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2958 - val_loss: 0.3733\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2775 - val_loss: 0.3496\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2607 - val_loss: 0.3270\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2453 - val_loss: 0.3075\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2309 - val_loss: 0.2888\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2171 - val_loss: 0.2710\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2041 - val_loss: 0.2534\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1918 - val_loss: 0.2371\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1803 - val_loss: 0.2210\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1687 - val_loss: 0.2056\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1589 - val_loss: 0.1907\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1489 - val_loss: 0.1765\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1393 - val_loss: 0.1631\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1313 - val_loss: 0.1503\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1228 - val_loss: 0.1386\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1150 - val_loss: 0.1279\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1078 - val_loss: 0.1183\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1017 - val_loss: 0.1095\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0953 - val_loss: 0.1019\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0908 - val_loss: 0.0952\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0855 - val_loss: 0.0895\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0810 - val_loss: 0.0848\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0775 - val_loss: 0.0810\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0740 - val_loss: 0.0779\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0718 - val_loss: 0.0755\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0691 - val_loss: 0.0736\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0671 - val_loss: 0.0721\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0655 - val_loss: 0.0708\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0640 - val_loss: 0.0696\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0626 - val_loss: 0.0684\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0611 - val_loss: 0.0672\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0599 - val_loss: 0.0660\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0588 - val_loss: 0.0649\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0574 - val_loss: 0.0638\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0563 - val_loss: 0.0628\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0551 - val_loss: 0.0617\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0540 - val_loss: 0.0607\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0529 - val_loss: 0.0597\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0518 - val_loss: 0.0586\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0507 - val_loss: 0.0576\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0496 - val_loss: 0.0566\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0486 - val_loss: 0.0555\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0476 - val_loss: 0.0545\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0467 - val_loss: 0.0535\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0457 - val_loss: 0.0526\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0448 - val_loss: 0.0517\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0439 - val_loss: 0.0508\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0432 - val_loss: 0.0499\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0423 - val_loss: 0.0490\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0415 - val_loss: 0.0482\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0407 - val_loss: 0.0475\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0400 - val_loss: 0.0467\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0393 - val_loss: 0.0460\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0386 - val_loss: 0.0452\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0379 - val_loss: 0.0445\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0372 - val_loss: 0.0439\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0366 - val_loss: 0.0432\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0360 - val_loss: 0.0426\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0353 - val_loss: 0.0420\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0348 - val_loss: 0.0414\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0342 - val_loss: 0.0408\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0336 - val_loss: 0.0402\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0330 - val_loss: 0.0396\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0325 - val_loss: 0.0391\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0319 - val_loss: 0.0385\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0314 - val_loss: 0.0379\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0309 - val_loss: 0.0373\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0304 - val_loss: 0.0367\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0299 - val_loss: 0.0362\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0294 - val_loss: 0.0355\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0289 - val_loss: 0.0350\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0285 - val_loss: 0.0344\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0280 - val_loss: 0.0339\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0276 - val_loss: 0.0333\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0271 - val_loss: 0.0327\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0267 - val_loss: 0.0322\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0263 - val_loss: 0.0316\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0258 - val_loss: 0.0311\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0254 - val_loss: 0.0306\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0251 - val_loss: 0.0301\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0246 - val_loss: 0.0296\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0242 - val_loss: 0.0291\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0239 - val_loss: 0.0286\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0235 - val_loss: 0.0282\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0231 - val_loss: 0.0278\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0228 - val_loss: 0.0273\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0224 - val_loss: 0.0268\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0221 - val_loss: 0.0264\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0217 - val_loss: 0.0259\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0214 - val_loss: 0.0255\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0211 - val_loss: 0.0252\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0208 - val_loss: 0.0248\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0205 - val_loss: 0.0244\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0202 - val_loss: 0.0240\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0199 - val_loss: 0.0236\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0196 - val_loss: 0.0233\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0193 - val_loss: 0.0230\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0190 - val_loss: 0.0226\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0187 - val_loss: 0.0223\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0185 - val_loss: 0.0219\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0182 - val_loss: 0.0216\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0180 - val_loss: 0.0212\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0177 - val_loss: 0.0209\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0174 - val_loss: 0.0206\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0172 - val_loss: 0.0203\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0169 - val_loss: 0.0200\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0167 - val_loss: 0.0197\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0165 - val_loss: 0.0194\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0163 - val_loss: 0.0190\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0160 - val_loss: 0.0187\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0158 - val_loss: 0.0184\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0156 - val_loss: 0.0181\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0154 - val_loss: 0.0178\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0152 - val_loss: 0.0176\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0149 - val_loss: 0.0173\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0147 - val_loss: 0.0170\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0145 - val_loss: 0.0167\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0143 - val_loss: 0.0165\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0141 - val_loss: 0.0162\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0139 - val_loss: 0.0160\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0136 - val_loss: 0.0155\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0134 - val_loss: 0.0152\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0132 - val_loss: 0.0150\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0130 - val_loss: 0.0147\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0127 - val_loss: 0.0142\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0125 - val_loss: 0.0140\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0123 - val_loss: 0.0138\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0122 - val_loss: 0.0136\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0120 - val_loss: 0.0134\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0119 - val_loss: 0.0132\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0117 - val_loss: 0.0130\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0116 - val_loss: 0.0128\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0114 - val_loss: 0.0126\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0111 - val_loss: 0.0122\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0087 - val_loss: 0.0092\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0086 - val_loss: 0.0091\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0084 - val_loss: 0.0088\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 270/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 287/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 301/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 327/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 344/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 352/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 353/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 354/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 355/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 356/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 357/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 358/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 359/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 360/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 361/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 362/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 363/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 364/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 365/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 366/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 367/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 368/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 369/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 370/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 371/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 372/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 373/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 374/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 375/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 376/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 377/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 378/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 379/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 380/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 381/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 382/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 383/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 384/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 385/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 386/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 387/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 388/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 389/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 390/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 391/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 392/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 393/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 394/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 395/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 396/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 397/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 398/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 399/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 400/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 401/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 402/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 403/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 404/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 405/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 406/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 407/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 408/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 409/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 410/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 411/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 412/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 413/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 414/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 415/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 416/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 417/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 418/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 419/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 420/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 421/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 422/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 423/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 424/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 425/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 426/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 427/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 428/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 429/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 430/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 431/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 432/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 433/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 434/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 435/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 436/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 437/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 438/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 439/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 440/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 441/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 442/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 443/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 444/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 445/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 446/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 447/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 448/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 449/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 450/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 451/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 452/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 453/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 454/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 455/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 456/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 457/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 458/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 459/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 460/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 461/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 462/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 463/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 464/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 465/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 466/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 467/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 468/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 469/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 470/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 471/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 472/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 473/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 474/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 475/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 476/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 477/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 478/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 479/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 480/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 481/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 482/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 483/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 484/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 485/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 486/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 487/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 488/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 489/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 490/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 491/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 492/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 493/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 494/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 495/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 496/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 497/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 498/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 499/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 500/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 501/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 502/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 503/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 504/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 505/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 506/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 507/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 508/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 509/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 510/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 511/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 512/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 513/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 514/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 515/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 516/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 517/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 518/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 519/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 520/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 521/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 522/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 523/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 524/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 525/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 526/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 527/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 528/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 529/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 530/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 531/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 532/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 533/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 534/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 535/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 536/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 537/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 538/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 539/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 540/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 541/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 542/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 543/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 544/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 545/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 546/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 547/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 548/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 549/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 550/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 551/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 552/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 553/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 554/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 555/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 556/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 557/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 558/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 559/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 560/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 561/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 562/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 563/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 564/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 565/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 566/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 567/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 568/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 569/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 570/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 571/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 572/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 573/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 574/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 575/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 576/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 577/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 578/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 579/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 580/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 581/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 582/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 583/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 584/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 585/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 586/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 587/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 588/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 589/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 590/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 591/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 592/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 593/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 594/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 595/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 596/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 597/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 598/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 599/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 600/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 601/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 602/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 603/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 604/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 605/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 606/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 607/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 608/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 609/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 610/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 611/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 612/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 613/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 614/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 615/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 616/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 617/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 618/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 619/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 620/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 621/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 622/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 623/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 624/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 625/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 626/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 627/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 628/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 629/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 630/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 631/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 632/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 633/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 634/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 635/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 636/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 637/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 638/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 639/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 640/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 641/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 642/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 643/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 644/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 645/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 646/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 647/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 648/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 649/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 650/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 651/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 652/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 653/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 654/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 655/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 656/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 657/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 658/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 659/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 660/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 661/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 662/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 663/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 664/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 665/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 666/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 667/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 668/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 669/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 670/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 671/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 672/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 673/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 674/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 675/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 676/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 677/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 678/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 679/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 680/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 681/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 682/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 683/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 684/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 685/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 686/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 687/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 688/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 689/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 690/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 691/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 692/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 693/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 694/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 695/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 696/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 697/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 698/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 699/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 700/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 701/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 702/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 703/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 704/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 705/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 706/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 707/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 708/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 709/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 710/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 711/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 712/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 713/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 714/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 715/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 716/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 717/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 718/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 719/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 720/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 721/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 722/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 723/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 724/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 725/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 726/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 727/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 728/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 729/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 730/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 731/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 732/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 733/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 734/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 735/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 736/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 737/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 738/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 739/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 740/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 741/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 742/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 743/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 744/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 745/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 746/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 747/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 748/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 749/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 750/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 751/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 752/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 753/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 754/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 755/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 756/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 757/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 758/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 759/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 760/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 761/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 762/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 763/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 764/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 765/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 766/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 767/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 768/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 769/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 770/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 771/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 772/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 773/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 774/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 775/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 776/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 777/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 778/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 779/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 780/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 781/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 782/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 783/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 784/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 785/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 786/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 787/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 788/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 789/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 790/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 791/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 792/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 793/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 794/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 795/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 796/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 797/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 798/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 799/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 800/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 801/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 802/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 803/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 804/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 805/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 806/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 807/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 808/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 809/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 810/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 811/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 812/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 813/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 814/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 815/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 816/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 817/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 818/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 819/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 820/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 821/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 822/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 823/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 824/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 825/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 826/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 827/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 828/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 829/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 830/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 831/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 832/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 833/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 834/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 835/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 836/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 837/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 838/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 839/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 840/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 841/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 842/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 843/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 844/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 845/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 846/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 847/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 848/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 849/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 850/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 851/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 852/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 853/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 854/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 855/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 856/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 857/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 858/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 859/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 860/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 861/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 862/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 863/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 864/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 865/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 866/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 867/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 868/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 869/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 870/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 871/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 872/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 873/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 874/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 875/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 876/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 877/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 878/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 879/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 880/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 881/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 882/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 883/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 884/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 885/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 886/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 887/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 888/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 889/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 890/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 891/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 892/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 893/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 894/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 895/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 896/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 897/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 898/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 899/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 900/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 901/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 902/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 903/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 904/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 905/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 906/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 907/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 908/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 909/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 910/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 911/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 912/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 913/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 914/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 915/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 916/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 917/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 918/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 919/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 920/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 921/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 922/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 923/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 924/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 925/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 926/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 927/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 928/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 929/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 930/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 931/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 932/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 933/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 934/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 935/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 936/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 937/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 938/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 939/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 940/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 941/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 942/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 943/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 944/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 945/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 946/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 947/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 948/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 949/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 950/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 951/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 952/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 953/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 954/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 955/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 956/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 957/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 958/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 959/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 960/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 961/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 962/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 963/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 964/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 965/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 966/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 967/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 968/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 969/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 970/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 971/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 972/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 973/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 974/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 975/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 976/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 977/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 978/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 979/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 980/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 981/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 982/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 983/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 984/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 985/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 986/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 987/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 988/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 989/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 990/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 991/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 992/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 993/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 994/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 995/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 996/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 997/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 998/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 999/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 1000/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.0022\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7382891552663304"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cd5e612a50>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
